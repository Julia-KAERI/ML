[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MachineLearning",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>MachineLearning</span>"
    ]
  },
  {
    "objectID": "src/theory/ML.html",
    "href": "src/theory/ML.html",
    "title": "기계 학습",
    "section": "",
    "text": "References",
    "crumbs": [
      "Home",
      "기계 학습"
    ]
  },
  {
    "objectID": "src/theory/ML.html#기계-학습의-분류",
    "href": "src/theory/ML.html#기계-학습의-분류",
    "title": "기계 학습",
    "section": "기계 학습의 분류",
    "text": "기계 학습의 분류\n\n지도 학습(Supervised Learning)\n\n입력 \\(\\boldsymbol{x}\\) 에 대한 정답(label) \\(\\boldsymbol{t}\\) 이 있는 데이터를 학습한다.\n회귀(regression) : 정답으로서 가능한 값이 실수(\\(\\mathbb{R}\\)) 인 경우.\n분류(classification) : 정답으로서 가능한 값이 이산적인 값일 경우.\n\n비지도 학습(Unsupervised Learning)\n\n정답(label)이 없는 데이터를 특징별로 군집화 (clustering) 하거나 데이터의 분포를 추정한다.\n\n강화학습 or 증강학습 (Reinforced Learning)\n\n주어진 데이터가 아닌, 환경과 상호작용을 통해 학습\n주어진 상태(state) 에 행동 (action) 을 취하며, 이에 대한 보상(reward)을 받는다.\n훈련 도중에, 최대 보상을 받도록 정책(policy)를 지속적으로 수정한다.",
    "crumbs": [
      "Home",
      "기계 학습"
    ]
  },
  {
    "objectID": "src/theory/ML.html#함수로서의-기계학습",
    "href": "src/theory/ML.html#함수로서의-기계학습",
    "title": "기계 학습",
    "section": "함수로서의 기계학습",
    "text": "함수로서의 기계학습\n\n인공지능은 어떤 입력에 대한 출력을 하며 우리는 보통 이런 것을 수학적으로는 함수(function) 라고 부른다.\n기계학습에서의 학습이란 대량의 데이터를 입력하여 이 데이터를 가장 잘 표현하는 하나의 함수를 정하는 것이다. 하나의 데이터에 대해 보통 입력값이 여러개이므로 \\(i\\)-번째 데이터의 입력은 \\(\\boldsymbol{x}_i\\) 로 \\(i\\)-번째 데이터의 label 은 \\(y_i\\) 로 표기한다. 입력값과 레이블 의 쌍을 \\((\\boldsymbol{x}_i, y_i)\\) 로 표기한다.\n함수를 내부적으로 표현하는데 쓰는 값을 매개변수 (parameter) 라 한다. 예를 들어 \\[\ny=f(\\boldsymbol{x}=(x_1, x_2)) = ax_1+bx_2+c = \\begin{bmatrix} 1 & a & b \\end{bmatrix}\\begin{bmatrix} 1 \\\\ x_1 \\\\ x_2 \\end{bmatrix}\n\\] 일 경우, 입력값은 \\(\\boldsymbol{x}=\\begin{bmatrix}x_1 & x_2\\end{bmatrix}^T\\), 매개변수는 \\(a, b, c\\), 출력값은 \\(y\\) 이다.\n기계학습을 통해 매개변수를 정해야 함수가 완성된다. 매개변수의 집합을 \\(\\boldsymbol{w}\\) 로 표기하여 함수를 다음과 같이 쓰기도 한다. \\[\ny=f(\\boldsymbol{x} ; \\boldsymbol{w})\n\\]\n출력값이 벡터일 경우는 다음과 같이 쓰기도 한다.\n\n\\[\n\\boldsymbol{y} = \\boldsymbol{f}(\\boldsymbol{x};\\boldsymbol{w})\n\\]\n\n데이터와 레이블의 쌍의 집합을 데이터셋이라고 하고 \\(i\\) 번째 데이터를 \\((\\boldsymbol{x}^{(i)},\\, \\boldsymbol{t}^{(i)})\\) 과 같이 표기하자. 함수가 얼마나 데이터를 잘 기술하는지를 평가하는 함수를 손실함수(Loss function) 혹은 비용함수(Cost function) 라고 한다. 대표적인 손실함수로는 신경망(Neural Network) 에서, 회귀의 경우 평균제곱오차 (Mean Square Error, MSE) 함수 와 분류의 경우 교차 엔트로피 오차 (Cross Entropy Error, CEE) 함수가 있다.\n\\[\n\\begin{aligned}\n\\text{MSE}(\\boldsymbol{w}) &= \\dfrac{1}{2} \\sum_{i=1}^N \\|\\boldsymbol{t}^{(i)} - f(\\boldsymbol{x}^{(i)}; \\boldsymbol{w})\\|^2 \\\\[0.3em]\n\\text{CEE}(\\boldsymbol{w}) &= -\\sum_{i=1}^N t^{(i)} \\ln (f(\\boldsymbol{x}^{(i)};\\boldsymbol{w}))\\\\[0.3em]\n\\end{aligned}\n\\] 여기에 대한 정확한 설명은 뒤로 미루기로 하자.\n기계학습을 통해 오차함수를 최소화 하는 매개변수들을 찾아 함수를 완성한다.\n손실 함수(Loss Function) \\(L(\\boldsymbol{w})\\) 의 특징\n\n\\(L(\\boldsymbol{w}) ≥ 0\\)\n\\(L(\\boldsymbol{w})\\) 는 미분가능 함수\n최적의 경우 = \\(L(\\boldsymbol{w})\\) 가 최소값이 되는 경우\n따라서 기계학습에서 학습이란 \\(L(\\boldsymbol{w})\\) 가 최소값이 되도록 하는 \\(\\boldsymbol{w}\\) 를 찾는 것이다. (최적화 (optimization))",
    "crumbs": [
      "Home",
      "기계 학습"
    ]
  },
  {
    "objectID": "src/theory/ML.html#통계학의-기본",
    "href": "src/theory/ML.html#통계학의-기본",
    "title": "기계 학습",
    "section": "통계학의 기본",
    "text": "통계학의 기본\n\n\n기본 개념\n\n표본 공간 (sample space) \\(\\Omega\\) : 실험/측정에 있어서 가능한 모든 결과값의 집합. \\(\\Omega\\) 의 각 원소들은 각각이 식별 가능하며, 상호 배타적(동시에 발생할 수 없음) 이어야 한다. 특정 결과값 \\(\\omega\\) 는 \\(\\Omega\\) 의 원소이다.\n사건 공간 (evant space) \\(\\mathcal{A}\\) : 실험/측정의 잠재적인 결과의 집합. 당연히 표본 공간 \\(\\Omega\\) 의 부분집합.\n확률 (probability) : \\(A\\in \\mathcal{A}\\) 에 대해 \\(A\\) 의 사건이 발생할 확률을 \\(p(A)\\) 라고 한다. 임의의 \\(A\\in \\mathcal{A}\\) 에 대해 \\(0\\le p(A)\\le 1\\) 이며 \\(\\sum_{A\\in \\Omega} p(A)=1\\) 이다.\n표적 공간 (target space) \\(\\mathcal{T}\\) : 우리가 관심있는 정량화된 값. 서로 구별되는 표적공간의 원소를 상태(state) 라고 한다.\n확률 변수 (random variable) : 표본공간의 성분 \\(\\omega\\) 와 표적공간의 성분 \\(t\\) 를 연결하는 함수 \\(X:\\Omega \\to \\mathcal{T}\\) 가 존재하며 이 \\(X\\) 를 확률변수 라고 한다.\n\n예를 들어 두개의 동전을 던져 이중 몇개의 동전이 앞면이 나오는 지 관심있다고 하자. 앞면을 \\(u\\), 뒷면을 \\(d\\) 라고 하면 \\(\\Omega = \\mathcal{A} = \\{ uu,\\, ud,\\,du,\\,dd\\}\\) 이며 \\(\\mathcal{T}=\\{0,\\,1,\\,2\\}\\) 가 된다. 이제 사건공간이 아닌 표적공간의 부분집합에 대한 확률에 관심을 갖게 된다. 즉 \\(S\\in \\mathcal{T}\\) 에 대해 \\(p(S)\\) 가 우리의 주요 관심사이다.\n표적공간 \\(\\mathcal{T}\\) 가 이산공간일 때 \\(X\\) 를 이산확률변수라고 하고 \\(\\mathbb{R}\\) 과 같이 연속일 때 연속확률변수라고 한다.\n\n\n\n이산 확률\n\n결합 확률(Joint Probability)\n확률변수 \\(X,\\,Y\\) 에 대해 \\(X\\) 는 \\(x_1,\\ldots,\\,x_M\\) 값을 가질 수 있으며, \\(Y\\) 는 \\(y_1,\\ldots,\\,y_L\\) 값을 가질 수 있다고 하자. 모두 \\(N\\) 번의 시행에서 \\(X=x_i,\\, Y=y_j\\) 가 나온 횟수를 \\(n_{ij}\\) 라 하자. \\(N\\) 번의 시행에서 \\(X=x_i\\) 인 횟수는 \\(c_i\\), \\(Y=y_j\\) 인 횟수는 \\(r_j\\) 라 하자. 즉, \\[\np(X=x_i,\\, Y=y_j)=\\dfrac{n_{ij}}{N},\\quad p(X=x_i)=\\dfrac{c_i}{N},\\quad p(Y=y_j)=\\dfrac{r_j}{N}\\;.\n\\tag{1}\\]\n이다. 이 때,\n\\[\np(X=x_i)=\\sum_{j=1}^L p(X=x_i,\\, Y=y_j)\n\\tag{2}\\]\n이며 (자명하다) 이를 sum rule 이라 한다. 여기서 \\(P(X=x_i)\\) 를 개별 사건의 확률로 주변 확률(marginal probability) 라 하기도 한다.\n\n\n\n조건부 확률(Conditional probability)\n\\(X=x_i\\) 인 상황에서 \\(Y=y_j\\) 인 확률을 \\(p(Y=y_j \\mid X=x_i)\\) 라 쓰며 \\(X=x_i\\) 일 때 \\(Y=y_j\\) 에 대한 조건부 확률(conditional probability) 이라고 하고 다음과 같이 주어진다. \\[\np(Y=y_j\\mid X=x_i)=\\dfrac{n_{ij}}{c_i}\n\\tag{3}\\]\n\n\n\n확률의 곱의 법칙(Product rule of probability)\n\\[\np(X=x_i,\\, Y=y_j)=\\dfrac{n_{ij}}N=\\dfrac{n_{ij}}{c_i}\\dfrac{c_i}{N}=P(Y=y_j\\mid X=x_i)\\cdot p(X=x_i)\\;.\n\\tag{4}\\]\n\n\n\n합과 곱의 규칙\n\\[\n\\begin{aligned}\n\\textbf{sum rule}&\\qquad p(X)=\\sum_Y p(X,\\,Y)\\,, \\\\\n\\textbf{product rule}& \\qquad p(X,\\,Y)=p(Y\\mid X)p(X)\n\\end{aligned}\n\\tag{5}\\]\n\n\n\n베이즈 정리(Bayes’ theorem)\n\\[\np(Y\\mid X)=\\dfrac{p(X\\mid Y) \\, p(Y)}{p(X)}\\;.\n\\tag{6}\\]\nWith sum rule, \\[\nP(X)=\\sum_{Y}p(X \\mid Y)\\, p(Y)\\,.\n\\tag{7}\\]\n\n\n변수의 독립성(Independence of variable)\n확률변수 \\(X,\\,Y\\) 에 때해 \\(p(X,\\,Y)=p(X)\\, p(Y)\\) 일 때 \\(X\\) 와 \\(Y\\) 는 서로 독립적(independent) 이라고 한다. \\(X,\\,Y\\) 가 서로 독립적이면 식 식 5 으로 부터 \\(p(Y|X)=p(Y)\\) 임을 알 수 있다.\n\n\n\n\n확률 밀도 함수\n표적공간이 연속일 때 확률은 확률밀도함수 \\(p(x)\\) 로 기술된다.\n\n확률밀도함수와 확률\n확률밀도함수 \\(p(x)\\)는 다음 두 조건을 만족해야 한다. \\[\n\\begin{align}\np(x) & \\ge 0\\\\\n\\int_{-\\infty}^\\infty p(x)\\,dx &=1\n\\end{align}\n\\tag{8}\\]\n연속확률변수일 때 \\(x\\in (a,\\,b)\\) 일 확률 \\(p(x\\in (a,\\,b))\\) 는 \\[\np(x\\in (a,\\,b))=\\int_a^b p(x)\\,dx\n\\tag{9}\\] 이다.\n\n\n\n변수의 변환\n\\(x=g(y)\\) 이며 \\(y\\) 에 대한 확률분포를 알고 싶을 때, 이 확률분포를 \\(p_y(y)\\) 라 하면, \\[\np_y(y)=p(x)\\left|\\dfrac{dx}{dy}\\right|=p(g(y))|g'(y)\n\\tag{10}\\] 임을 쉽게 보일 수 있다.\n\n\n\n누적 분포 함수\n\\(P(z)=p(x\\in (-\\infty,\\,z))\\) 를 누적 분포 함수(cumulative distribution function) 이라 하며, \\[\nP(z) = \\int_{-\\infty}^z p(x)\\, dx\n\\tag{11}\\]\n로 정의된다. \\(P'(x)=p(x)\\) 임은 십게 알 수 있다.\n다변수 \\(\\boldsymbol{x}=(x_1,\\ldots,\\,x_D)\\) 에 대한 확률분포는 \\(\\boldsymbol{x}\\) 를 포함하는 infinitesimal volume \\(\\delta \\boldsymbol{x}\\) 에 대해 \\(p(\\boldsymbol{x})\\,\\delta \\boldsymbol{x}\\) 로 주어지며 다음과 같은 성질을 만족한다.\n\\[\n\\begin{aligned}\np(\\boldsymbol{x}) & \\ge 0  \\\\\n\\int p(\\boldsymbol{x})\\,d\\boldsymbol{x}&= 1\n\\end{aligned}\n\\tag{12}\\]\n연속적인 변수, 이산적인 변수 모두에 대한 확률 분포함수를 probability density function 이라 하기도 하고, 이산적인 변수에 대해서 probability mass function 이라고 구분하여 부르기도 한다.\nSum rule과 Bayes’ theorem 을 생각하면 다음이 성립함을 알 수 있다. \\[\n\\begin{aligned}\np(x) &= \\int p(x,\\,y)\\, dy \\\\\np(x,\\,y)&=p(y| x)\\,p(x)\n\\end{aligned}\n\\tag{13}\\]\n\n\n\n\n기댓값과 공분산\n\n기댓값\n확률변수 \\(X\\) 에 대한 확률분포가 \\(p(x)\\) 일 때 \\(x\\) 에 대한 함수 \\(f(x)\\) 의 평균값을 \\(f\\) 에 대한 기댓값(expectation) 이라 하며 \\(\\mathbb{E}[f]\\) 로 표기하고 다음과 같다. \\[\n\\begin{align}\n\\mathbb{E}[f]&:=\\sum_x p(x) f(x) &&\\text{for descrete distribution,}\\\\\n&:=\\int  p(x) f(x)\\, dx& &\\text{for continuous distribution.}\n\\end{align}\n\\tag{14}\\]\n\\(N\\) 개의 sample 이 주어졌을 때 기댓값은 다음과 같이 근사 될 수 있다. \\[\n\\mathbb{E}[f] \\approx \\dfrac{1}{N} \\sum_{i=1}^N f(x_n).\n\\tag{15}\\]\n식 14 의 두 식은 식 15 의 \\(N \\to \\infty\\) 극한과 동일하다.\n다변수 확률분포에서 특정 변수에 대한 기댓값은 \\(\\mathbb{E}_x [f(x,\\,y)]\\) 와 같이 표기하며 다음과 같다. \\[\n\\mathbb{E}_x [f(x,\\,y)]=\\sum_x p (x,\\,y) f(x,\\,y) =\\int p(x,\\,y) f(x,\\,y)\\, dx\n\\tag{16}\\]\n\n\n\n조건부 기댓값\n\\(p(x\\,|\\,y)\\) 에 대한 \\(f(x)\\) 의 기댓값은 다음과 같다. \\[\n\\mathbb{E}_x [f \\mid y\\,]= \\sum_x p(x\\,|\\, y)\\, f(x)\n\\tag{17}\\]\n\n\n\n분산\n\\(f(x)\\) 에 대한 분산(variance) \\(\\text{Var}[f]\\) 는 다음과 같이 정의된다. \\[\n\\begin{aligned}\n\\operatorname{Var}[f] & := \\mathbb{E}\\left[(f(x)-\\mathbb{E}[f(x)])^2\\right] \\\\[0.3em]\n&=\\mathbb{E}[f(x)^2]-(\\mathbb{E}[f(x)])^2\\;\n\\end{aligned}\n\\tag{18}\\]\n이다. 변수 \\(x\\) 자체에 대한 분산 \\(\\text{Var}[x]\\) 는 다음과 같다. \\[\n\\operatorname{Var}[x]=\\mathbb{E}[x^2]-\\mathbb{E}[x]^2.\n\\tag{19}\\]\n\n\n\n공분산\n아래와 같이 정의되는 \\(\\text{Cov}[x,\\,y]\\) 를 \\(X,\\,Y\\) 에 대한 공분산(covariance) 라고 한다. \\[\n\\begin{align}\n\\operatorname{Cov}[x,\\,y]&:= \\mathbb{E}_{x,\\,y} \\left[(x-\\mathbb{E}[x]) (y-\\mathbb{E}[y])\\right] \\\\\n&=\\mathbb{E}_{x,\\,y}[xy] -\\mathbb{E}[x] \\mathbb{E}[y].\n\\end{align}\n\\tag{20}\\]\n\\(x,\\,y\\) 가 서로 독립이면 \\(\\operatorname{Cov}[x,\\,y]=0\\) 이다.\n두 확률 변수가 벡터 \\(\\boldsymbol{x},\\, \\boldsymbol{y}\\) 이면 \\[\n\\begin{aligned}\n\\operatorname{Cov}[\\boldsymbol{x},\\, \\boldsymbol{y}]&= \\mathbb{E}_{\\boldsymbol{x},\\, \\boldsymbol{y}}\\left[\\left( \\boldsymbol{x}-\\mathbb{E}[\\boldsymbol{x}]\\right)\\left( \\boldsymbol{y}^T-\\mathbb{E}[\\boldsymbol{y}^T]\\right)\\right] \\\\[0.3em]\n&=\\mathbb{E}_{\\boldsymbol{x},\\,\\boldsymbol{y}}[\\boldsymbol{x}\\boldsymbol{y}^T]-\\mathbb{E}[\\boldsymbol{x}]\\,\\mathbb{E}[\\boldsymbol{y}^T]\n\\end{aligned}\n\\tag{21}\\]\n이다. \\(\\operatorname{Cov}[\\boldsymbol{x}] := \\operatorname{Cov}[\\boldsymbol{x},\\,\\boldsymbol{x}]\\) 로 정의한다.",
    "crumbs": [
      "Home",
      "기계 학습"
    ]
  },
  {
    "objectID": "src/theory/optimization.html",
    "href": "src/theory/optimization.html",
    "title": "2  최적화",
    "section": "",
    "text": "1 최적화",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>최적화</span>"
    ]
  },
  {
    "objectID": "src/theory/optimization.html#최적화",
    "href": "src/theory/optimization.html#최적화",
    "title": "2  최적화",
    "section": "",
    "text": "1.1 최적화문제\n일반적으로 최적화 문제는 어떤 함수 \\(f:U \\subset \\mathbb{R}^n \\to \\mathbb{R}\\) 에 대해 아래의 \\(\\boldsymbol{\\theta}^\\ast\\) 문제를 구하는 것으로 주어진다.\n\\[\n\\boxed{\n\\begin{aligned}\n\\quad& \\boldsymbol{\\theta}^\\ast = \\argmin_{\\boldsymbol{\\theta}\\in U} && f(\\boldsymbol{\\theta}) \\\\[0.3em]\n&\\text{subject to} \\quad && g_i(\\boldsymbol{\\theta})\\le 0,\\qquad i = 1,\\ldots,\\,m\\\\[0.3em]\n&&& h_j(\\boldsymbol{\\theta})= 0,\\qquad j=1,\\ldots,\\,k.\\quad\n\\end{aligned}\n}\n\\tag{1}\\]\n\n\n3가지 기본 요소\n (\\(1\\)) 변수 (Decesion variable or unknown) \\(\\boldsymbol{\\theta}\\in \\mathbb{R}^n\\)\n (\\(2\\)) 목적함수 (objective function) \\(f:\\mathbb{R}^n \\to \\mathbb{R}\\)\n (\\(3\\)) 제약 조건 (Constraint) : 식 1 에 주어진 \\(g_i(\\boldsymbol{\\theta}) \\le 0,\\, h_j(\\boldsymbol{\\theta})=0\\) 의 조건들.\n\n\n\n과정\n (\\(1\\)) 모델링 : 목적함수, 변수, 제약조건을 찾고 확인한다.\n (\\(2\\)) 모델을 만든 후 최적화 알고리즘을 사용하여 해를 구한다.\n\n\n\n\n1.2 최적화의 수학 모델\n\n수학적 표준 모델\n\n제약조건을 만족하는 \\(\\mathcal{C}\\subset \\mathbb{R}^n\\) 를 가능해 영역(feasible region) 이라고 한다. 식 1 과 같은 최적화 문제에 대해 \\(\\mathcal{C}\\) 는 아래와 같다. \\[\n\\mathcal{C} = \\{\\boldsymbol{\\theta}\\in U : g_i(\\boldsymbol{\\theta})\\le 0,\\,i=1,\\ldots,\\,m,\\, h_j(\\boldsymbol{\\theta})=0,\\, j=1,\\ldots,\\,k\\}.\n\\tag{2}\\]\n식 1 을 짧게 쓰면 가능해 영역 \\(\\mathcal{C}\\) 에 대해 \\(\\displaystyle \\boldsymbol{\\theta}^\\ast = \\argmin_{\\boldsymbol{\\theta}\\in \\mathcal{C}} f(\\boldsymbol{\\theta})\\) 를 찾는 문제이다. 이 \\(\\boldsymbol{\\theta}^\\ast\\) 를 최적해 (optimal solution) 이라고 한다.\n\\(\\{g_i\\}\\) 나 \\(\\{h_j\\}\\) 와 같은 제약조건이 없다면 unconstrained 라고 하며, 그렇지 않다면 constrained 라고 한다.\n\n\n\n\n등가 변환\n\n우리가 구하고자 하는 문제가 \\(f(\\boldsymbol{\\theta})\\) 를 최소화 하는 것이 아닌 최대로 하는 \\(\\boldsymbol{\\theta}\\) 를 찾는 문제라면 \\(-f(\\boldsymbol{\\theta})\\) 를 최소화 하는 문제이다.\nconstraint 가 \\(g_i(\\boldsymbol{\\theta}) \\ge 0\\) 이라면 \\(-g_i(\\boldsymbol{\\theta})\\le 0\\) 으로 바꿀 수 있다.\n즉 수학적 표준 모델은 상당히 표면적으로 보이는 것보다 훨씬 넓은 범위의 문제를 포괄한다.\n\n\n\n\n\n1.3 전역적 최적화와 국소적 최적화\n함수 \\(f(x)\\) 가 아래 그림과 같다고 하자.\n\n\n\n\n\n\n그림 1: 전역적 최소와 국소적 최소\n\n\n\n전체 영역에서의 최소점은 \\(x_G\\) 이며 이를 전역적 최소점(global minimum) 이라고 한다. 그리고 \\(x_L\\) 같이 어떤 근방에서의 최소점을 국소적 최소점(local minimum) 혹은 극소점 이라고 한다. 함수 \\(f(x)\\) 가 단 하나의 국소적 최소점을 갖는다는 보장이 없으며, 또한 많은 알고리즘은 전역적 최소점이 아닌 국소적 최소점을 찾는다. \\(f(x)\\) 가 두번 미분 가능할 경우 국소적 최소점은 보통 미분이 \\(0\\) 이고 이차미분이 양수인 점이다. 다변수의 경우 \\(\\nabla f(\\boldsymbol{\\theta})=\\boldsymbol{0}\\) 이며 헤시안 행렬 \\(\\boldsymbol{H}_f\\) 가 positive definite 한 경우이다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>최적화</span>"
    ]
  },
  {
    "objectID": "src/theory/optimization.html#볼록-최적화-convex-optimization",
    "href": "src/theory/optimization.html#볼록-최적화-convex-optimization",
    "title": "2  최적화",
    "section": "2 볼록 최적화 (Convex optimization)",
    "text": "2 볼록 최적화 (Convex optimization)\n\n2.1 볼록 함수와 볼록 집합\n\n\n\n\n\n\n\n정의 1 (볼록 함수 (convex function)) \\(f:\\mathbb{R}^n\\to\\mathbb{R}\\) 이 다음을 만족하면 볼록 함수라고 한다. \\[\n\\forall s\\in [0,\\,1],\\, \\boldsymbol{x},\\, \\boldsymbol{y}\\in \\mathbb{R}^n \\implies f(s \\boldsymbol{x}+(1-s)\\boldsymbol{y}) \\le s f(\\boldsymbol{x}) + (1-s)f(\\boldsymbol{y})\n\\tag{3}\\]\n\n\n정의 2 (볼록 집합 (convex set)) \\(A\\subset\\mathbb{R}^n\\) 이 다음을 만족하면 볼록 집합이라 한다.\n\\[\n\\forall s\\in [0,\\,1],\\, \\boldsymbol{x},\\, \\boldsymbol{y}\\in A \\implies s \\boldsymbol{x}+(1-s)\\boldsymbol{y}\\in A\n\\tag{4}\\]\n\n\n\n\n\n\n\n2.2 볼록 최적화\n식 1 의 최적화 문제가 주어졌다고 하자. 이 때 목적함수가 볼록 함수 이고 가능해 영역 이 볼록 집합인 경우의 최적화 문제를 볼록 최적화 (convex optimization) 문제 라고 한다.\n\n\\(g_i(\\boldsymbol{\\theta})\\) 가 볼록 함수이고 \\(h_j(\\boldsymbol{\\theta})=\\boldsymbol{a}^T\\boldsymbol{\\theta}+b\\) 꼴이면 항상 볼록 최적화 문제이다.\n볼록 최적화에서의 모든 국소적 해는 전역적 해이다. (정리 1)\n\n\n\n\n정리 1 볼록 최적화 문제에서 목적함수 \\(f:\\mathbb{R}^n \\to \\mathbb{R}\\) 과 가능해 공간 \\(\\mathcal{C}\\) 에 대해 국소적 최소점은 전역적 최소점이다.\n\n\n\n\n(증명). \\(\\boldsymbol{\\theta}^\\ast\\) 가 국소적 최소점이며 \\(\\boldsymbol{\\theta}_G \\ne \\boldsymbol{\\theta}^\\ast\\) 가 전역적 최소점이라고 하자. 즉 \\(f(\\boldsymbol{\\theta}_G)&lt;f(\\boldsymbol{\\theta}^\\ast)\\) 이다. \\(s\\in [0,\\,1]\\) 에 대해 \\(s\\boldsymbol{\\theta}^\\ast + (1-s)\\boldsymbol{\\theta}_G\\in \\mathcal{C}\\) 이며\n\\[\n\\begin{aligned}\nf(s \\boldsymbol{\\theta}^\\ast + (1-s)\\boldsymbol{\\theta}_G) &\\le s f(\\boldsymbol{\\theta}^\\ast) + (1-s)f(\\boldsymbol{\\theta}_G) \\\\[0.3em]\n& &lt; s f(\\boldsymbol{\\theta}^\\ast) + (1-s)f(\\boldsymbol{\\theta}^\\ast) = f(\\boldsymbol{\\theta}^\\ast)\n\\end{aligned}\n\\]\n이다. 즉 \\(f(\\boldsymbol{\\theta}^\\ast)\\) 가 국소적 해라는 전제에 모순이므로 국소적 해와 다른 전역적 해는 존재하지 않는다. \\(\\square\\)\n\n\n국소적 최저점이 전역적 최저점이라고 해서 단 하나의 국소적 최저점만 가질 필요는 없다. 여러개의 최적해가 존재할 때 다음의 성질을 갖는다.\n\n\n\n정리 2 볼록 최적화 문제의 해 가 하나 이상일 때 해의 집합을 \\(X\\) 라고 하자. 즉 \\(\\displaystyle X = \\argmin_{\\boldsymbol{\\theta}\\in \\mathcal{C}} f(\\boldsymbol{\\theta})\\) 라고 하면 \\(X\\) 는 볼록집합이다.\n\n\n\n\n(증명). \\(\\boldsymbol{\\theta}_1,\\, \\boldsymbol{\\theta}_2\\in X\\) 라고 하자. \\(\\mathcal{C}\\) 가 볼록집합이므로 \\(s\\in [0,\\,1]\\) 에 대해 \\(s \\boldsymbol{\\theta}_1 + (1-s)\\boldsymbol{\\theta}_2 \\in \\mathcal{C}\\) 이다. 또한 \\(\\boldsymbol{\\theta}_1,\\,\\boldsymbol{\\theta}_2\\) 가 전역적 최소점이므로 \\(f(\\boldsymbol{\\theta}_1)=f(\\boldsymbol{\\theta}_2)=f_m\\) 이다. 이로부터\n\\[\n\\begin{aligned}\nf(s \\boldsymbol{\\theta}_1 + (1-s)\\boldsymbol{\\theta}_2) & \\le s f(\\boldsymbol{\\theta}_1) + (1-s)f(\\boldsymbol{\\theta}_2) = f_m\n\\end{aligned}\n\\]\n그런데 \\(f(s \\boldsymbol{\\theta}_1 + (1-s)\\boldsymbol{\\theta}_2) \\ge f_m\\) 이어야 하므로 \\(f(s\\boldsymbol{\\theta}_1 + (1-s)\\boldsymbol{\\theta}_2) =f_m\\) 이다. \\(\\square\\)",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>최적화</span>"
    ]
  },
  {
    "objectID": "src/theory/optimization.html#선형계획법",
    "href": "src/theory/optimization.html#선형계획법",
    "title": "2  최적화",
    "section": "3 선형계획법",
    "text": "3 선형계획법\n일반적으로 선형계획법 문제는 다음과 같은 형태로 주어진다.\n\\[\n\\boxed{\n\\begin{aligned}\n\\quad \\boldsymbol{\\theta}^\\ast = \\argmin_{\\boldsymbol{\\theta}\\in U} f(\\boldsymbol{x}), \\quad &&f(\\boldsymbol{\\theta}) = \\boldsymbol{c}^T\\boldsymbol{\\theta} \\\\[0.3em]\n&&\\text{subject to} \\quad & \\boldsymbol{g}_i^T\\boldsymbol{\\theta}\\le b_j,\\qquad && i = 1,\\ldots,\\,m,\\\\[0.3em]\n&&& \\boldsymbol{h}_j^T\\boldsymbol{\\theta}= a_j,\\qquad &&j=1,\\ldots,\\,k.\\quad\n\\end{aligned}\n}\n\\tag{5}\\]\n\n즉 선형계획법에서는\n\n목적함수는 변수에 대한 선형함수이며\n제한조건은 변수에 대한 affine 함수 (\\(\\boldsymbol{a}^T\\boldsymbol{\\theta}+b\\) 형태의 함수) 이다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>최적화</span>"
    ]
  },
  {
    "objectID": "src/theory/optimization.html#unconstrained-convex-optimizaiton-문제",
    "href": "src/theory/optimization.html#unconstrained-convex-optimizaiton-문제",
    "title": "2  최적화",
    "section": "4 Unconstrained convex optimizaiton 문제",
    "text": "4 Unconstrained convex optimizaiton 문제\n\n\\(\\nabla_\\boldsymbol{\\theta}f(\\boldsymbol{\\theta}^\\ast)=\\boldsymbol{0}\\) 인 \\(\\boldsymbol{\\theta}^\\ast\\) 를 찾는 문제이다.\n\n\\[\n\\nabla_\\boldsymbol{\\theta} f := \\begin{bmatrix} \\dfrac{\\partial f}{\\partial \\theta_1} \\\\ \\vdots \\\\ \\dfrac{\\partial f}{\\partial \\theta_n}\\end{bmatrix}\n\\tag{6}\\]\n이와 유사하게\n\\[\n\\dfrac{df}{d\\boldsymbol{\\theta}} := \\begin{bmatrix} \\dfrac{\\partial f}{\\partial \\theta_1} & \\cdots & \\dfrac{\\partial f}{\\partial \\theta_n}\\end{bmatrix}\n\\tag{7}\\]\n로 정의한다. 즉 \\(\\nabla_{\\boldsymbol{\\theta}}f\\) 는 열벡터이며 \\(\\dfrac{d f}{d\\boldsymbol{\\theta}}\\) 는 행벡터이다.\n\n\n4.1 Gradient\n\\(\\boldsymbol{\\theta} = \\begin{bmatrix}\\theta_1 & \\cdots & \\theta_n \\end{bmatrix}^T \\in \\mathbb{R}^n\\), \\(\\boldsymbol{a} \\in \\mathbb{R}^n\\), \\(\\boldsymbol{A}=\\mathcal{M}_{m \\times n}(\\mathbb{R})\\) 일 때 \\(\\boldsymbol{\\theta}\\) 에 대한 스칼라 함수의 gradient 는 다음과 같다.\n\\[\n\\begin{aligned}\n\\nabla_\\boldsymbol{\\theta} (\\boldsymbol{a}^T\\boldsymbol{\\theta}) &= \\boldsymbol{a}\\\\[0.3em]\n\\nabla_\\boldsymbol{\\theta} (\\boldsymbol{\\theta}^T\\boldsymbol{a}) &= \\boldsymbol{a}\\\\[0.3em]\n\\nabla_\\boldsymbol{\\theta} (\\boldsymbol{\\theta}^T\\boldsymbol{\\theta}) &= 2\\boldsymbol{\\theta}\\\\[0.3em]\n\\nabla_{\\boldsymbol{\\theta}} (\\boldsymbol{\\theta}^T\\boldsymbol{A\\theta}) &= (\\boldsymbol{A}^T +\\boldsymbol{A})\\boldsymbol{\\theta}\n\\end{aligned}\n\\tag{8}\\]\n\n\n\n4.2 직접법\n\n\\(\\nabla_\\boldsymbol{\\theta}f(\\boldsymbol{\\theta}^\\ast)=\\boldsymbol{0}\\) 인 \\(\\boldsymbol{\\theta}^\\ast\\) 를 직접 구한다.\n\n\n이제 몇가지 형태의 convex 함수인 목적함수에 대한 그래디언트 \\(\\nabla_{\\boldsymbol{\\theta}}f(\\boldsymbol{\\theta})\\) 와 헤시안 행렬 \\(\\boldsymbol{H}_f\\) 를 구해보자.\n\n\n예제 1 (Affine 형태의 목적함수) \\(f(\\boldsymbol{\\theta}) = \\boldsymbol{a}^T\\boldsymbol{\\theta} + \\boldsymbol{b}\\) 인 경우\n\\[\n\\nabla_\\boldsymbol{\\theta}f(\\boldsymbol{\\theta})=\\boldsymbol{a},\\qquad \\boldsymbol{H}_f = \\boldsymbol{0}.\n\\]\n이다. 따라서 \\(\\boldsymbol{a}=\\boldsymbol{0}\\) 인 특별한 경우가 아니면 최소값이 존재하지 않는다.\n\n\n\n\n\n예제 2 (Quadratic 형태의 목적함수) 대칭행렬 \\(\\boldsymbol{P}\\) 에 대해 \\(f(\\boldsymbol{\\theta}) = \\boldsymbol{\\theta}^T\\boldsymbol{P\\theta} + \\boldsymbol{b}^T\\boldsymbol{\\theta}+c\\) 인 경우\n\\[\n\\nabla_{\\boldsymbol{\\theta}}f(\\boldsymbol{\\theta})= 2\\boldsymbol{P\\theta} + \\boldsymbol{b},\\qquad \\boldsymbol{H}_f = 2\\boldsymbol{P}\n\\]\n이다.\n\n\n\n\n\n예제 3 (제곱 형태의 목적함수) 대칭행렬 \\(\\boldsymbol{P}\\) 에 대해 \\(f(\\boldsymbol{\\theta}) = \\|\\boldsymbol{A\\theta}-\\boldsymbol{b}\\|_2^2\\) 인 경우\n\\[\nf(\\boldsymbol{\\theta})= \\boldsymbol{\\theta}^T\\boldsymbol{A}^T\\boldsymbol{A\\theta} - \\boldsymbol{\\theta}^T\\boldsymbol{A}^T\\boldsymbol{b}-\\boldsymbol{b}^T\\boldsymbol{A\\theta}+\\boldsymbol{b}^T\\boldsymbol{b}\n\\]\n이므로 gradient 와 헤시안 행렬은 다음과 같다.\n\\[\n\\nabla_{\\boldsymbol{\\theta}}f(\\boldsymbol{\\theta})= 2\\boldsymbol{A}^T\\boldsymbol{A\\theta} -2\\boldsymbol{A}^T\\boldsymbol{b},\\qquad \\boldsymbol{H}_f = 2\\boldsymbol{A}^T\\boldsymbol{A}.\n\\]\n이 때 \\(\\boldsymbol{\\theta}^\\ast = (\\boldsymbol{A}^T\\boldsymbol{A})^{-1}\\boldsymbol{A}^T\\boldsymbol{b}\\) 이어야 한다. 이 때 \\((\\boldsymbol{A}^T\\boldsymbol{A})^{-1}\\boldsymbol{A}^T\\) 는 잘 알려진 무어-펜로즈 좌측 유사역행렬(left pseudoinverse matrix) 이다.\n\n\n\n\n\n4.3 경사 하강법(Gradient descent)\n미분 가능한 \\(f(\\boldsymbol{\\theta})\\) 에 대해 \\(\\boldsymbol{\\theta}_0\\) 가 주어졌으며 충분히 작은 값 \\(\\alpha_k\\) 에 대해 \\(\\boldsymbol{\\theta}_{k+1}\\) 이 다음과 같다고 하자.\n\\[\n\\boldsymbol{\\theta}_{k+1} = \\boldsymbol{\\theta}_k -\\alpha_k \\nabla_\\boldsymbol{\\theta} f(\\boldsymbol{\\theta}_k)\n\\]\n그렇다면 \\(f(\\boldsymbol{\\theta}_{k+1}) &lt; f(\\boldsymbol{\\theta}_k)\\) 가 될 것이고 이것을 계속 반복해 나가면 \\(f(\\boldsymbol{\\theta})\\) 의 국소적 최저점을 찾을 수 있다. 이것을 경사 하강법(gradient descent method) 이라고 한다.\n\n\n\n4.4 뉴턴법\n\\(f:U \\subset \\mathbb{R}\\to R\\) 인 함수에 대해 \\(f(\\theta)=0\\) 을 찾는 방법 가운데 뉴턴-랩슨 방법은 초기값 \\(\\theta_0\\) 를 주고\n\\[\n\\theta_{k+1} = \\theta_k - \\dfrac{f(\\theta_k)}{f'(\\theta_k)}\n\\]\n를 통해 점진적으로 \\(f(\\theta)=0\\) 을 찾는 방법이다. 만약 \\(f\\in C_2\\) 라면 \\(f'(\\theta^\\ast)=0\\) 의 해는 뉴턴-랩슨 방법을 사용하여\n\\[\n\\theta_{k+1}=\\theta_k - \\dfrac{f'(\\theta_k)}{f''(\\theta_k)}\n\\]\n를 통해 얻을 수 있다. 만약 \\(f:\\mathbb{R}^n \\to \\mathbb{R}\\) 이\n\\[\nf(\\boldsymbol{\\theta}) = \\|\\boldsymbol{A\\theta}-\\boldsymbol{b}\\|_2^2\n\\]\n으로 주어졌다면 예제 3 로 부터\n\\[\n\\boldsymbol{\\theta}_{k+1}= \\boldsymbol{\\theta}_k - \\left(\\boldsymbol{H}_f\\right)^{-1} \\nabla_\\boldsymbol{\\theta} f(\\boldsymbol{\\theta}_k) = \\boldsymbol{\\theta}_k - (\\boldsymbol{A}^T\\boldsymbol{A})^{-1}\\boldsymbol{A}^T(\\boldsymbol{A}\\boldsymbol{\\theta}_k-\\boldsymbol{b})\n\\]\n를 이용하여 반복적으로 최적해 \\(\\boldsymbol{\\theta}^\\ast\\) 를 찾는다. 뉴턴법은 경사하강법에 비해 수렴속도가 빠르지만 1) 헤세 행렬 \\(\\boldsymbol{H}_f\\) 를 구해야 하며, 2) 헤세 행렬에 대한 역행렬도 구해야 한다. 이 둘 모두 큰 계산량을 요구한다.\n\n\n\n4.5 준-뉴턴법(Quasi-Newton method)\n뉴턴법의 큰 계산량을 줄이기 위해 고안된 방법이다. \\(f(\\boldsymbol{\\theta})\\) 를 2차 근사하면 헤세 행렬 \\(\\boldsymbol{H}_f\\) 에 대해 다음과 같다.\n\n\\[\nf(\\boldsymbol{\\theta} + \\Delta \\boldsymbol{\\theta}) \\approx f(\\boldsymbol{\\theta}) + \\dfrac{df(\\boldsymbol{\\theta})}{d\\boldsymbol{\\theta}} \\cdot \\Delta \\boldsymbol{\\theta} + \\dfrac{1}{2} \\Delta \\boldsymbol{\\theta}^T \\boldsymbol{H}_f\\Delta \\boldsymbol{\\theta}\n\\]\n뉴턴법에서는 최적해 \\(\\boldsymbol{\\theta}^\\ast\\) 에 대한 추정값 \\(\\boldsymbol{\\theta}_0\\) 을 입력하고 헤세 행렬을 직접 계산했지만 여기서는 \\(\\boldsymbol{\\theta}_0\\) 뿐만 아니라 헤세 행렬에 대한 추정값 \\(\\boldsymbol{B}_0\\) 도 입력하며 \\(\\boldsymbol{\\theta}_k\\) 뿐만 아니라 헤세 행렬에 상응하는 행렬 \\(\\boldsymbol{B}_k\\) 도 계속 업데이트 한다.\n\\[\n\\begin{aligned}\nf(\\boldsymbol{\\theta}_k + \\boldsymbol{\\epsilon}_k) &\\approx f(\\boldsymbol{\\theta}_k) + \\dfrac{df(\\boldsymbol{\\theta})}{d\\boldsymbol{\\theta}} \\cdot \\boldsymbol{\\epsilon}_k + \\dfrac{1}{2} (\\boldsymbol{\\epsilon}_k)^T\\cdot  \\boldsymbol{B}_k \\cdot ( \\boldsymbol{\\epsilon}_k) \\\\[0.3em]\n\\nabla_{\\boldsymbol{\\epsilon}_k} f(\\boldsymbol{\\theta}_k + \\boldsymbol{\\epsilon}_k) &\\approx  \\nabla_{\\boldsymbol{\\theta}}f(\\boldsymbol{\\theta}_k) + \\boldsymbol{B}_k\\boldsymbol{\\epsilon}_k\n\\end{aligned}\n\\]\n을 이용한다. 위의 식 가운데 두번째에서 \\(\\boldsymbol{\\theta}_k + \\boldsymbol{\\epsilon}_k\\) 가 극소점에 다가가면 \\(0\\) 에 가깝게 될 것이므로 \\(\\boldsymbol{\\epsilon}_k = - \\boldsymbol{B}_k^{-1}\\cdot \\nabla_{\\boldsymbol{\\theta}}f(\\boldsymbol{\\theta}_k)\\) 로 근사한다. 그렇다면\n\\[\n\\boldsymbol{\\theta}_{k+1} = \\boldsymbol{\\theta}_k +\\boldsymbol{\\epsilon}_k = \\boldsymbol{\\theta}_k -\\boldsymbol{B}_k^{-1} \\cdot \\nabla_{\\boldsymbol{\\theta}}f(\\boldsymbol{\\theta})\n\\]\n로 업데이트 한다. 이것은 뉴턴법과 차이가 없지만 준 뉴턴법은 \\(\\boldsymbol{B}_k\\) 를 구하는 방법에 따라 BFGS, DFP, SR1, Broyden 등의 여러가지 세부 방법이 있다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>최적화</span>"
    ]
  },
  {
    "objectID": "src/theory/optimization.html#등식-제약이-주어졌을-때",
    "href": "src/theory/optimization.html#등식-제약이-주어졌을-때",
    "title": "2  최적화",
    "section": "5 등식 제약이 주어졌을 때",
    "text": "5 등식 제약이 주어졌을 때\n\n5.1 라그랑주 승수법\n라그랑주 승수법은 다음과 같이 기술되는 문제에 사용된다. 즉 제한조건이 등식 형태로만 주어진 경우이다.\n\\[\n\\boxed{\n\\begin{aligned}\n\\quad&\\min_{\\boldsymbol{\\theta}} && f(\\boldsymbol{\\theta}) \\\\[0.3em]\n&\\text{subject to} \\quad && h_j(\\boldsymbol{\\theta})= 0,\\qquad j=1,\\ldots,\\,k.\\quad\n\\end{aligned}\n}\n\\tag{9}\\]\n아래의 정리는 잘 알려져 있다.\n\n\n\n정리 3 (라그랑주 승수법) \\(\\mathbb{R}^n\\) 에서의 열린 영역 \\(U\\) 에서 정의된 미분가능한 \\(f:U \\to \\mathbb{R}\\) 와 \\(C_1\\) 급 함수 \\(h_i : U \\to \\mathbb{R},\\, i=1,\\ldots,\\,M\\) 에 대해 가능해 영역 \\(\\mathcal{C}\\) 가 다음과 같이 \\(h_i(\\boldsymbol{\\theta})=0\\) 을 만족하는 형태로만 주어졌다고 하자.\n\\[\n\\mathcal{C} = \\{\\boldsymbol{\\theta}\\in U: \\boldsymbol{\\theta}\\in h_i(\\boldsymbol{\\theta})=0,\\, i=1,\\ldots,\\,M\\}\n\\]\n각각의 \\(\\boldsymbol{\\theta}\\in \\mathcal{C}\\) 에 대해 \\(\\nabla_{\\boldsymbol{\\theta}} h_1(\\boldsymbol{\\theta}),\\ldots,\\,\\nabla_{\\boldsymbol{\\theta}}h_M(\\boldsymbol{\\theta})\\) 가 선형 독립일 때 \\(f\\) 를 \\(\\mathcal{C}\\) 로 제한한 \\(f|_{\\mathcal{C}}\\) 의 극점 \\(\\boldsymbol{\\theta}^\\ast\\) 가 존재한다면\n\\[\n\\nabla_{\\boldsymbol{\\theta}}f(\\boldsymbol{\\theta}^\\ast) = \\sum_{i=1}^M \\lambda_i \\nabla_\\boldsymbol{\\theta}h_i(\\boldsymbol{\\theta}^\\ast)\n\\tag{10}\\]\n인 \\(\\lambda_i,\\, i=1,\\ldots,\\,M\\) 가 존재한다.\n\n\n\n목적함수 \\(f(\\boldsymbol{\\theta})\\) 에 대해 \\(h_i(\\boldsymbol{\\theta})=0,\\, (i=1,\\ldots,\\,M)\\) 의 제약조건이 주어졌다고 하자. 이 때 식 10 을 만족하는 \\(\\boldsymbol{\\theta}^\\ast\\) 는 가능해 영역 \\(\\mathcal{C}\\) 에서의 \\(f(\\boldsymbol{\\theta})\\) 의 stationary point 이다. 극소점일 수도, 극대점일 수도 saddle point 일 수도 있다.\n\n극소점인지 확인해야 한다.\n만약 \\(U\\) 의 경계를 포함하는 영역에서의 극소점을 찾는다면 경계에서의 값은 별도로 찾아서 비교해야 한다.\n\n\n\n\n5.2 KKH\n문제가 다음과 같이 주어졌다고 하자.\n\\[\n\\boxed{\n\\begin{aligned}\n\\quad&\\min_{\\boldsymbol{\\theta}} && f(\\boldsymbol{\\theta}) \\\\[0.3em]\n&\\text{subject to} \\quad && g_i(\\boldsymbol{\\theta})\\le 0,\\qquad i = 1,\\ldots,\\,m\\\\[0.3em]\n&&& h_j(\\boldsymbol{\\theta})= 0,\\qquad j=1,\\ldots,\\,k.\\quad\n\\end{aligned}\n}\n\\tag{11}\\]\nKKH 조건, 즉 Karush-Kuhn-Tucker conditions 는 \\(\\boldsymbol{\\theta}^\\ast\\) 의 필요조건의 나열이다.\n (\\(1\\)) \\(\\displaystyle \\nabla_{\\boldsymbol{\\theta}} f(\\boldsymbol{\\theta}) + \\sum_{i=1}^m \\lambda_i \\nabla_{\\boldsymbol{\\theta}}g_i(\\boldsymbol{\\theta}) + \\sum_{j=1}^k \\nabla_{\\boldsymbol{\\theta}} \\mu_j h_j(\\boldsymbol{\\theta})=0\\) 을 만족하는 \\(\\{\\lambda_i\\}\\) 와 \\(\\{\\mu_j\\}\\) 가 존재한다.\n (\\(2\\)) \\(\\mu_j h_j(\\boldsymbol{\\theta})\\) 이다. 즉 \\(\\mu_j\\) 와 \\(h_j(\\boldsymbol{\\theta})\\) 가운데 하나는 \\(0\\) 이다.\n (\\(3\\)) \\(j=1,\\ldots,\\,k\\) 에 대해 \\(\\mu_j\\ge 0\\) 이다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>최적화</span>"
    ]
  },
  {
    "objectID": "src/theory/regression.html",
    "href": "src/theory/regression.html",
    "title": "3  선형 회귀",
    "section": "",
    "text": "1 선형회귀",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>선형 회귀</span>"
    ]
  },
  {
    "objectID": "src/theory/regression.html#선형회귀",
    "href": "src/theory/regression.html#선형회귀",
    "title": "3  선형 회귀",
    "section": "",
    "text": "1.1 선형회귀와 설계행렬\n입력 \\(\\boldsymbol{x}^{(1)},\\ldots,\\,\\boldsymbol{x}^{(N)}\\in \\mathbb{R}^n\\) 과 이에 대한 레이블 \\(y^{(1)},\\ldots,\\,y^{(N)}\\) 을 데이터셋이라고 하자. 이 데이터셋을 기술하는 함수\n\\[\nf(\\boldsymbol{x};\\boldsymbol{\\theta})= \\begin{bmatrix} \\theta_1 & \\cdots & \\theta_n\\end{bmatrix}\\boldsymbol{x} + \\theta_0 = \\begin{bmatrix}\\theta_0 & \\theta_1 & \\cdots & \\theta_m\\end{bmatrix} \\begin{bmatrix} 1 \\\\ \\boldsymbol{x}\\end{bmatrix}\n\\]\n를 찾는 문제를 선형 회귀 (linear regression) 문제라고 한다.\n\n여기서 주의할 것은 \\(\\{\\boldsymbol{x}_i\\}\\) 에 대해 선형이기 때문에 선형 회귀가 아니라 \\(\\boldsymbol{\\theta}=  \\begin{bmatrix}\\theta_0 & \\theta_1 & \\cdots & \\theta_m\\end{bmatrix}\\) 에 대한 선형 함수이므로 선형 회귀이다.\n\n이제 \\(\\boldsymbol{x}^{(i)} \\in \\mathbb{R}^n\\) 의 \\(j\\) 번째 성분을 \\(\\boldsymbol{x}^{(i)}_j\\) 라고 표기하기로 하고 아래와 같이 행렬과 벡터를 정의한다.\n\\[\n\\boldsymbol{\\Phi}:= \\begin{bmatrix} 1 & \\boldsymbol{x}^{(1)}_1 & \\cdots & \\boldsymbol{x}^{(1)}_n \\\\ 1 & \\boldsymbol{x}^{(2)}_1 & \\cdots & \\boldsymbol{x}^{(2)}_n \\\\ \\vdots & & & \\vdots \\\\ 1 & \\boldsymbol{x}^{(N)}_1 & \\cdots & \\boldsymbol{x}^{(N)}_n  \\end{bmatrix}, \\qquad \\boldsymbol{\\theta} := \\begin{bmatrix} \\theta_0 \\\\ \\theta_1 \\\\ \\vdots \\\\ \\theta_n \\end{bmatrix},\\qquad \\boldsymbol{y} := \\begin{bmatrix} y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(N)} \\end{bmatrix}\n\\]\n이 때 \\(\\boldsymbol{\\Phi}\\) 를 설계 행렬(design matrix) 이라고 한다. 그리고\n\\[\n\\boldsymbol{e}:=\\boldsymbol{y}-\\boldsymbol{\\Phi \\theta}\n\\]\n라고 하면 \\(\\boldsymbol{e}\\in \\mathbb{R}^m\\) 의 \\(i\\) 번째 성분 \\(e_i = y_i - f(\\boldsymbol{x}_i;\\boldsymbol{\\theta})\\) 이다. 결국 선형 회귀 문제는 벡터 \\(\\boldsymbol{e}\\) 의 크기, 즉 노름을 최소화 하는 \\(\\boldsymbol{\\theta}^\\ast\\) 를 찾는 문제로 바뀌며 다음과 같이 기술 될 수 있다.\n\\[\n\\boldsymbol{\\theta}^\\ast = \\argmin_\\boldsymbol{\\theta} \\left\\|\\boldsymbol{y}- \\boldsymbol{\\Phi \\theta}\\right\\|\n\\tag{1}\\]\n노름 가운데 유클리드 노름, 즉 \\(L_2\\) 노름 혹은 \\(L_1\\) 노름을 사용한다. \\(L_p\\) 노름을 사용했을 경우 식 1 는 다음과 같이 표기된다.\n\\[\n\\boldsymbol{\\theta}^\\ast = \\argmin_\\boldsymbol{\\theta} \\left\\|\\boldsymbol{y}- \\boldsymbol{\\Phi \\theta}\\right\\|_p\n\\tag{2}\\]\n벡터 \\(\\boldsymbol{v}\\in \\mathbb{R}^k\\) 의 \\(L_p\\) 노름 \\(\\|\\boldsymbol{v}\\|_p\\) 는 다음과 같이 정의된다.\n\\[\n\\|\\boldsymbol{v}\\|_p := \\left(\\sum_{i=1}^k |v_i|^p\\right)^{1/p}\n\\]\n즉 \\(\\|\\boldsymbol{v}\\|_1 = \\sum |v_i|\\) 이며 \\(\\|\\boldsymbol{v}\\|_2 = \\displaystyle \\sqrt{\\sum_{i=1}^k |v_i|^2}\\) 는 유클리드 노름이다. \\(L_\\infty\\) 는 \\(p\\to \\infty\\) 극한으로 정의되며 \\(\\|\\boldsymbol{v}\\|_\\infty =\\displaystyle \\max_{i=1,\\ldots,\\,k} |v_k|\\) 이다. 만약 데이터 가운데 소위 튀는 데이터가 있다면 \\(L_\\infty\\) 노름이 가장 큰 영향을 받으며 \\(\\|\\boldsymbol{v}\\|_1\\) 노름이 가장 영향을 적게 받는다. 따라서 \\(L_\\infty\\) 노름은 거의 사용되지 않는다. \\(L_2\\) 노름의 경우\n\\[\n\\boldsymbol{\\theta}^\\ast = \\argmin_\\boldsymbol{\\theta} \\|\\boldsymbol{y}-\\boldsymbol{\\Phi\\theta}\\|_2^2\n\\tag{3}\\]\n이며 \\(\\argmin_\\boldsymbol{\\theta}\\|\\boldsymbol{y}-\\boldsymbol{\\Phi\\theta}\\|_2^2\\) 가 \\(\\sqrt{\\cdots}\\) 가 없어 미분 계산이 훨씬 간단해 지기 때문에 노름의 제곱을 많이 사용한다.\n\n\n\n1.2 학습/훈련과 예측\n우리가 이미 획득한 입력 벡터의 집합 \\(\\{\\boldsymbol{x}^{(i)}\\}\\) 와 레이블(label) \\(\\{y^{(i)}\\}\\) 로 이루어진 데이터셋 \\(\\{(\\boldsymbol{x}^{(i)},\\, y^{(i)})\\}\\), 그리고 데이터를 잘 설명할것이라고 기대되는 함수 \\(f(\\boldsymbol{x},\\,\\boldsymbol{\\theta})\\) 에 대해 식 1 의 \\(\\boldsymbol{\\theta}^\\ast\\) 를 얻는 것을 훈련 혹은 학습 이라고 한다. 이 \\(\\boldsymbol{\\theta}^\\ast\\) 에 대해 \\(\\boldsymbol{x}\\) 의 상황에서 \\(f(\\boldsymbol{x};\\boldsymbol{\\theta}^\\ast)\\) 의 값을 얻을것이라고 기대한다. 즉 우리는 주어진 데이터를 학습시켜 미지의 상황을 예측 할 수 있다. 이것은 비단 선형 회귀 뿐만 아니라 모든 통계학적 처리 및 기계학습의 과정에 공통된다.\n여기서 우리가 고려해야 할 상황이 있다. 이것은 항상 명심해야 한다.\n  Q1. 데이터는 편항되거나 오염되거나 부실하지 않은가?\n  Q2. \\(f(\\boldsymbol{x};\\boldsymbol{\\theta})\\) 의 선택은 합리적인가?\n  Q3. \\(\\boldsymbol{\\theta}^\\ast\\) 를 얻는 과정은 정확한가?\n\n\n\n1.3 최소제곱합\n식 3 은 보통 데이터와 모델값의 오차에 대한 제곱합 오차 함수 \\(E(\\boldsymbol{\\theta})\\) 이다.\n\\[\nE(\\boldsymbol{\\theta})=\\sum_{i=1}^m (y_i - f(\\boldsymbol{x}_i;\\boldsymbol{\\theta}))^2 = \\|\\boldsymbol{y}-\\boldsymbol{\\Phi \\theta}\\|_2^2.\n\\]\n이 때 \\(E(\\boldsymbol{\\theta})\\) 가 미분가능하다면 \\(E(\\boldsymbol{\\theta})\\) 를 최소로 하는 \\(\\boldsymbol{\\theta}^\\ast\\) 에 대해 \\(\\nabla_\\boldsymbol{\\theta} E(\\boldsymbol{\\theta}^\\ast)=\\boldsymbol{0}\\) 이어야 한다.\n\\[\n\\begin{aligned}\n\\nabla_\\boldsymbol{\\theta}E(\\boldsymbol{\\theta}) &= -2\\boldsymbol{\\Phi}^T \\boldsymbol{y}-2\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}\\boldsymbol{\\theta}^\\ast = \\boldsymbol{0}\n\\end{aligned}\n\\]\n이로부터\n\\[\n\\boldsymbol{\\theta}^\\ast = \\left(\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}\\right)^{-1}\\boldsymbol{\\Phi}^T \\boldsymbol{y}\n\\tag{4}\\]\n를 얻는다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>선형 회귀</span>"
    ]
  },
  {
    "objectID": "src/theory/regression.html#다양한-선형-회귀",
    "href": "src/theory/regression.html#다양한-선형-회귀",
    "title": "3  선형 회귀",
    "section": "2 다양한 선형 회귀",
    "text": "2 다양한 선형 회귀\n\n2.1 1차원 선형 회귀\n1차원 선형회귀에서 설계행렬 \\(\\boldsymbol{\\Phi}\\) 는 다음과 같다.\n\\[\n\\boldsymbol{\\Phi} = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\\\ 1 & x_n\\end{bmatrix}.\n\\]\n그리고\n\\[\n\\begin{aligned}\n\\boldsymbol{\\theta}=\\begin{bmatrix} \\theta_0 \\\\ \\theta_1 \\end{bmatrix},\n\\qquad \\boldsymbol{x} = \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n\\end{bmatrix}, \\qquad\n\\boldsymbol{y} = \\begin{bmatrix} y_1 \\\\ \\vdots \\\\ y_n\\end{bmatrix}\n\\end{aligned}\n\\]\n에 대해\n\\[\n\\theta^\\ast = \\begin{bmatrix} \\theta_1^\\ast \\\\ \\theta_2^\\ast\\end{bmatrix} = \\argmin_{\\boldsymbol{\\theta}} \\|\\boldsymbol{y} - \\boldsymbol{\\Phi \\theta}\\|^2\n\\]\n이다. \\(L_2\\) 노름의 경우 \\(\\boldsymbol{\\theta}^\\ast\\) 는 식 4 로 부터 다음과 같다는 것을 안다.\n\\[\n\\boldsymbol{\\theta}^\\ast = \\left(\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}\\right)^{-1}\\boldsymbol{\\Phi}^T \\boldsymbol{y}.\n\\]\n\n\n\n2.2 다항 회귀\n1 차원 변수 \\(x\\) 에 대한 다항식 \\(f(x;\\boldsymbol{\\theta}) = \\theta_0 + \\theta_1 x + \\cdots + \\theta_m x^m\\) 로 데이터를 설명한다고 하자. 우리는 \\(\\mathbb{R}\\) 에서 정의된 \\(\\{1,\\,x,\\,x^2,\\ldots,\\,x^m\\}\\) 이 선형독립임을 안다. 즉 다항회귀를 다차원 선형회귀로 간주 할 수 있다. 그렇다면 설계행렬 \\(\\boldsymbol{\\Phi}\\) 는 다음과 같다.\n\\[\n\\boldsymbol{\\Phi} = \\begin{bmatrix} 1 & x_1 & x_1^2 & \\cdots & x_1^m \\\\ 1 & x_2 & x_2^2 & \\cdots & x_2^m \\\\ \\vdots & & & &\\vdots \\\\ 1 & x_n & x_n^2 & \\cdots & x_n^m\\end{bmatrix}.\n\\]\n\\(L_2\\) 노름에 대해서라면 역시 \\(\\boldsymbol{\\theta}^\\ast = \\left(\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}\\right)^{-1}\\boldsymbol{\\Phi}^T \\boldsymbol{y}\\) 를 구하면 된다.\n\n아래 코드와 그림은 데이터를 3차 다항식으로 회귀시킨다.\nusing LinearAlgebra, CairoMakie,\n\nxs = 1:0.5:10\nf(x, p) = p[1]  + p[2] * x^1 +p[3] * x^2 + p[4] * x^3\np0 = [-9.0, 11.8, -3.0, 0.2]\nf(x) = f(x, p0)\nys = f.(xs) .+ 1.0*(rand(length(xs)) .- 0.5);\nΦ = [x^k for x in xs, k in 0:3]\nθ = inv(Φ'*Φ) * Φ' * ys\nf1(x) = f(x, θ)\n\n\n\n\n\n\n그림 1: 다항 회귀\n\n\n\n\n\n\n2.3 비선형 회귀\n다항회귀에서 예를 보였지만 우리가 맞추기를 원하는 함수가 굳이 선형함수가 아니어도 선형회귀를 쓸 수 있다. 실계수 다항식의 집합 \\(\\mathbb{R}[x]\\) 은 벡터공간이며 여기에서 \\(\\{1,\\,x,\\,x^2,\\ldots,\\,x^m\\}\\) 이 선형독립인것, 따라서 기저가 될 수 있다는 것을 알고 있다. 마찬가지로 선형 독립인 함수의 집합을 기저로 사용 할 수 있다.\n선형 독립인 기저함수를 \\(\\{\\phi_1,\\ldots,\\,\\phi_m\\}\\) 라고 하고 데이터 \\(\\{\\boldsymbol{x}_i\\},\\, \\{y_i\\}\\) 를 아래의 \\(f(\\boldsymbol{x};\\boldsymbol{\\theta})\\) 로 회귀시키고자 한다고 하자.\n\\[\nf(\\boldsymbol{x};\\boldsymbol{\\theta}) = \\theta_1\\phi_1(\\boldsymbol{x}) + \\cdots + \\theta_m \\phi_m (\\boldsymbol{x})\n\\]\n그렇다면 설계 행렬 \\(\\boldsymbol{\\Phi}\\) 는\n\\[\n\\boldsymbol{\\Phi} = \\begin{bmatrix}  \\phi_1(\\boldsymbol{x}_1) & \\cdots & \\phi_m(\\boldsymbol{x}_1) \\\\ \\phi_1(\\boldsymbol{x}_2) & \\cdots & \\phi_2(\\boldsymbol{x}_2) \\\\ \\vdots & & \\vdots \\\\  \\phi_m(\\boldsymbol{x}_1) & \\cdots & \\phi_m(\\boldsymbol{x}_1) \\end{bmatrix}\n\\]\n와 같고 역시 \\(L_2\\) 노름에 대해서라면 \\(\\boldsymbol{\\theta}^\\ast = \\left(\\boldsymbol{\\Phi}^T\\boldsymbol{\\Phi}\\right)^{-1}\\boldsymbol{\\Phi}^T \\boldsymbol{y}\\) 를 구한다.\n비선형 회귀에 사용되는 기저함수로는\n\n\n\n표 1: 비선형 회귀에 사용되는 기저 함수\n\n\n\n\n\n\n\n\n\n\n이름\n정의\n특징\n\n\n\n\n다항 함수\n\\(\\phi_j (x) = x^{j}\\)\n\n\n\n가우시안 기저 함수\n\\(\\phi_j (\\boldsymbol{x}) = \\exp \\left[- \\dfrac{\\|\\boldsymbol{x}-\\boldsymbol{\\mu}_j\\|^2}{2\\sigma^2}\\right]\\)\n소위 radial basis function(RBF)\n\n\n시그모이드 함수\n\\(\\phi_j(x) = \\dfrac{1}{1+\\exp (-(x-\\mu_j)/\\sigma)}\\)",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>선형 회귀</span>"
    ]
  },
  {
    "objectID": "src/theory/regression.html#reguralization",
    "href": "src/theory/regression.html#reguralization",
    "title": "3  선형 회귀",
    "section": "3 Reguralization",
    "text": "3 Reguralization\n\n\n\n\n\n\nReguralization 의 한글 번역\n\n\n\nReguralization 에 대한 한글 번역으로 정규화, 정칙화 등이 사용되지만 보통 정규화로 번역되는 normalization 와는 달리 reguralization 은 특정 값이 너무 커지지 않게 묶어 두는 역할을 하게 되며, 정규화나 정칙화의 글자 그대로의 의미와는 거리가 있다. 게다가 값 자체를 바꾸는 것이 아니고 값 자체의 크기를 제한하기 때문에 xx화 라는 이름을 붙이는 것도 어울리지 않는것처럼 보인다. (억제기가 어떨까?)\n\n\n\n\n3.1 Overfitting\n주어진 데이터 에 대한 2차, 4차, 5차, 9차 다항식에 대한 다항회귀의 결과는 아래와 같다.\n\n\n\n\n\n\n그림 2: 다항회귀\n\n\n\n데이터 자체가 그다지 규칙적이지 않다. 총 9개의 데이터가 있으며 우리는 주어진 데이터의 결과와 일치하는 다항식이 8차 이상에 서 존재한다는 것을 안다. 그러나 이렇게 얻은 8차 이상의 다항식이 주어진 변수 \\(\\{x_i\\}\\) 이외의 점에서 제대로 된 예측값을 내는것은 다른 문제이다. 예를 들어 위에서 얻은 8차 다항식에 의하면 \\(x=2\\) 에서의 예측값이 71.8 정도인데 실제 데이터가 -20 에서 20 사이에 존재한다는 것을 고려해보면 매우 튀는 결과이다.\n물론 이 데이터가 어떤 데이터냐에 따라 맞는 결과, 혹은 정답에 가까운 결과일 수도 있다. 문제는 실제로 이 데이터가 실제로 어떤 시스템에 대한 데이터냐이며, 만약 우리가 다루는 시스템에서 허용하지 않거나 아주 희박한 확률로 가능한 결과라면 여기서 얻은 8차 다항식은 시스템을 제대로 설명하는 모델이라고 할 수 없다.\n이렇게 주어진 데이터에는 잘 맞지만 이 데이터가 기술하는 시스템과는 동떨어진 모델을 만들어 내는 것을 과적합(overfitting) 이라고 한다. 과적합은 모델에서 결정해야 하는 매개변수의 갯수가 필요 이상으로 많아서, 즉 모델의 자유도가 지나치게 커서 발생한다.\n이것을 해결하기 위해 우선 생각할 수 있는 것은 매개변수의 갯수가 적은 모델을 선택하는 것이다. 또 하나의 방법은 매개변수의 절대값이 지나치게 커지는 것을 막는 것이다. 이 방법중 가장 유용한 방법이 다음에 소개할 정규화(reguralization) 이다.\n\n\n\n3.2 Reguralization\n우리는 매개변수의 최적값 \\(\\boldsymbol{\\theta}^\\ast\\) 를\n\\[\n\\boldsymbol{\\theta}^\\ast = \\argmin_{\\boldsymbol{\\theta}} \\|\\boldsymbol{y}-\\boldsymbol{\\Phi \\theta}\\|_2^2\n\\]\n로 정했다. 만약 적당햔 양수 \\(\\lambda&gt;0\\) 에 대해\n\\[\n\\boldsymbol{\\theta}^\\ast =   \\argmin_\\boldsymbol{\\theta} \\left(\\|\\boldsymbol{y}-\\boldsymbol{\\Phi \\theta}\\|_2^2 + \\lambda \\|\\boldsymbol{\\theta}\\| \\right)\n\\tag{5}\\]\n로 정하는 것이다. 식 5 의 \\(\\lambda \\|\\boldsymbol{\\theta}\\|\\) 는 \\(\\|\\boldsymbol{\\theta}\\|\\) 값이 큰 경우에서 \\(\\boldsymbol{\\theta}^\\ast\\) 가 결정되는 것을 방해한다. 뒤의 \\(\\lambda \\|\\boldsymbol{\\theta}\\|\\) 의 노름은 \\(L_1\\) 혹은 \\(L_2\\) 가운데 선택하며 앞의 \\(\\|\\boldsymbol{y}-\\boldsymbol{\\Phi \\theta}\\|\\) 의 노름과 같을 필요는 없다. \\(L_2\\) 노름의 경우를 Ridge regression 이라고 하고 \\(L_1\\) 노름의 경우는 LASSO (least absolute shrinkage and selection operator) 라고 한다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>선형 회귀</span>"
    ]
  },
  {
    "objectID": "src/theory/statistics.html",
    "href": "src/theory/statistics.html",
    "title": "4  통계학 이론",
    "section": "",
    "text": "1 베이지안 통계 (Bayesian Probabilities)\n지금까지 우리는 확률을 무작위성(randomness) 과 반복적인 사건(repeated events) 이라는 고전적(classica) 혹은 빈도적(frequencies) 이라고 불리는 관점에서 봤다. 이제 우리는 확률을 이용하여 불확실성을 정량화하는 Bayesian 관점을 학습할 것이다.\n커브 피팅 혹은 모델링을 생각하자. 즉 측정된 값 \\(\\mathcal{D}=\\{t_1,\\ldots,\\,t_n\\}\\) 을 통해 측정값을 가장 잘 기술하는 함수 \\(y(\\boldsymbol{x};\\,\\boldsymbol{w})\\) 를 결정한다고하자. 여기서 \\(\\boldsymbol{w}\\) 는 모델 매개변수이다. 빈도주의적 입장에서 \\(\\boldsymbol{w}\\) 는 확률이 아닌 우리가 알 내야 하는 값이 된다. 이에 대한 베이즈 정리는 다음과 같다. \\[\np(\\boldsymbol{w}\\,|\\, \\mathcal{D})=\\dfrac{p(\\mathcal{D}\\,|\\,\\boldsymbol{w}) \\cdot p(\\boldsymbol{w})}{p(\\mathcal{D})}.\n\\]\n여기서 \\(p(\\mathcal{D}\\,|\\,\\boldsymbol{w})\\) 를 가능도 혹은 우도 (likelihood function) 라고 하고 \\(p(\\boldsymbol{w})\\) 를 사전 확률 분포 (prior distribution) 라고 한다. \\(p(\\mathcal{D})\\) 는 정규화 상수(normalization constant) 이다. \\(p(\\mathcal{D})\\) 는 실험 결과에 따라 정해지는 확률이기 때문에 실험이 종료된 상황에서는 상수일 뿐이다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>통계학 이론</span>"
    ]
  },
  {
    "objectID": "src/theory/statistics.html#베이지안-통계-bayesian-probabilities",
    "href": "src/theory/statistics.html#베이지안-통계-bayesian-probabilities",
    "title": "4  통계학 이론",
    "section": "",
    "text": "고전적/빈도주의적 입장\n고전적 입장에서는 \\(p(\\boldsymbol{w})=1\\) 이다. 따라서 \\(p(\\boldsymbol{w}|\\mathcal{D})\\) 를 최대화 하는 것은 \\(p(\\mathcal{D}|\\boldsymbol{w})\\) 를 최대화 하는 것이다. 보통 기계학습에서 에러 함수 \\(L(\\boldsymbol{w})=-\\ln p(\\mathcal{D}|\\boldsymbol{w})\\) 이므로 에러 함수를 최소화 하는 것은 가능도를 최대로 하는 것과 동치이다.\n\n\n\n베이지언적 입장\n매개변수 \\(\\boldsymbol{w}\\) 는 고정된 값이 아닌 확률로 표현되는 값이다. 데이터를 보기 전에 \\(p(\\boldsymbol{w})\\) 에 대해 임시로 정한다. \\(\\mathcal{D}=\\{t_1,\\ldots,\\,t_N\\}\\) 는 \\(p(\\mathcal{D}\\,|\\,\\boldsymbol{w})\\) 에 반영된다.\n\n빈도주의적이든 베이즈적이든 \\(p(\\mathcal{D}|\\boldsymbol{w})\\) 가 중심적인 역할을 하지만 이에 대한 두 입장의 견해는 매우 다르다. 빈도주의 입장에서는 \\(\\boldsymbol{w}\\) 는 고정된 매개변수 이며 그 값과 에러는 \\(\\mathcal{D}\\) 의 분포를 고려하여 얻어진다. 그러나 베이즈주의적 입장에서는 유일한 \\(\\mathcal{D}\\) 가 존재하며 매개변수 \\(\\boldsymbol{w}\\) 가 확률 분포 \\(p(\\boldsymbol{w})\\) 로서 표현된다.\n널리 사용되는 빈도주의자들의 estimator는 최대 가능도 혹은 최대 우도 (maximum likelihood) 이다. 이 입장에서는 \\(p(\\boldsymbol{w})=1\\) 이므로 \\(p(\\mathcal{D}\\,|\\,\\boldsymbol{w})\\) 를 최대화하면 자연스럽게 \\(p(\\boldsymbol{w}\\,|\\,\\mathcal{D})\\) 가 최대화 된다. ML 에서는 \\(-\\ln p(D\\,|\\,\\boldsymbol{w})\\) 를 error function 이라 한다. 따라서 likelihood 를 최대화 하는것은 error function 을 최소화 하는 것이다.\n예를 들어 동전을 던졌을 때 앞면이 나올 확률을 \\(q\\) 라 하자. 세번의 동전을 던져 셋 다 앞면이 나왔을 때, 빈도주의적 접근에 의하면, Likelihood function 은 \\[\np(\\text{3 up}\\,|\\,q)=q^3\n\\] 이므로 \\(p(\\text{3 up}|q)\\) 를 최대화 하는 것은 \\(q=1\\) 이다. 이것은 매우 극단적인 결과이다.\n그런데 베이지언에서는 \\(\\boldsymbol{w}\\) 에 받아들일만 한 사전확률분포 \\(p(\\boldsymbol{w})\\) 을 부여하므로 덜 극단적인 결론에 도달할 수 있다.\n베이지언에 대한 가장 일반적인 비판중의 하나는 사전확률분포 \\(p(\\boldsymbol{w})\\) 를 선택할 때 수학적인 편리성이나 편견에 의해 결과가 왜곡 될 수 있다는 것이다. 이러한 주관성을 개선하기 위해 소위 non-informative priors 가 도입되기도 한다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>통계학 이론</span>"
    ]
  },
  {
    "objectID": "src/theory/statistics.html#the-gaussian-distribution-normal-distribution",
    "href": "src/theory/statistics.html#the-gaussian-distribution-normal-distribution",
    "title": "4  통계학 이론",
    "section": "2 The Gaussian Distribution (Normal Distribution)",
    "text": "2 The Gaussian Distribution (Normal Distribution)\n평균 (mean) \\(\\mu\\) 와 분산 \\(\\sigma^2\\) 에 대한 1차원 가우시안 분포 \\(\\mathcal{N}(x\\mid \\mu,\\,\\sigma^2)\\) 는 다음과 같다. \\[\n\\mathcal{N} (x\\mid \\mu,\\,\\sigma^2) = \\dfrac{1}{\\sigma \\sqrt{2\\pi }} \\exp \\left[-\\dfrac{(x-\\mu)^2}{2\\sigma^2}\\right]\n\\tag{1}\\]\n가우시안 분포 \\(\\mathcal{N}(x\\mid \\mu,\\,\\sigma^2)\\) 는 다음과 같은 성질을 갖는다.\n\\[\n\\begin{align}\n\\mathcal{N}&(x\\mid \\mu,\\,\\sigma^2)  \\ge 0\\,,\\\\\n\\int_{-\\infty}^\\infty &\\mathcal{N}(x\\mid \\mu,\\,\\sigma^2)\\, dx = 1,\\, \\\\\n\\mathbb{E}[x] &=\\int_{-\\infty}^\\infty x\\, \\mathcal{N}(x\\mid \\mu,\\,\\sigma^2)\\,dx=\\mu\\;, \\\\\n\\mathbb{E}[x^2] &= \\int_{-\\infty}^\\infty x^2 \\mathcal{N}(x\\mid \\mu,\\,\\sigma^2)\\,dx=\\mu^2+\\sigma^2\\;,\\\\\n\\operatorname{var}[f] &=\\mathbb{E}[x^2]-\\left(\\mathbb{E}[x]\\right)^2=\\sigma^2 \\;.\n\\end{align}\n\\tag{2}\\]\n\\(\\mathbb{R}^\\mathcal{D}\\) 에서 평균 \\(\\boldsymbol{\\mu}\\) 와 공분산 \\(\\boldsymbol{\\Sigma}\\) 를 갖는 가우스 분포는 다음과 같다.\n\\[\n\\mathcal{N}(\\boldsymbol{x}\\mid \\boldsymbol{\\mu},\\,\\boldsymbol{\\Sigma}) = \\dfrac{1}{(2\\pi)^{\\mathcal{D}/2}}\\dfrac{1}{\\left|\\boldsymbol{\\Sigma}\\right|^{1/2}} \\exp \\left[-\\dfrac{1}{2} (\\boldsymbol{x}-\\boldsymbol{\\mu})^T \\boldsymbol{\\Sigma} (\\boldsymbol{x}-\\boldsymbol{\\mu})\\right]\n\\tag{3}\\]\n\n\n2.1 1-변수 가우스분포에서의 \\(\\mu\\)와 \\(\\sigma^2\\) 의 추정 - 최대 가능도\n스칼라 변수 \\(x\\) 에 대해 \\(N\\) 번 측정한 것을 \\(\\boldsymbol{x}=\\begin{bmatrix}x_1 &\\ldots &x_N\\end{bmatrix}^T\\) 라 하자. 이 관측은 평균이 \\(\\mu\\) 이며 분산이 \\(\\sigma^2\\) 인 가우시안 분포를 따르는 변수에 대한 각각 독립적인 측정이라고 하자.\n우선 \\(N\\) 측정에서 \\(\\boldsymbol{x}\\) 가 관측될 확률은 \\[\np(\\boldsymbol{x}\\mid \\mu,\\,\\sigma^2)= \\prod_{n=1}^N \\mathcal{N}(x_n\\mid \\mu,\\,\\sigma^2)\n\\tag{4}\\]\n이며 likelihood function for the Gaussian (가우시안 가능도 함수)이라 불리운다.\n어쨋든, 식 4 의 우도함수를 최대화하는 \\(\\mu,\\,\\sigma^2\\) 를 정하자. 계산의 편의를 위해 로그함수를 사용한다. \\[\n\\ln p(\\boldsymbol{x}\\mid \\mu,\\,\\sigma^2)= - \\dfrac{1}{2\\sigma^2}\\sum_{n=1}^N (x_n-\\mu)^2-\\dfrac{N}{2} \\ln \\sigma^2 - \\dfrac{N}{2} \\ln 2\\pi\n\\]\n이 때 \\(p (\\boldsymbol{x}\\mid \\mu,\\,\\sigma^2)\\) 를 최대화 하는 \\(\\mu\\) 와 \\(\\sigma^2\\) 를 \\(\\mu_{ML},\\,\\sigma_{ML}^2\\) 라 할 때 다음과 같다.\n\\[\n\\begin{align}\n\\mu_{ML} &= \\dfrac{1}{N}\\sum_{n=1}^N x_n \\;,\\\\\n\\sigma_{ML}^2 &= \\dfrac{1}{N} \\sum_{n=1}^N (x_n-\\mu_{ML})^2\\;\n\\end{align}\n\\tag{5}\\]\n\n\n편항\n위와 같은 최대 가능도로부터 얻어진 분산은 원래 분포의 분산보다 작은데 하는데 이런 현상을 편향(bias)이라 한다. 표본의 평균과 분산의 기대값은 다음과 같다. \\[\n\\begin{align}\n\\mathbb{E}[\\mu_{ML}]& =\\mu \\\\\n\\mathbb{E}\\left[\\sigma_{ML}^2\\right] & =\\left(\\dfrac{N-1}{N}\\right)\\sigma^2.\n\\end{align}\n\\tag{6}\\]\n식 (1.58)에서 보듯이 \\(\\mathbb{E}\\left[\\sigma^2_{ML}\\right]&lt;\\sigma^2\\) 이다. 따라서 아래와 같이 정의된 \\(\\widetilde{\\sigma\\,}^2\\) 는 samples 로 부터 추정한 모집단의 분산과 같다. (즉 unbiased.) 이를 표본분산이라 한다. \\[\n\\widetilde{\\sigma\\,}^2 = \\dfrac{N}{N-1}\\sigma_{ML}^2 = \\dfrac{1}{N-1} \\sum_{n=1}^N\\left(x_n-\\mu_{ML}\\right)^2\n\\tag{7}\\]\n\\(N\\to \\infty\\) 일 때 \\(\\sigma_{ML}^2 \\to \\sigma^2\\) 임은 쉽게 알 수 있다. 실제로 \\(N\\) 이 작지만 않으면 큰 문제는 되지 않는다.\n\n\n\n\n2.2 Curve Fitting Revisited\n\\(N\\) 개의 입력 변수 \\(\\boldsymbol{x} = \\begin{bmatrix} x_1 &\\ldots & x_N \\end{bmatrix}^T\\) 와 표적값 \\(\\boldsymbol{t}=\\begin{bmatrix} t_1 &\\ldots &t_N\\end{bmatrix}^T\\) 사이에 다항식 \\(t=y(x;\\boldsymbol{w})=w_0 + w_1x+ \\cdots +w_nx^n\\) 의 관계를 가정한다. 표적값의 불확도를 확률분포로서 표현하자. 이를 위해 주어진 \\(x\\) 에 대해 표적값의 확률은 \\(y(\\boldsymbol{x},\\,\\boldsymbol{w})\\) 를 중심으로 분산이 \\(\\beta^{-1}\\) 인 가우시안분포를 따른다고 가정한다. 즉,\n\\[\np(t\\mid x,\\,\\boldsymbol{w},\\, \\beta)=\\mathcal{N}(t\\mid y(x,\\,\\boldsymbol{w}),\\,\\beta^{-1})\n\\tag{8}\\]\n이다.\n훈련 데이터 \\(\\{\\boldsymbol{x},\\,\\boldsymbol{t}\\}\\) 를 이용하여 미지의 매개변수 \\(\\boldsymbol{w}\\) 와 \\(\\beta\\) 를 결정하자. 그렇다면 가능도 함수는 다음과 같이 주어진다. \\[\np(\\boldsymbol{t}\\mid \\boldsymbol{x},\\,\\boldsymbol{w},\\,\\beta)=\\prod_{n=1}^N \\mathcal{N}(t_n\\mid y(x_n,\\, \\boldsymbol{w}),\\, \\beta^{-1}).\n\\tag{9}\\]\n앞서와 같이 \\(\\ln\\) 을 취하면\n\\[\n\\ln p(\\boldsymbol{t}\\mid \\boldsymbol{x},\\, \\boldsymbol{w},\\,\\beta)= -\\dfrac{\\beta}{2} \\sum_{n=1}^N \\left[y(x_n,\\,\\boldsymbol{w})-t_n\\right]^2+\\dfrac{N}{2} \\ln \\beta - \\dfrac{N}{2} \\ln (2\\pi)\n\\tag{10}\\]\n이 된다.\n\n식 10 로부터 고정된 \\(\\beta\\) 에 대해 \\(p(\\boldsymbol{t}\\mid \\boldsymbol{x},\\, \\boldsymbol{w},\\,\\beta)\\) 를 최대화 하는 것과 \\(\\displaystyle \\dfrac{1}{2}\\sum_{n=1}^N \\left[ y(x_n,\\,\\boldsymbol{w})-t_n\\right]^2\\) 를 최소화하는 것, 즉 제곱합 오차를 최소화 하는것은 동치라는 것을 알 수 있다. 이 \\(\\boldsymbol{w}\\) 를 \\(\\boldsymbol{w}_{ML}\\)이라 하자.\n또한 \\(\\beta\\) 에 대해 미분하여 \\(p\\) 를 최대화 하는 \\(\\beta\\) 를 찾아 \\(\\beta_{ML}\\) 이라 하면, \\[\n\\dfrac{1}{\\beta_{ML}}=\\dfrac{1}{N}\\sum_{n=1}^N \\left[ y(x_n,\\, \\boldsymbol{w}_{ML})-t_n\\right]^2\n\\tag{11}\\]\n이다. \\(\\beta\\) 역시 \\(\\boldsymbol{w}_{ML}\\) 이 결정된 상황에서 제곱합 오차를 최소화 할 때 확률을 최대화 하도록 결정된다.\n\n이제 우리는 주어진 데이터로부터 가장 잘 예측할 수 있는 확률 분포를 다음과 갇이 얻는다.\n\\[\np(t\\mid x,\\,\\boldsymbol{w}_{ML},\\, \\beta_{ML})=\\mathcal{N}(t\\mid  y(x,\\,\\boldsymbol{w}_{ML}),\\,\\beta_{ML}^{-1})\n\\tag{12}\\]\n\n\n베이즈 통계를 위한 공식\n\\[\n\\begin{align}\np(a|x)&=\\sum_y p(a| x,\\,y)\\, p(y| x)  \\tag{B1} \\\\\np(a|x,\\,y) &= \\dfrac{p(x|a,\\,y)\\, p(a|y)} {p(y|x)}  \\tag{B2}\n\\end{align}\n\\]\n\n\n(증명). (\\(B1\\)) \\[\n\\begin{aligned}\n\\sum_y p (a\\,|\\, x,\\,y)\\, p(y\\mid x)&=\\sum_y \\dfrac{p(a,\\,x,\\,y)}{p(x,y)} \\cdot \\dfrac{p(x,\\,y)}{p(x)} =\\sum_y \\dfrac{p(a,\\,x,\\,y)}{p(x)} \\\\\n&=\\dfrac{1}{p(x)}\\sum_{y}p(a,\\,x,\\,y) = \\dfrac{p(a,\\,x)}{p(x)} \\\\\n&=p(a|x)\n\\end{aligned}\n\\]\n(\\(B2\\)) \\[\n\\begin{aligned}\n\\dfrac{p(x|a,\\,y)\\, p(a|y)}{p(y|x)} &= \\dfrac{p(a,\\,x,\\,y)}{p(a,\\,y)} \\cdot \\dfrac{p(a,\\,y)}{p(y)} \\cdot \\dfrac{p(y)}{p(x,\\,y)}=\\dfrac{p(a,\\,x,\\,y)}{p(x,\\,y)}=p(a|x,\\,y)\n\\end{aligned}\n\\]\n\n\n\n이제 Bayesian 접근법을 좀 알아보자. 즉 \\(\\boldsymbol{w}\\) 에 대한 사전 분포 \\(p(\\boldsymbol{w})\\) 에 대한 것이다. \\(\\boldsymbol{w}\\) 가 아래와 같은 분포를 따른다고 하자.\n\\[\np(\\boldsymbol{w}|\\alpha)=\\mathcal{N}(\\boldsymbol{w}|\\boldsymbol{0},\\,\\alpha^{-1}\\boldsymbol{1}_{M+1})=\\left(\\dfrac{\\alpha}{2\\pi}\\right)^{(M+1)/2} \\exp \\left(-\\dfrac{\\alpha}{2}\\boldsymbol{w}^T \\boldsymbol{w}\\right)\n\\tag{13}\\]\n여기서 \\(M\\) 은 다항식의 차수이며 이며 따라서 \\(\\boldsymbol{w}\\) 는 \\(M+1\\) 개의 성분을 가진다. \\(\\alpha\\) 와 같이 모델 파라메터의 분포를 제어하는 변수를 초매개변수(hyperparameters) 라 한다.\n베이즈 정리로 부터, \\[\n[\\boldsymbol{w} \\text{ 에 대한 사후 확률}] \\propto [\\text{가능도}]\\times[\\boldsymbol{w}\\text{ 의 사전 확률 분포}]\n\\]\n임을 알고 있으므로,\n\\[\np(\\boldsymbol{w}\\,|\\,\\boldsymbol{x},\\,\\boldsymbol{t},\\,\\alpha,\\,\\beta) \\propto p(\\boldsymbol{t}\\,|\\,\\boldsymbol{x},\\,\\boldsymbol{w},\\,\\beta)\\cdot p(\\boldsymbol{w}\\,|\\,\\alpha)\n\\tag{14}\\]\n이다. 식 14 에 \\(-\\ln\\) 을 취하고 식 10, 식 12 를 대입하면, 사후확률을 극대화 하는 \\(\\boldsymbol{w}\\) 는 다음 식을 최소화 하는 것 \\(\\boldsymbol{w}\\) 이다.\n\\[\n\\dfrac{\\beta}{2}\\sum_{n=1}^N \\{y(x_n,\\,\\boldsymbol{w})-t_n\\}^2+\\dfrac{\\alpha}{2} \\boldsymbol{w}^T \\boldsymbol{w}.\n\\tag{15}\\]\n즉 베이지안에서 사후확률분포를 최대화하는 것은 정규화된 제곱합 오차 함수를 최소화 하는 것과 동등하다.\n\n\n\n2.3 Bayesian Curve Fitting\n앞서 우리는 사전확률분포 \\(p(\\boldsymbol{w}|\\alpha)\\) 에 대한 추정을 포함시켰지만, \\(\\boldsymbol{w}\\) 에 대한 point estimate 이므로 이것은 제대로 된 베이지안 처리가 아니다. 제대로 된 베이지언 처리는 확률에 대한 합과 곱의 규칙들을 일관되게 적용해야 하며, 이는 \\(\\boldsymbol{w}\\) 에 대한 모든 값에 대해 적분해야 함을 의미한다. 이러한 marginalizations 가 패턴 인식에서의 베이지언 방법의 핵심이다.\n\n일단 \\(\\alpha,\\,\\beta\\) 를 고정시키고 (편의를 위해 식에서는 일단 빼자.), test set \\(\\{\\boldsymbol{x},\\,\\boldsymbol{t}\\}\\) 만을 생각하자. 베이지안 방법은\n\\[\np(t\\,|\\,x,\\,\\mathbf{x},\\,\\mathbf{t})=\\int p(t\\mid x,\\,\\mathbf{w})\\, p(\\mathbf{w}\\mid\\mathbf{x},\\,\\mathbf{t})\\,d\\mathbf{w}\n\\tag{16}\\]\n을 생각한다. 여기서 \\(p(t\\mid x,\\,\\boldsymbol{w})\\) 는 식 식 8 에 나와 있으며 \\(p(\\boldsymbol{w}\\mid \\boldsymbol{x},\\,\\boldsymbol{t})\\) 는 사후확률분포이다. (식 14 을 보라.)\n뒤에 보겠지만, curve fitting example 과 같은 문제에서 이 사후확률분포 은 Gaussian 이며 해석적으로 계산 할 수 있다. 비슷하게 식 16 도 해석적으로 적분될 수 있으며 그 결과는 아래와 같은 가우시한 형태로 주어진다.\n\\[\np(t\\mid x,\\,\\boldsymbol{x},\\,\\boldsymbol{t}) =\\mathcal{N}(t\\mid m(x),\\, s^2(x))\n\\]\n여기서 평균 \\(m(x)\\) 와 분산 \\(s^2(x)\\) 는 다음과 같다. \\[\n\\begin{aligned}\nm(x) &=\\beta \\phi(x)^T \\boldsymbol{S} \\sum_{n=1}^N \\boldsymbol{\\phi} (x_n) t_n\\\\\ns^2(x) &=\\beta^{-1}+ \\boldsymbol{\\phi}(x)^T\\boldsymbol{S}\\boldsymbol{\\phi}(x) \\\\\n\\end{aligned}\n\\]\n여기서 행렬 \\(\\boldsymbol{S}\\) 는 다음과 같고 \\(\\boldsymbol{\\phi}(x) = \\begin{bmatrix} x^0 & \\cdots & x^M\\end{bmatrix}^T\\) 이다.\n\\[\n\\begin{align}\n\\boldsymbol{S}^{-1} &= \\alpha \\boldsymbol{I} + \\beta \\sum_{n=1}^N \\boldsymbol{\\phi}(x_n) \\boldsymbol{\\phi}(x_n)^T\n\\end{align}\n\\]",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>통계학 이론</span>"
    ]
  },
  {
    "objectID": "src/theory/statistics.html#model-selection",
    "href": "src/theory/statistics.html#model-selection",
    "title": "4  통계학 이론",
    "section": "3 Model Selection",
    "text": "3 Model Selection\n\n최소자승법을 이용한 Polynomial curve fitting 에서 보았듯이 best generalization을 주는 최적의 다항식의 order \\(M\\) 이 존재한다. 다항식의 order는 모델에서 free parameters의 갯수를 제어한다. Regularization 을 사용하면 regularization coefficient \\(\\lambda\\) 는 모델의 유효 복잡도(effiective complexcity) 를 통제한다.\n실제 응용에서 우리는 이러한 parameters 들을 결정해야 하며 이렇게 하는 주요 목적은 새로운 데이터에 대한 최소의 predictive performance를 얻기 위함이다. 또한 이렇게 complexicity parameters 에 대한 적당한 값을 찾는 것 뿐만 아니라, 특정 목표에 적합한 모델을 찾기 위해 다양한 모델을 고려할 필요가 있다.\nMLA (maximum likelihood approach) 에서 보았듯이 training set 에 대한 performance 가 다른 데이터에 대한 예측력을 보장해주지 않는다. (overfitting). 만약 데이터가 많다면 가용한 데이터중 일부를 다양한 모델을 학습시키거나, 주어진 모델에 대해 complexicity parameters 를 다양한 범위에서 학습시키는데 사용하고 이것을 독립적인 데이터를 사용하여 predictive performance를 비교하여 수 도 있다. 이렇게 학습데이터와 독립적으로 사용되는 데이터를 validation set 이라 한다. 이렇게 수차례 반복한 다음에 test set 이라 불리는 별도의 독립적인 데이터를 사용하여 최종적으로 평가할 수도 있다.\n보통은 training과 testing에 사용될 수 있는 데이터가 부족한데, 이 경우 좋은 모델을 만들기 위해 training에 가능한 많은 데이터를 사용하고자 할 수 있다. 그러나 만약 validation set이 부족하면 it will give a relatively noisy estimate of predictive performance. 이 딜레마에 대한 해결방법중 하나로 cross validation 방법이 있다.\n\n\nCross Validation\n\n전체 데이터를 \\(S\\) 개의 group으로 나눈다. \\(S\\) 개의 training group 으로 각 training group 마다 \\(S-1\\) 개의 데이터 그룹을 training set으로 나머지 하나를 validation set으로 사용한다.\nTraining group 마다 각자의 모델 (혹은 별도의 parameters set) 을 사용하므로 computationally expensive 하다. 또한 하나의 모델에 대한 다수의 complexcity parameter 를 갖게 될 수 있다. 이런 조합들을 탐색하다보면 최악의 경우 training run 이 parameter 갯수의 지수승으로 증가할수도 있다.!!!\n우리는 더 좋은 접근법을 사용해야 한다. 이상적으로 이 접근법은 training data 에 의존해야 하며, 한번의 training run을 통해 비교 할 수 있는 다수의 hyperparameters와 model types 를 허용해야 하는데….\n이를 위해 training data 에만 의존하며 over fitting에 의한 bias로부터 자유로운 성능 척도를 찾아야 한다.\n역사적으로 복잡한 모델에서의 over fitting을 보상하는 penalty term을 추가함으로서 maximum likelihood의 bais를 교정하고자 하는 다양한 ‘information criteria’ 가 제안되었다. 예를 들어 Akaike information criterion (AIC) 의 경우 \\[\n\\ln p(\\mathcal{D}\\mid \\boldsymbol{w}_{ML})-M\n\\] 을 최대화 하는 모델을 선택한다. 여기서 \\(p(\\mathcal{D}\\mid \\boldsymbol{w}_{ML})\\) 은 best-fit log likelihood 이며 \\(M\\) 은 모델에서 adjustable 한 parameter의 갯수이다. 이의 변형으로서 Bayesian information criterion 이 있는데 이는 section 4.4.1 에서 소개될 것이다. 이러한 criteria는 model parameter의 불확실성을 고려하지 않으며, 실제적으로는 과하게 간단한 모델을 선호한다.\n따라서 우리는 section 3.4 에서 fully Bayesian approach 로 전환할 것이며 이러한 complexity penalty 가 자연스럽고 원칙적인 방법으로 발생하는지 볼 것이다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>통계학 이론</span>"
    ]
  },
  {
    "objectID": "src/theory/statistics.html#차원의-저주",
    "href": "src/theory/statistics.html#차원의-저주",
    "title": "4  통계학 이론",
    "section": "4 차원의 저주",
    "text": "4 차원의 저주\n\n우리가 다루고자 하는 입력 데이터가 고차원의 데이터 (\\(\\mathcal{D}-\\dim\\))라고 가정해보자. 다항식 근사에서 order \\(3\\) 까지 전개하면 다음과 같다.\n\\[\ny(\\boldsymbol{x},\\,\\boldsymbol{w})=w_0+\\sum_{i=1}^\\mathcal{D} w_i x_i + \\sum_{i=1}^\\mathcal{D}\\sum_{j=1}^\\mathcal{D} w_{ij}x_ix_j + \\sum_{i=1}^\\mathcal{D}\\sum_{j=1}^\\mathcal{D} \\sum_{k=1}^\\mathcal{D} w_{ijk}x_i x_j x_k\n\\tag{17}\\]\n\\(\\mathcal{D}\\) 에 따라 3차항의 계수의 갯수는 \\(\\mathcal{D}^3\\) 개 만큼 증가하는 것처럼 보인다.(실제로는 interchange symmetry 로 인해 이것보다는 작지만 그래도 \\(\\mathcal{D}\\gg M\\) 일 경우는 \\(\\mathcal{D}^M\\) 와 같이 증가한다. (@Bishop2006 exercise 1.16) 이것도 아주 급격하게 증가하는 것이다. )\n\\({D}\\) 차원의 구를 생각하자. \\({D}\\) 가 커질수록 구의 대부분의 부피는 표면에 분포한다. \\({D}\\) 차원에서 반경 \\(r\\) 인 구의 부피 \\(V_D(r)=K_D r^D\\) 이다 여기에 작은 \\(0&lt;\\epsilon\\ll 1\\) 을 생각하면 구 표면의 두께 \\(\\epsilon\\) 만큼의 껍질의 부피와 \\(D\\) 차원에서의 unit sphere 의 부피의 비는, \\[\n\\dfrac{V_D(1)-V_D(1-r)}{V_D(1)}=1-(1-\\epsilon)^D\n\\] 임을 안다. \\({D}\\) 가 커질 수록 작은 \\(\\epsilon\\) 에서의 값이 크다.\n\\(D\\) 차원 가우시안 분포에서 이 데이터를 polar coordinate 로 바꾸어 보자. 차원이 늘어날수록 \\(p(r)\\) 에서 가장 높은 확률을 가진 값이 점점 커진다. 이는 고차원 구에서 대부분의 부피가 spherical shell에 위치한다는 앞의 논리와 상응한다.\n차원의 저주는 저차원에서의 직관이 고차원에서도 통용되지 않는 경우가 많음을 의미한다. 이 차원의 저주는 패턴 인식의 응용에 있어서 중요한 문제를 제기하지만 고차원을 다루는 효율적인 테크닉이 부족하거나 없다는 것을 의미하지는 않는다.\n\n고차원의 데이터라도 실제로는 보다 낮은 차원의 특정 영역에 데이터가 제한되어 있는 경우가 흔하며,\n실제 데이터는 전형적으로 어떤 smoothness properties 를 (최소한 국소적으로라도) 가지고 있는 경우가 많다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>통계학 이론</span>"
    ]
  },
  {
    "objectID": "src/theory/classification.html",
    "href": "src/theory/classification.html",
    "title": "5  퍼셉트론과 분류",
    "section": "",
    "text": "기하학\n분류 문제를 다루는데 SVM 등은 \\(n\\) 차원 공간 \\(\\mathcal{M}_n(\\mathbb{R})\\) 에서의 기하학을 이용한다.\n초평면 (hyperplane)\n정해진 벡터 \\(\\boldsymbol{w} \\in \\mathcal{M}_n(\\mathbb{R}) = V\\) 와 \\(n\\) 차원 변수 \\(\\boldsymbol{x}\\) 에 대해 \\(\\boldsymbol{w}^T\\boldsymbol{x}+c=0\\) 를 만족하는 \\(\\boldsymbol{x}\\) 의 집합은 \\(n-1\\) 차원 부분공간이며 이를 \\(V\\) 에 대한 초평면이라고 한다.\n\\[\n0 = \\boldsymbol{\\omega}^T \\boldsymbol{x} + c = \\boldsymbol{\\omega}^T \\left( \\boldsymbol{x} + \\dfrac{c\\boldsymbol{\\omega}}{\\|\\omega\\|^2}\\right)\n\\]\n이므로 원점과 평면사이의 거리 \\(d=\\dfrac{c}{\\|\\boldsymbol{\\omega}\\|}\\) 이다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>퍼셉트론과 분류</span>"
    ]
  },
  {
    "objectID": "src/theory/classification.html#분류-문제",
    "href": "src/theory/classification.html#분류-문제",
    "title": "5  퍼셉트론과 분류",
    "section": "1 분류 문제",
    "text": "1 분류 문제\n\n1.1 개요\n분류(classification) 문제는 표적값(target) 이 유한개인 문제이다. 표적값에 따라 입력 벡터를 구별할 수 있으며, 이렇게 구별되는 입력 벡터의 집합을 클래스(class) 라고 하고 각 클래스를 분리하는 경계를 결정 경계(decision boundary) 혹은 결정 표면(decision surface) 이라고 하며 결정 경계를 바탕으로 분리된 부분집합을 결정 구역(decision region) 이라고 한다.\n입력 벡터가 \\(D\\) 차원 공간이라고 하자. 결정 표면을 \\(D\\) 차원 공간에 대한 \\(D-1\\) 차원 초평면 으로 분리하는 모델을 선형 모델(linear model) 이라고 하며, 데이터들이 다수의 초평면으로 정확하게 각각의 클래스로 분류될 수 있을 때, 이 데이터의 집합을 선형 분리 가능 집합(linearly seperable set) 이라고 한다.\n가능한 output 이 \\(K\\) 개의 클래스라고 하자. 이 \\(K\\) 개의 클래스를 \\(\\mathbb{R}^K\\) 의 표준 기저 벡터로 표현하는 것을 원-핫 인코딩(one hot encoding) 이라고 하고 이렇게 표현된 벡터를 원-핫 벡터 라고 한다. 예를 들어 다수의 과일 이미지를 사과, 배, 딸기로 분류한다다면 이 이미지들은 3개의 클래스로 분류된다는 의미이다. 사과 클래스는 원-핫 인코딩을 통해 \\(\\boldsymbol{e}_1=\\begin{bmatrix} 1 & 0 & 0\\end{bmatrix}^T\\) 로, 배, 딸기는 각각 \\(\\boldsymbol{e}_2,\\,\\boldsymbol{e}_3\\) 로 표현될 수 있다.\n\n\n\n1.2 일반화된 선형 모델\n입력값 \\(\\boldsymbol{x}\\) 에 대한 모델을 구성할 때 모댈 내부의 매개변수 \\(\\boldsymbol{w}\\) 에 대한 가장 간단한 함수로서\n\\[\ny(\\boldsymbol{x}; \\boldsymbol{w},\\,w_0) = f(\\boldsymbol{w}^T \\boldsymbol{x}+w_0)\n\\tag{1}\\]\n를 생각 할 수 있다. 이 때 보통 \\(f(s)\\) 는 비선형 함수이며 활성화 함수(activation fucntion) 이라고 불린다. 또한 식 1 로 기술되는 모델을 일반화된 선형 모델(generalized linear model) 이라고 한다.\n일반화된 선형 모델의 경우 결정 표면은 어떤 상수 \\(c\\) 에 대해 \\(\\boldsymbol{w}^T\\boldsymbol{x} + w_0 = c\\) 인 초평면이 된다. 즉 선형 분리 가능 집합의 경우 일반화된 선형 모델로 잘 설명이 된다.\n\n\n\n1.3 선형 판별\n입력벡터를 어느 클래스로 분류할지 판단하는 함수를 판별함수라고 하고 판별함수에 의한 결정표면이 초평면 일 경우 선형 판별(linear determination) 이라고 한다,.\n\n\n이진 분류\n두개의 클래스 \\(C_1,\\,C_2\\) 로 분류하는 것을 이진 분류라고 한다. 식 1 에서의 활성화 함수 \\(f\\) 를 \\(\\text{sign}(a)\\) 함수 즉,\n\\[\n\\text{sign}(a) = \\left\\{\\begin{array}{ll} 1, \\qquad & a\\ge 0 \\\\ 0 & a&lt;0 \\end{array} \\right.\n\\]\n로 정한다. 즉 \\(y(\\boldsymbol{x};\\boldsymbol{w},\\,w_0)\\) 값이 \\(1\\) 이면 \\(C_1\\), \\(-1\\) 이면 \\(C_2\\) 클래스에 포함되도 하는 매개변수를 찾는 문제가 된다. 이진분류의 함수값을 \\(\\{1,\\,0\\}\\) 이 아니라 \\(\\{-1,\\,1\\}\\) 로 놓는 경우도 있지만 뒤에 다룰 확률론적 분류를 위해 \\(\\{1,\\,0\\}\\) 의 값을 사용하도록 한다.\n\n\n\n다중 클래스 의 경우\n2 개 이상 \\(K\\) 개의 클래스 \\(C_1,\\ldots,\\,C_K\\) 로 분류하는 문제의 경우는 매우 복잡해진다. 예를 들어 이진 분류법을 각 클래스 \\(C_1,\\ldots,\\,C_N\\) 에 대해 사용한다고 하자. 각 클래스에 대한 대한 활성화 함수 \\(f_1,\\,\\ldots,\\,f_N\\) 을 정하더라도 겹치거나, 어디에도 포함되지 않는 모호한 영역이 생길 수 있다. 이런 경우를 처리할 수 있는 한가지 방법으로 \\(K\\) 개의 선형 판별 함수 \\(y_1,\\ldots,\\,y_K\\) 를 아래와 같이 우선 정의한다.\n\\[\ny_k(\\boldsymbol{x}; \\boldsymbol{w}_k,\\, w_{k0}) = \\boldsymbol{w}_k^T \\boldsymbol{x} + b_k,\\qquad k=1,\\ldots,\\, K.\n\\tag{2}\\]\n이 때 \\(y_{k}(\\boldsymbol{x}; \\boldsymbol{w}_k,\\, b_k) \\ge y_{j}(\\boldsymbol{x}; \\boldsymbol{w}_j,\\, b_j)\\) 이면 \\(C_k\\) 클래스에 포함되도록 하면 된다. 즉 결정",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>퍼셉트론과 분류</span>"
    ]
  },
  {
    "objectID": "src/theory/classification.html#로지스틱-회귀",
    "href": "src/theory/classification.html#로지스틱-회귀",
    "title": "5  퍼셉트론과 분류",
    "section": "2 로지스틱 회귀",
    "text": "2 로지스틱 회귀\n\n2.1 비용함수\n수학적으로 \\(f:\\mathbb{R}^n \\to \\{0,\\,1\\}\\) 인 함수\n\\[\nf(t) = \\left\\{\\begin{array}{ll} 1,\\qquad & t\\ge 0,\\\\ 0, &t&lt;0 \\end{array}\\right. .\n\\]\n를 생각하자. 입력 벡터 \\(\\boldsymbol{x}\\) 를 비선형 변환 \\(\\boldsymbol{\\phi}\\) 를 통해 특징벡터(feature vector) 로 변환시킬 때\n\\[\ny = f(\\boldsymbol{w}^T \\boldsymbol{x} + b)\n\\]\n인 함수이다.\n우선 여기에 대한 비용함수를 생각해보자. 우선적으로 생각 할 수 있는 오차제곱합을 사용할 경우 발생할 수 있는 문제를 예를 들어 보자.\n\n\n\n예제 1 간단한 이진 분류 문제를 생각해 보자. \\([0,\\,1]\\times [0,\\,1]\\) 공간에 \\(N\\) 개의 임의의 점을 찍고 \\(x\\ge y\\) 이면 \\(1\\), 아니면 \\(2\\) 의 클래스를 부여한다고 하자. 그리고 원점을 지나는 직선 \\(y=wx\\) 로 클래스를 분리한다고 할 때 비용함수로 오차제곱합을 사용한다고 하자. 총 50 개의 무작위 점에 대해 분류하고 \\(w\\) 에 대한 오차제곱합 \\(L(w)\\) 를 구하면 아래 그림의 가운데 그림과 같다. 가장 오른쪽 그림의 \\(L_{\\text{Logistics}}(w)\\) 는 이후 설명한다.\nusing CairoMakie, LinearAlgebra, LaTeXStrings\n\nN=50\nt2, t3 = nothing, nothing\nσ(t) = 1/(1.0+exp(-t))\nX, Y = rand(N), rand(N)\nC1X, C1Y, C2X, C2Y = [], [],[],[]\nt1=[]\nfor i in 1:N\n    if X[i] ≥ Y[i] \n        append!(C1X, X[i])\n        append!(C1Y, Y[i])\n        append!(t1,1)\n    else \n        append!(C2X, X[i])\n        append!(C2Y, Y[i])\n        append!(t1, 0)\n    end\nend\nwr = 0.0:0.01:1.0\nerr1 = []\nerr2 = []\nfor w0 ∈ wr\n    t2=Int.(w0.*X .- 0.5.* Y .&gt;0)\n    t3=σ.(30 .* w0 .* X .- 15 .* Y)\n    append!(err1, sum((t1 .- t2).^2))\n    append!(err2, -sum((t1 .* log.(t3 .+ 1.0e-15) .+ (1.0 .- t1) .* log.(1.0 .- t3 .+ 1.0e-15))))\nend\n\n\nfig = Figure(size=(1500, 600))\nax = Axis(fig[1, 1], aspect = 1, limits = (-0.05, 1.05, -0.05, 1.05), xlabel=L\"X\", ylabel = L\"Y\")\nscatter!(ax, C1X, C1Y, color=:red, markersize=15, label=L\"C1\")\nscatter!(ax, C2X, C2Y, color=:green, markersize=15, label=L\"C2\")\naxislegend(ax)\nax2 = Axis(fig[1, 2], xlabel = L\"w\", ylabel = L\"L(w)\")\nscatter!(ax2, wr, err1)\nax3 = Axis(fig[1, 3], xlabel = L\"w\", ylabel = L\"L_{\\text{Logistic}}(w)\")\nscatter!(ax3, wr, err2)\nfig\n\n\n\n\n\n\n그림 1: 이진 분류와 비용함수\n\n\n\n가운데 그림에서 보다시피 오차제곱합 함수를 사용한 비용함수 \\(L(w)\\) 는 불연속이며 따라서 미분 불가 함수이다. \\(w\\) 를 변경시킬 때 각 클래스에 속하는 점의 갯수가 변할 때마다 불연속이 된다.\n\n물론 오차제곱합 함수 말고도 단지 함수에서 오분류된 점의 갯수, 혹은 전체 점에 대한 비율로 오류함수를 정의 할 수 도 있지만 어쨌든 \\(w\\) 에 대해 불연속이 된다는 것은 자명하다.\n\n\n\n\n2.2 시그모이드 함수와 로지스틱 회귀\n앞서 비용함수의 불연속성은 target 집합 이 \\(\\{0,\\,1\\}\\) 이기 때문에 발생한다. 이 문제를 해결하기 위해 확률론을 도입한다. 즉 모델 함수의 치역을 \\([0,\\,1]\\) 하는 연속함수중에 선택 할 수 있다. 가장 대표적으로 널리 사용되는 것이 로지스틱 시그모이드 함수(logistic sigmoid function) \\(\\sigma(t)\\) 이다.\n\\[\n\\sigma(t) = \\dfrac{1}{1+e^{-t}}\n\\tag{3}\\]\n\n\n\n\n\n\n그림 2: 시그모이드 함수\n\n\n\n그렇다면 모델 함수 \\[\ny=\\sigma\\left(\\boldsymbol{w}^T \\boldsymbol{x} + b\\right)\n\\]\n는 \\(\\boldsymbol{x}\\) 가 정해진 클래스에 속할 확률이 된다. 이 로지스틱 시그모이드를 판별함수로 하는 분류를 로지스틱 회귀(logistic regression) 라고 한다. 회귀(regression) 이라는 말이 들어가지만 회귀가 아닌 분류 문제에 사용된다.\n그리고 이에 대한 비용 함수는 이진 교차 엔트로피(Binary cross entropy, BCE) 함수를 사용한다. \\(\\hat{y}^{(i)} = \\sigma \\left(\\boldsymbol{w}^T\\boldsymbol{x}^{(i)}\\right)\\) 에 대해\n\\[\nL(\\boldsymbol{w}) = \\text{BCE}(\\boldsymbol{w}) =\\sum_{i=1}^n y^{(i)} \\left[\\ln \\left(\\hat{y}^{(i)}\\right) + \\left(1-y^{(i)}\\right) \\ln \\left(1-\\left(\\hat{y}^{(i)}\\right)\\right)\\right]\n\\tag{4}\\]\n를 사용한다. 앞서 예제 1 에서 오차함수로 위의 \\(\\text{BCE}\\) 함수를 사용했을 때가 그림 1 의 가장 오른쪽 그림이다.\n\n\n\n2.3 다중 클래스 로지스틱 회귀\n\\(C_1,\\ldots,\\,C_K\\) 클래스로 분류하는 데 사용되는 판별함수 \\(a_1 = a_1(\\boldsymbol{x};\\boldsymbol{w}_1,\\,b_1),\\ldots,\\,a_K=a_K(\\boldsymbol{x};\\boldsymbol{w}_K,\\,b_K)\\) 에 대해 소프트 맥스 변환 \\(G:\\mathbb{R}^K \\to \\mathbb{R}^K\\) 은 \\(\\boldsymbol{a}=\\begin{bmatrix} a_1 & \\cdots & a_K\\end{bmatrix}^T\\) 에 대해 다음과 같이 정의된다. \\[\nG(\\boldsymbol{a}) := \\dfrac{1}{\\sum_{j=1}^K e^{a_j}} \\begin{bmatrix} e^{a_1} \\\\ \\vdots \\\\ e^{a_K}\\end{bmatrix}\n\\tag{5}\\]\n우리는 각각의 \\(a_i\\) 가 \\([0,\\,1]\\) 사이의 값을 갖는다는 것을 알고 있다. \\(G(\\boldsymbol{a})\\) 의 각 성분 역시 \\([0,\\,1]\\) 사이의 값을 가지며 그 성분의 합이 \\(1\\) 이다. 따라서 \\(G(\\boldsymbol{a})\\) 의 각 성분은 확률 그 클래스에 속할 확률로 해석 할 수 있다. 이렇게 다중 클래스 분류 문제를 확률로 해석하는 것을 다중 클래스 로지스틱 회귀라고 한다.\n다중 클래스 회귀에 대한 비용함수로는 교차 엔트로피 오차 함수(Cross entropy error function, CEE) 가 사용된다.\n\\[\n\\text{CEE}(\\boldsymbol{w}) = -\\sum_{i=1}^n\\sum_{j=1}^K   y^{(i)}_j \\ln \\left(\\hat{y}^{(i)}_j\\right)\n\\tag{6}\\]\n소프트 맥스 회귀를 사용하는 다중 클래스 로지스틱 회귀에서는 식 6 는 \\[\n\\text{CEE}(\\boldsymbol{w})  =  -\\sum_{i=1}^n\\sum_{j=1}^K  y^{(i)}_j \\left[ a_j - \\ln \\left(\\sum_{m=1}^K e^{a_m}\\right) \\right]\n\\tag{7}\\]\n이다.\n\n\n\n2.4 비용 함수의 미분\n로지스틱 회귀의 모델 함수 \\(\\sigma(\\boldsymbol{w}^T\\boldsymbol{x}+b)\\) 에서 우리가 최적값을 찾아야 할 것은 \\(\\boldsymbol{w}\\) 와 \\(b\\) 이다. 수식 표기량을 줄이기 위해\n\\[\n\\tilde{\\boldsymbol{x}}=\\begin{bmatrix}1 \\\\ \\boldsymbol{x}\\end{bmatrix} = \\begin{bmatrix} 1 \\\\ x_1 \\\\ \\vdots \\\\ x_n\\end{bmatrix}, \\qquad \\tilde{\\boldsymbol{w}}= \\begin{bmatrix} b \\\\ \\boldsymbol{w}\\end{bmatrix} = \\begin{bmatrix} b \\\\ w_1 \\\\ \\vdots \\\\ w_n\\end{bmatrix}\n\\]\n를 사용하여 \\(\\sigma (\\boldsymbol{w}^T\\boldsymbol{x}+b)=\\sigma (\\tilde{\\boldsymbol{w}}^T\\tilde{\\boldsymbol{x}})\\) 의 표기법을 도입하거나 \\(\\boldsymbol{w},\\, \\boldsymbol{x}\\) 가 실제로는 \\(\\tilde{\\boldsymbol{w}},\\, \\tilde{\\boldsymbol{x}}\\) 를 의미한다고 간주하고 계산하기도 한다. 여기서는 후자를 사용하며 이후로는 필요하다면 명확하게 언급 한 후 그 방식으로 사용하기로 하자.\n교차 엔트로피 함수 \\(L_C(\\boldsymbol{w}_1,\\ldots,\\boldsymbol{w}_K)= \\text{CEE}(\\boldsymbol{w})\\) 에 대한 미분을 생각해보자. \\(w_{kl}= (\\boldsymbol{w}_k)_l\\) 이라 하면\n\\[\n\\begin{aligned}\n\\dfrac{\\partial L_C}{\\partial w_{kl}} &= -\\sum_{i=1}^n \\sum_{j=1}^K y_j^{(i)} \\left[\\dfrac{\\partial a_j}{\\partial w_{kl}} - \\dfrac{\\dfrac{\\partial a_k}{\\partial w_{kl}} e^{a_k}}{\\sum a_m}\\right] = -\\sum_{i=1}^n \\sum_{j=1}^K y_j^{(i)} \\left[\\delta_{jk}\\dfrac{\\partial a_j}{\\partial w_{kl}} - \\dfrac{\\partial a_k}{\\partial w_{kl}} \\hat{y}_k^{(i)}\\right] \\\\\n&= - \\dfrac{\\partial a_k}{\\partial w_{kl}}\\left[\\sum_{i=1}^n \\left[y_k^{(i)}  - \\sum_{j=1}^K y_j^{(i)} \\hat{y}_k^{(i)} \\right]\\right]\n\\end{aligned}\n\\]\n여기서 \\(\\sum_{j=1}^K y_j^{(i)}=1\\) 이므로\n\\[\n\\dfrac{\\partial L_C}{\\partial w_{kl}} =- \\dfrac{\\partial a_k}{\\partial w_{kl}} \\sum_{i=1}^n \\left(y_k^{(i)} -\\hat{y}^{(i)}_k\\right)\n\\tag{8}\\]\n인 매우 단순한 식이 된다. 즉\n\\[\n\\nabla_{\\boldsymbol{w}_k} L_C(\\boldsymbol{w}_1,\\ldots,\\, \\boldsymbol{w}_K) =  \\left[\\sum_{i=1}^n \\left(\\hat{y}_k^{(i)} -y^{(i)}_k\\right)\\right] \\nabla_{\\boldsymbol{w}_k} a_k\n\\tag{9}\\]\n이다. 이진 분류의 경우 \\(\\boldsymbol{w}\\) 만 생각하면 되므로\n\\[\n\\nabla_\\boldsymbol{w} L_B(\\boldsymbol{w})= \\left[\\sum_{i=1}^n \\left(\\hat{y}_k^{(i)} -y^{(i)}_k\\right)\\right] \\nabla_{\\boldsymbol{w}} a\n\\tag{10}\\]\n이다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>퍼셉트론과 분류</span>"
    ]
  },
  {
    "objectID": "src/theory/perceptron_and_ann.html",
    "href": "src/theory/perceptron_and_ann.html",
    "title": "6  퍼셉트론과 인공신경망",
    "section": "",
    "text": "1 퍼셉트론",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>퍼셉트론과 인공신경망</span>"
    ]
  },
  {
    "objectID": "src/theory/perceptron_and_ann.html#퍼셉트론",
    "href": "src/theory/perceptron_and_ann.html#퍼셉트론",
    "title": "6  퍼셉트론과 인공신경망",
    "section": "",
    "text": "1.1 퍼셉트론\n앞서의 일반화된 선형 모델 은 원래 생물의 신경 세포(neuron) 을 수학적으로 모사한 것이다. 로지스틱 회귀에서는 입력변수와 매개변수의 내적에 대한 시그모이드 함수로 처리하여 출력했으며, 다중 클래스 로지스틱 회귀에서는 소프트 맥스 함수를 사용하였다. 이 퍼셉트론을 여러 층으로 쌓은 것을 신경망(neural network) 이라고 하며 현재 인공지능 시스템의 핵심이 되었다. 여기서 입력변수와 매개변수의 내적을 처리하는 함수를 활성화 함수(activation function) 라고 하며 신경망 에서는 시그모이드나 소프트 맥스 이외에 각각의 장점과 목적에 맞게 다양한 함수를 사용 할 수 있다.\n\n\n\n\n\n\n그림 1: 퍼셉트론\n\n\n\n요약하자면\n (\\(1\\)) \\(n\\) 개의 입력 변수 \\(\\boldsymbol{x}\\in \\mathbb{R}^n\\),\n (\\(2\\)) \\(n+1\\) 개의 내부 파라미터 : 1개의 bias \\(b\\) 와 \\(n\\) 개의 값을 갖는 \\(\\boldsymbol{w}=\\begin{bmatrix} w_1 & \\ldots &w_n\\end{bmatrix}^T\\),\n (\\(3\\)) 활성화 함수(activation function) \\(\\sigma(z)\\) : 비선형 함수.\n로 정의된다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>퍼셉트론과 인공신경망</span>"
    ]
  },
  {
    "objectID": "src/theory/perceptron_and_ann.html#다층-신경망",
    "href": "src/theory/perceptron_and_ann.html#다층-신경망",
    "title": "6  퍼셉트론과 인공신경망",
    "section": "2 다층 신경망",
    "text": "2 다층 신경망\n\n2.1 다층 신경망\n\n\n\n\n\n\n그림 2: 다층 신경망\n\n\n\n\n입력층(input layer) 는 퍼셉트론이 아닌 입력 데이터 벡터이다.\n입력층과 출력층을 제외한 신경망의 각 층을 은닉층(hidden layer) 라고 한다.\n첫번째 은닉층(hidden layer)의 퍼셉트론을 \\(h_1^{(1)},\\,h_2^{(1)},\\ldots\\) 와 같이 표기한다.\n\\(k\\) 번째 은닉층의 퍼셉트론을 \\(h_1^{(k)},\\,h_2^{(k)},\\ldots\\) 와 같이 표기한다.\n\\(k\\) 번째 은닉층의 퍼셉트론의 갯수를 \\(N_k\\) 로 표기한다.\n출력층은 출력값 벡터를 출력하는 마지막 층의 퍼셉트론이다.\n신경망의 층수는 입력층을 제외하고 은닉층의 수에 출력층 1 을 더하여 표기한다. 즉 위의 그림은 4층 신경망이다.\n\n다층 퍼셉트론은 입력값 벡터 \\(\\boldsymbol{x}\\in \\mathbb{R}^D\\) 에 대해 출력값 \\(\\hat{\\boldsymbol{y}}\\in \\mathbb{R}^K\\) 를 내는 함수로 내부에 각각의 퍼셉트론의 매개변수 전체 신경망의 매개변수로 가지는 함수이다.\n입력층 \\(\\boldsymbol{x} = \\begin{bmatrix}x_1 & \\cdots & x_D\\end{bmatrix}^T\\) 에 대해 첫번째 은닉층의 \\(j\\) 번째 퍼셉트론의 내부 파라미터 벡터를 \\(\\boldsymbol{w}^{(1j)}\\) 와 \\(b^{(1)}_j\\) 로 표기한다면 활성화 함수 \\(\\sigma\\) 에 대해 출력값 \\(y^{(1)}_j\\) 는 \\[\nz^{(1)}_j = \\sigma \\left(\\boldsymbol{w}^{(1j)} \\boldsymbol{\\cdot x}+b^{(1)}_j\\right)\n\\]\n이다. 첫번째 은닉층에 \\(N_1\\) 개의 퍼셉트론이 있다고 하고 행렬 \\(\\boldsymbol{W}^{(1)}\\) 와 \\(\\tilde{\\boldsymbol{x}}\\) 를 다음과 같이 정의하자.\n\\[\n\\boldsymbol{W}^{(1)} := \\begin{bmatrix} w^{(11)}_1 & w^{(11)}_2 & \\cdots & w^{(11)}_n & b^{(1)}_1 \\\\ w^{(12)}_1 & w^{(12)}_2 & \\cdots & w^{(12)}_n & b^{(1)}_2 \\\\ \\vdots & & & & \\vdots \\\\ w^{(1,N_1)}_1 & w^{(1,N_1)}_2 & \\cdots & w^{(1,N_1)}_n & b^{(1)}_{N_1} \\end{bmatrix},\\qquad \\tilde{\\boldsymbol{x}} := \\begin{bmatrix} x_1 \\\\ \\vdots \\\\ x_n \\\\ 1\\end{bmatrix}.\n\\tag{1}\\]\n즉 \\(\\boldsymbol{W}^{(1)}\\boldsymbol{\\tilde{x}}\\) 의 \\(j\\) 번째 행은 첫번째 은닉층의 \\(j\\) 번째 퍼셉트론의 활성화 함수에 적용되는 값이다. 첫번째 은닉층의 \\(j\\) 번째 퍼셉트론의 출력값을 \\(z^{(j)}\\) 라고 하고\n\\[\n\\boldsymbol{z}^{(1)} = \\begin{bmatrix} z^{(1)}_1 \\\\ \\vdots \\\\ z^{(1)}_{N_1}\\end{bmatrix} = \\begin{bmatrix} \\sigma_1\\left(\\left[\\boldsymbol{W}^{(1)}\\boldsymbol{\\tilde{x}}\\right]_{1}\\right) \\\\ \\vdots \\\\  \\sigma_1\\left(\\left[\\boldsymbol{W}^{(1)}\\boldsymbol{\\tilde{x}}\\right]_{N_1}\\right)  \\end{bmatrix}\n\\]\n라고 하면 \\(\\boldsymbol{z}^{(1)}\\) 은 첫번째 은닉층에서의 전체 출력값을 나타내는 벡터이다. 여기서 \\(\\left[\\boldsymbol{W}^{(1)}\\boldsymbol{\\tilde{x}}\\right]_k\\) 는 \\(\\boldsymbol{W}^{(1)}\\boldsymbol{\\tilde{x}}\\) 의 \\(k\\) 행 값을 의미한다. 이 값이 두번째 은닉층의 입력값이 되는데, 첫번째 은닉층에 대한 입력값과 마찬가지로 bias 를 고려해야 하므로 두번째 은닉층의 입력값 \\(\\tilde{\\boldsymbol{z}}^{(1)}\\) 을 다음과 같이 놓자.\n\\[\n\\tilde{\\boldsymbol{z}}^{(1)} := \\begin{bmatrix} \\boldsymbol{z}^{(1)} \\\\ 1\\end{bmatrix} = F^{(1)}\\left(\\boldsymbol{W}^{(1)}\\boldsymbol{\\tilde{x}}\\right) = \\begin{bmatrix} \\sigma_1\\left(\\left[\\boldsymbol{W}^{(1)}\\boldsymbol{\\tilde{x}}\\right]_{1}\\right) \\\\ \\vdots \\\\  \\sigma_1\\left(\\left[\\boldsymbol{W}^{(1)}\\boldsymbol{\\tilde{x}}\\right]_{N_1}\\right) \\\\ 1 \\end{bmatrix}\n\\]\n이제 두번째 은닉층에서의 매개변수를 첫번째 은닉층의 매개변수와 같은 방법으로 구성한 \\(\\boldsymbol{W}^{(2)}\\) 와 두번째 층의 퍼셉트론의 갯수 \\(N_2\\) 에 대해\n\\[\n\\tilde{\\boldsymbol{z}}^{(2)} = F^{(2)}\\left(\\boldsymbol{W}^{(2)}\\tilde{\\boldsymbol{z}}^{(1)}\\right) = \\begin{bmatrix}  \\sigma_2\\left(\\left[\\boldsymbol{W}^{(1)}\\boldsymbol{\\tilde{x}}\\right]_{1}\\right) \\\\ \\vdots \\\\  \\sigma_2\\left(\\left[\\boldsymbol{W}^{(1)}\\boldsymbol{\\tilde{x}}\\right]_{N_2}\\right) \\\\ 1\\end{bmatrix}\n\\]\n라 할 수 있다. 이것을 이후 이어지는 은닉층에 계속 진행 할 수 있다. 임의의 \\(m\\) 번째 은닉층이 \\(N_m\\) 개의 퍼셉트론으로 구성되었다고 하자. 여기에서의 출력값은 은닉층의 매개변수 \\(\\boldsymbol{W}^{(m)}\\) 과 입력 벡터 \\(\\tilde{\\boldsymbol{z}}^{(m-1)}\\) 에 대해 다음과 같다.\n\\[\n\\tilde{\\boldsymbol{z}}^{(m)} = F^{(m)}\\left(\\boldsymbol{W}^{(m)} \\tilde{\\boldsymbol{z}}^{(m-1)}\\right) = \\begin{bmatrix} \\sigma_m\\left(\\left[\\boldsymbol{W}^{(m)} \\tilde{\\boldsymbol{z}}^{(m-1)}\\right]_1\\right) \\\\ \\vdots \\\\ \\sigma_m\\left(\\left[\\boldsymbol{W}^{(m)} \\tilde{\\boldsymbol{z}}^{(m-1)}\\right]_{N_m}\\right) \\\\ 1 \\end{bmatrix}\n\\tag{2}\\]\n이후 역전파 에 나올 내용이지만 여기서 미리 언급해 두자. 여기서 \\(\\tilde{\\boldsymbol{z}}^{(m-1)}=\\boldsymbol{a}\\) 에서의 미분은 다음과 같다. \\[\n\\dfrac{\\partial \\tilde{z}_k^{(m)}}{\\partial w_{ij}^{(m)}} = \\left\\{\\begin{array}{ll}0, & i\\ne k\\text{ or } k=N_m+1,\\\\[0.3em] \\sigma'_{m}\\left(\\left[\\boldsymbol{W}^{(m)} \\boldsymbol{a}\\right]_i \\right)a_j, & i=k \\end{array}\\right.\n\\tag{3}\\]\n즉, 다음과 같이 쓸 수 있다.\n\\[\n\\boxed{\n\\dfrac{\\partial \\tilde{z}_k^{(m)}}{\\partial w_{ij}^{(m)}} = \\delta_{ik} \\sigma'_{m}\\left(\\left[\\boldsymbol{W}^{(m)} \\tilde{\\boldsymbol{z}}^{(m-1)}\\right]_i \\right)\\tilde{z}_j^{(m-1)}\n}\n\\tag{4}\\]\n이제 출력층을 보자. 보통 출력층에서의 활성화 함수는 다른 은닉층의 활성화 함수와 다르기 때문에 \\(\\sigma_O\\) 라고 하자. 은닉층이 3개이므로\n\\[\n\\hat{\\boldsymbol{y}} = \\begin{bmatrix}  \\sigma_O \\left( [\\boldsymbol{W}^{(O)}\\tilde{\\boldsymbol{z}}^{(3)}]_1\\right) \\\\ \\vdots \\\\\\sigma_O \\left(  [\\boldsymbol{W}^{(O)}\\tilde{\\boldsymbol{z}}^{(3)}]_K \\right) \\end{bmatrix}\n\\tag{5}\\]\n이다. 여기에 대한 미분은\n\\[\n\\boxed{\n\\dfrac{\\partial \\hat{y}_k}{\\partial w^{(O)}_{ij}} = \\delta_{ik} \\sigma_{O}'\\left([\\boldsymbol{W}^{(O)}\\tilde{\\boldsymbol{z}}^{(3)}]_i\\right)\\tilde{z}^{(3)}_j\n}\n\\tag{6}\\]\n\n\n\n2.2 활성화 함수\n은닉층, 즉 출력층을 제외한 신경망의 퍼셉트론에 대표적으로 많이 사용되는 활성화 함수에는 다음과 같은 것이 있다.\n\n\n\n\n\n\n그림 3: 대표적인 활성화 함수\n\n\n\n\n활성화 함수를 구별짓는 특징으로는 다음과 같은 것들이 있다.\n\n함수의 치역(range) 는 어디인가?\n매끄러운 정도는? 즉 몇번 미분 가능한가?\n도함수를 원래 함수, 또는 쉽게 계산 할수 있는 함수를 이용하여 쉽게 계산 할 수 있는가?\n\n\n이 외에 특정한 목적으로 사용되는 \\(\\text{Maxout}\\) 함수가 있다. \\(\\boldsymbol{x}=\\begin{bmatrix}x_1 & \\cdots & x_n\\end{bmatrix}^T\\) 에 대해\n\\[\n\\text{Maxout}(\\boldsymbol{x}) := \\max \\{x_1,\\ldots,\\,x_n\\}\n\\tag{7}\\]\n으로 정의된다.\n\n\n\n2.3 비용함수\n정해진 모든 퍼셉트론의 파라미터를 \\(\\boldsymbol{\\theta}\\) 라고 하고 입력 \\(\\boldsymbol{x}\\) 에 대한 출력값을 \\(\\hat{\\boldsymbol{y}}=F(\\boldsymbol{x};\\boldsymbol{\\theta})\\) 라고 쓰자. 우리가 데이터를 학습시킬 때 \\(i\\) 번째 입력 벡터를 \\(\\boldsymbol{x}_{(i)}\\) 라고 쓰면 마찬가지로 label 은 원-핫 벡터 \\(\\boldsymbol{y}_{(i)}\\) 로 표현 할 수 있으며 출력값은 \\(\\hat{\\boldsymbol{y}}_{(i)}=F\\left(\\boldsymbol{x}_{(i)};\\boldsymbol{\\theta}\\right)\\) 로 표기 할 수 있다. 다층신경망에 사용된 모든 퍼셉트론의 파라미터를 \\(\\boldsymbol{\\theta}\\) 라고 표기하기로 하자. 다층 신경망에서의 오차함수는 신경망에서의 출력값의 특성에 따라 최소 제곱합이나 교차 엔트로피 함수 혹은 다른 특정한 목적을 위한 함수를 사용 할 수 있다.\n\n\n\n2.4 경사 하강법\n결국은 다층 신경망을 학습시키는 것은 입력 데이터 \\(\\boldsymbol{x}^{(1)}, \\,\\boldsymbol{x}^{(2)},\\ldots\\) 와 정답(label) \\(\\boldsymbol{y}^{(1)},\\,\\boldsymbol{y}^{(2)},\\ldots\\), 모델함수 \\(f(\\boldsymbol{x};\\boldsymbol{\\theta})\\) 에 대해 비용함수 \\(L(\\boldsymbol{\\theta})\\) 를 최소화 하는 파라미터 \\(\\boldsymbol{\\theta}\\) 를 찾는 문제이다. 문제는 입력 및 정답의 갯수 뿐만 아니라 \\(\\boldsymbol{\\theta}\\) 의 갯수도 아주 크다는 것이다. 어쨌든 신경망은 일단 파라미터에 제한이 없으므로 unrestricted condtion 의 최적화 문제로 볼 수 있다. 이 경우 사용하는 것이 경사하강법이다. 매개변수 \\(\\boldsymbol{\\theta}\\) 는 \\(k\\) 번째 update 에서의 학습률 \\(\\eta_k\\) 에 대해 다음과 같이 update 된다.\n\\[\n\\boldsymbol{\\theta}_{k+1} = \\boldsymbol{\\theta}_k - \\eta_k \\nabla_\\boldsymbol{\\theta}L(\\boldsymbol{\\theta}_k)\n\\]\n\\(\\nabla_{\\boldsymbol{\\theta}}L(\\boldsymbol{\\theta}_k)\\) 를 구하는 방법은 뒤의 역전파에서 다루기로 하고 일단 이것을 알고 있다고 하자.\n한번의 업데이트에 사용되는 데이터셋을 배치(batch) 라고 한다. 데이터셋의 크기가 매우 클 경우 모든 데이터셋을 포함하여 비용함수를 계산한다면, 비용함수 및 그 그래디언트를 계산하는데 계산 비용이 많이 소모된다. 만약 소수의 데이터셋만 사용한다면 계산량은 줄지만 노이즈에 취약하게 된다. 이를 위해 전체 데이터셋을 몇등분하며 각각의 등분된 부분의 데이터셋으로 파라미터를 업데이트 할 수 도 있다. 이렇게 등분된 데이터셋을 미니 배치(mini batch) 라고 한다. 전체의 데이터셋으로 파라미터를 업데이트 시켰을 경우를 1 에포크(epoch) 라고 한다.\n즉 1000 개의 훈련용 데이터 셋이 있다면 1000 개의 데이터셋으로 이루어진 1개의 배치가 있다. 이것을 250 개의 미니배치로 나누어 250 개의 데이터셋을 이용하여 4번 파라미터를 업데이트 할 수도 있다. 어쨌든 1000 개의 준비된 데이터셋을 사용하여 파라미터를 업데이트 하였다면 1 에포크 의 훈련 혹은 학습을 수행한 것이다.\n\n배치와 미니배치에 따라 세가지 방법을 사용 할 수 있다.\n\n배치 경사 하강법 (Batch gradient discent) : 각각의 \\(\\boldsymbol{\\theta}\\) 업데이트에 대해 전체 데이터셋을 사용한다. 즉 미니배치를 사용하지 않는다.노이즈에 대해 강건하지만(영향을 적게 받지만) 계산량이 많다.\n확률적 경사 하강법 (Stochastic gradient discent) : 데이터셋 하나가 미니배치를 이룬다. 즉 \\(\\boldsymbol{\\theta}\\) 업데이트에 하나의 데이터셋만 사용한다. 계산량이 가장 적지만 노이즈에 취약하다.\n미니 배치 경사 하강법(Mini batch gradient discent) : 전체 데이터셋보다 작고 하나보다 큰 미니배치를 사용한다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>퍼셉트론과 인공신경망</span>"
    ]
  },
  {
    "objectID": "src/theory/perceptron_and_ann.html#sec-ML_ANN_backpropagation",
    "href": "src/theory/perceptron_and_ann.html#sec-ML_ANN_backpropagation",
    "title": "6  퍼셉트론과 인공신경망",
    "section": "3 역전파 (Backpropagation)",
    "text": "3 역전파 (Backpropagation)\n역전파는 비용함수 \\(L(\\boldsymbol{\\theta})\\) 의 내부 매개변수가 \\(\\boldsymbol{\\theta}_k\\) 로 주어졌을 때 \\(\\nabla_\\boldsymbol{\\theta}L(\\boldsymbol{\\theta}_k)\\) 를 계산하는 방법이다. 역전파를 위해서는 우선 주어진 매개변수 \\(\\boldsymbol{\\theta}\\) 와 입력값에 대해 모든 퍼셉트론에 대해서 출력값이 정해져야 한다. 신경망의 경우 입력 벡터, 혹은 데이터셋에 대해 \\(\\tilde{\\boldsymbol{z}}^{(1)}\\) 부터 마지막 은닉층의 \\(\\tilde{\\boldsymbol{z}}^{(M)}\\) 와 출력값 \\(\\hat{\\boldsymbol{y}}\\) 까지 모두 정해진다. 뿐만 아니라 자동미분(Auto differentiation)을 통해 각 퍼셉트론의 식 4 가 계산된다. 이것을 순전파 (forward propagation) 라고 한다.\n그리고 이 비용함수 값과 모든 퍼셉트론의 출력값을 이용하여 신경망에서 \\(\\nabla_\\boldsymbol{\\theta} L(\\boldsymbol{\\theta}_k)\\) 를 계산 할 때 의 후진법(Backward method or reverse method) 를 사용하며, 신경망의 각 층을 거꾸로 거슬러 올라가며 \\(\\boldsymbol{\\theta}\\) 를 update 하므로 역전파(back propagation) 이라고 불린다.\n다음과 같은 신경망을 생각하자.\n\n\\(\\mathbb{R}^D\\) 차원의 입력 벡터와 \\(\\mathbb{R}^K\\) 차원의 출력 벡터, 그리고 \\(M\\) 개의 은닉층과 출력층으로 구성되었으며 \\(l\\) 번째 은닉층에는 \\(N_l\\) 개의 퍼셉트론이 존재한다.\n\n\n\n3.1 출력층에서의 역전파\n출력층의 매개변수를 \\(\\boldsymbol{W}^{(O)}\\) 이라고 하고 활성화 함수를 \\(\\sigma_{(O)}\\) 라고 하자. 그리고 비용 함수를 \\(L(\\boldsymbol{\\theta})\\) 라고 하자. 그렇다면 비용함수는 \\(\\boldsymbol{W}^{(1)},\\ldots,\\, \\boldsymbol{W}^{(M)},\\, \\boldsymbol{W}^{(O)}\\) 의 함수이다.\n\\[\nL(\\boldsymbol{W}) = L\\left(\\boldsymbol{W}^{(1)},\\ldots,\\,\\boldsymbol{W}^{(M)},\\, \\boldsymbol{W}^{(F)}\\right)\n\\]\nChain rule 을 이용하면 식 5 에 대해 다음을 알 수 있다. 여기서 \\(\\sigma'_{O,\\,i}:=\\sigma'_{O}\\left(\\left[\\boldsymbol{W}^{(O)} \\tilde{\\boldsymbol{z}}^{(M)}\\right]_i \\right)\\) 라고 하면\n\\[\n\\dfrac{\\partial L(\\boldsymbol{W})}{\\partial w^{(O)}_{ij}} = \\sum_k \\dfrac{\\partial L}{\\partial \\hat{y}_k} \\dfrac{\\partial \\hat{y}_k}{\\partial w^{(O)}_{ij}} = \\sum_k \\dfrac{\\partial L}{\\partial \\hat{y}_k}\\delta_{ik}\\sigma'_{O, i} \\tilde{z}^{(M)}_j= \\dfrac{\\partial L}{\\partial\\hat{y}_i} \\dfrac{\\partial \\hat{y}_i}{\\partial w^{(O)}_{ij}}\n\\tag{8}\\]\n이다. 기본적으로 자동 미분에 의해 \\(\\dfrac{\\partial \\hat{y}_i}{\\partial w^{(O)}_{ij}}\\) 는 순전파 과정에서 이미 정해졌으며 여기서는 \\({\\partial L}/{\\partial \\hat{y}_i}\\) 만을 구해서 출력층에서의 매개변수에 대한 편미분을 구할 수 있다. 이제 마지막 은닉층에서의 출력값 \\(\\tilde{z}^{(M)}_j= \\sigma \\left(\\left[\\boldsymbol{W}^{(M)}\\tilde{\\boldsymbol{z}}^{(M-1)}\\right]_j\\right)\\) 에 대해 \\[\n\\dfrac{\\partial L(\\boldsymbol{W})}{\\partial w^{(M)}_{ij}} = \\sum_{k} \\sum_{l}\\dfrac{\\partial L(\\boldsymbol{\\theta})}{\\partial \\hat{y}_k} \\dfrac{\\partial \\hat{y}_k}{\\partial \\tilde{z}^{(M)}_l}\\dfrac{\\partial \\tilde{z}^{(M)}_l}{\\partial w^{(M)}_{ij}}\n\\tag{9}\\]\n이며,\n\\[\n\\sigma'_{M, k} = \\left(\\dfrac{d\\sigma_M(t)}{dt}\\right)_{t=[\\boldsymbol{W}^{(M)}\\tilde{\\boldsymbol{z}}]_k}\n\\]\n라고 하면 \\[\n\\dfrac{\\partial \\hat{y}_k}{\\partial \\tilde{z}_l^{(M)}}=\\sigma'_{M, k} w^{(M)}_{kl},\\qquad \\dfrac{\\partial \\tilde{z}_l^{(M)}}{\\partial w^{(M)}_{ij}}= \\delta_{il}\\sigma'_{M, i}\\tilde{z}^{(M-1)} = \\delta_{li}\\dfrac{\\partial \\tilde{z}^{(M)}_l}{\\partial w^{(M)}_{ij}}\n\\]\n이므로 식 9 은\n\\[\n\\dfrac{\\partial L}{\\partial w^{(M)}_{ij}} = \\sum_{k_O} \\dfrac{\\partial L}{\\partial \\hat{y}_{k_O}} \\sigma'_{M, k} w_{k_O,i}^{(M)} \\dfrac{\\partial \\tilde{z}^{(M)}_i}{\\partial w^{(M)}_{ij}}\n\\tag{10}\\]\n이다. 여기서 \\(\\dfrac{\\partial \\tilde{z}^{(M)}_i}{\\partial w^{(M)}_{ij}}\\) 는 순전파 과정에서 정해지므로 마지막 은닉층의 매개변수에 대한 비용함수의 편미분을 모두 구할 수 있다. 이제 \\(m\\) 번 은닉층의 매개변수에 대한 편미분은\n\\[\n\\boxed{\n\\begin{aligned}\n\\dfrac{\\partial L}{\\partial w_{ij}^{(m)}} &= \\sum_{k_O=1}^{K} \\sum_{k_M=1}^{N_M} \\cdots \\sum_{k_{m+1}=1}^{N_{m+1}}\\dfrac{\\partial L}{\\partial \\hat{y}_{k_O}}  \\\\[0.3em]\n&\\qquad \\times \\left[ \\sigma'_{M, k_O} w^{(M)}_{k_O, k_M}\\right] \\left[\\sigma'_{M-1, k_{M-1}}w^{(M-1)}_{k_{M},k_{M-1}}\\right] \\cdots \\left[\\sigma'_{m+1,\\, k_{m+1}}w^{(m+1)}_{k_{m+1}, i}\\right]\\dfrac{\\partial \\tilde{z}^{(m)}_i}{\\partial w^{(m)}_{ij}}\n\\end{aligned}\n}\n\\tag{11}\\]\n로 구할 수 있다.\n\n\n\n3.2 기울기 소멸\n신경망 초기에는 활성화 함수로 sigmoid 함수를 만이 사용했다. \\(f(t)\\) 가 sigmoid 함수일 때 \\(0&lt;f(t)&lt;1\\) 이며\n\\[\nf'(t) = \\dfrac{e^{-t}}{(1+e^{-t})^2}= f(t) (1-f(t))\n\\]\n이다. Sigmoid 함수와 그 도함수는 아래 그림과 같으며 도함수의 최대값은 0.25 이다.\n\n\n\n\n\n\n그림 4: Sigmoid 함수와 그 미분\n\n\n\n식 11 를 보면 각 층에서의 활성화 함수의 도함수가 계속 곱해진다. 신경망의 층수가 매우 크다면 입력층에 가까운 퍼셉트론의 매개변수에 대한 미분값은 \\(0\\) 에 가까울 것이며 따라서 경사 하강법에 의헤 업데이트 되는 매개변수 \\(\\theta\\) 는 그 update 가 매우 느리거나 멈출 수 밖에 없다. 즉\n\\[\n\\theta_{k+1} = \\theta_k - \\alpha_k \\dfrac{\\partial L}{\\partial \\theta}\n\\]\n에서 \\(\\partial L/\\partial \\theta \\approx 0\\) 이므로 \\(\\theta_{k+1}\\approx \\theta_k\\) 가 된다. 이 현상을 기울기 소멸(vanishing gradient) 라고 한다. 기울기 소멸을 극복하기 위해 다양한 기법이 제시되었으며 대표적으로 활성화 함수를 기울기 소멸이 쉬운 sigmoid 함수나 \\(\\tanh\\) 함수를 사용하지 않고 \\(\\text{ReLU}\\), 혹은 이에서 파생한 \\(\\text{Leaky ReLU}\\), \\(\\text{ELU}\\) 함수를 사용하는 방법이 있다(그림 3 를 보라).",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>퍼셉트론과 인공신경망</span>"
    ]
  }
]