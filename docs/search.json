[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MachineLearning",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.",
    "crumbs": [
      "Home",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>MachineLearning</span>"
    ]
  },
  {
    "objectID": "src/theory/ML.html",
    "href": "src/theory/ML.html",
    "title": "기계 학습",
    "section": "",
    "text": "References",
    "crumbs": [
      "Home",
      "기계 학습"
    ]
  },
  {
    "objectID": "src/theory/ML.html#기계-학습의-분류",
    "href": "src/theory/ML.html#기계-학습의-분류",
    "title": "기계 학습",
    "section": "기계 학습의 분류",
    "text": "기계 학습의 분류\n\n지도 학습(Supervised Learning)\n\n입력 \\(\\boldsymbol{x}\\) 에 대한 정답(label) \\(\\boldsymbol{t}\\) 이 있는 데이터를 학습한다.\n회귀(regression) : 정답으로서 가능한 값이 실수(\\(\\mathbb{R}\\)) 인 경우.\n분류(classification) : 정답으로서 가능한 값이 이산적인 값일 경우.\n\n비지도 학습(Unsupervised Learning)\n\n정답(label)이 없는 데이터를 특징별로 군집화 (clustering) 하거나 데이터의 분포를 추정한다.\n\n강화학습 or 증강학습 (Reinforced Learning)\n\n주어진 데이터가 아닌, 환경과 상호작용을 통해 학습\n주어진 상태(state) 에 행동 (action) 을 취하며, 이에 대한 보상(reward)을 받는다.\n훈련 도중에, 최대 보상을 받도록 정책(policy)를 지속적으로 수정한다.",
    "crumbs": [
      "Home",
      "기계 학습"
    ]
  },
  {
    "objectID": "src/theory/ML.html#함수로서의-기계학습",
    "href": "src/theory/ML.html#함수로서의-기계학습",
    "title": "기계 학습",
    "section": "함수로서의 기계학습",
    "text": "함수로서의 기계학습\n\n인공지능은 어떤 입력에 대한 출력을 하며 우리는 보통 이런 것을 수학적으로는 함수(function) 라고 부른다.\n기계학습에서의 학습이란 대량의 데이터를 입력하여 이 데이터를 가장 잘 표현하는 하나의 함수를 정하는 것이다. 하나의 데이터에 대해 보통 입력값이 여러개이므로 \\(i\\)-번째 데이터의 입력은 \\(\\boldsymbol{x}_i\\) 로 \\(i\\)-번째 데이터의 label 은 \\(y_i\\) 로 표기한다. 입력값과 레이블 의 쌍을 \\((\\boldsymbol{x}_i, y_i)\\) 로 표기한다.\n함수를 내부적으로 표현하는데 쓰는 값을 매개변수 (parameter) 라 한다. 예를 들어 \\[\ny=f(\\boldsymbol{x}=(x_1, x_2)) = ax_1+bx_2+c = \\begin{bmatrix} 1 & a & b \\end{bmatrix}\\begin{bmatrix} 1 \\\\ x_1 \\\\ x_2 \\end{bmatrix}\n\\] 일 경우, 입력값은 \\(\\boldsymbol{x}=\\begin{bmatrix}x_1 & x_2\\end{bmatrix}^T\\), 매개변수는 \\(a, b, c\\), 출력값은 \\(y\\) 이다.\n기계학습을 통해 매개변수를 정해야 함수가 완성된다. 매개변수의 집합을 \\(\\boldsymbol{w}\\) 로 표기하여 함수를 다음과 같이 쓰기도 한다. \\[\ny=f(\\boldsymbol{x} ; \\boldsymbol{w})\n\\]\n출력값이 벡터일 경우는 다음과 같이 쓰기도 한다.\n\n\\[\n\\boldsymbol{y} = \\boldsymbol{f}(\\boldsymbol{x};\\boldsymbol{w})\n\\]\n\n데이터와 레이블의 쌍의 집합을 데이터셋이라고 하고 \\(i\\) 번째 데이터를 \\((\\boldsymbol{x}^{(i)},\\, \\boldsymbol{t}^{(i)})\\) 과 같이 표기하자. 함수가 얼마나 데이터를 잘 기술하는지를 평가하는 함수를 손실함수(Loss function) 혹은 비용함수(Cost function) 라고 한다. 대표적인 손실함수로는 신경망(Neural Network) 에서, 회귀의 경우 평균제곱오차 (Mean Square Error, MSE) 함수 와 분류의 경우 교차 엔트로피 오차 (Cross Entropy Error, CEE) 함수가 있다.\n\\[\n\\begin{aligned}\n\\text{MSE}(\\boldsymbol{w}) &= \\dfrac{1}{2} \\sum_{i=1}^N \\|\\boldsymbol{t}^{(i)} - f(\\boldsymbol{x}^{(i)}; \\boldsymbol{w})\\|^2 \\\\[0.3em]\n\\text{CEE}(\\boldsymbol{w}) &= -\\sum_{i=1}^N t^{(i)} \\ln (f(\\boldsymbol{x}^{(i)};\\boldsymbol{w}))\\\\[0.3em]\n\\end{aligned}\n\\] 여기에 대한 정확한 설명은 뒤로 미루기로 하자.\n기계학습을 통해 오차함수를 최소화 하는 매개변수들을 찾아 함수를 완성한다.\n손실 함수(Loss Function) \\(L(\\boldsymbol{w})\\) 의 특징\n\n\\(L(\\boldsymbol{w}) ≥ 0\\)\n\\(L(\\boldsymbol{w})\\) 는 미분가능 함수\n최적의 경우 = \\(L(\\boldsymbol{w})\\) 가 최소값이 되는 경우\n따라서 기계학습에서 학습이란 \\(L(\\boldsymbol{w})\\) 가 최소값이 되도록 하는 \\(\\boldsymbol{w}\\) 를 찾는 것이다. (최적화 (optimization))",
    "crumbs": [
      "Home",
      "기계 학습"
    ]
  },
  {
    "objectID": "src/theory/ML.html#통계학의-기본",
    "href": "src/theory/ML.html#통계학의-기본",
    "title": "기계 학습",
    "section": "통계학의 기본",
    "text": "통계학의 기본\n\n\n기본 개념\n\n표본 공간 (sample space) \\(\\Omega\\) : 실험/측정에 있어서 가능한 모든 결과값의 집합. \\(\\Omega\\) 의 각 원소들은 각각이 식별 가능하며, 상호 배타적(동시에 발생할 수 없음) 이어야 한다. 특정 결과값 \\(\\omega\\) 는 \\(\\Omega\\) 의 원소이다.\n사건 공간 (evant space) \\(\\mathcal{A}\\) : 실험/측정의 잠재적인 결과의 집합. 당연히 표본 공간 \\(\\Omega\\) 의 부분집합.\n확률 (probability) : \\(A\\in \\mathcal{A}\\) 에 대해 \\(A\\) 의 사건이 발생할 확률을 \\(p(A)\\) 라고 한다. 임의의 \\(A\\in \\mathcal{A}\\) 에 대해 \\(0\\le p(A)\\le 1\\) 이며 \\(\\sum_{A\\in \\Omega} p(A)=1\\) 이다.\n표적 공간 (target space) \\(\\mathcal{T}\\) : 우리가 관심있는 정량화된 값. 서로 구별되는 표적공간의 원소를 상태(state) 라고 한다.\n확률 변수 (random variable) : 표본공간의 성분 \\(\\omega\\) 와 표적공간의 성분 \\(t\\) 를 연결하는 함수 \\(X:\\Omega \\to \\mathcal{T}\\) 가 존재하며 이 \\(X\\) 를 확률변수 라고 한다.\n\n예를 들어 두개의 동전을 던져 이중 몇개의 동전이 앞면이 나오는 지 관심있다고 하자. 앞면을 \\(u\\), 뒷면을 \\(d\\) 라고 하면 \\(\\Omega = \\mathcal{A} = \\{ uu,\\, ud,\\,du,\\,dd\\}\\) 이며 \\(\\mathcal{T}=\\{0,\\,1,\\,2\\}\\) 가 된다. 이제 사건공간이 아닌 표적공간의 부분집합에 대한 확률에 관심을 갖게 된다. 즉 \\(S\\in \\mathcal{T}\\) 에 대해 \\(p(S)\\) 가 우리의 주요 관심사이다.\n표적공간 \\(\\mathcal{T}\\) 가 이산공간일 때 \\(X\\) 를 이산확률변수라고 하고 \\(\\mathbb{R}\\) 과 같이 연속일 때 연속확률변수라고 한다.\n\n\n\n이산 확률\n\n결합 확률(Joint Probability)\n확률변수 \\(X,\\,Y\\) 에 대해 \\(X\\) 는 \\(x_1,\\ldots,\\,x_M\\) 값을 가질 수 있으며, \\(Y\\) 는 \\(y_1,\\ldots,\\,y_L\\) 값을 가질 수 있다고 하자. 모두 \\(N\\) 번의 시행에서 \\(X=x_i,\\, Y=y_j\\) 가 나온 횟수를 \\(n_{ij}\\) 라 하자. \\(N\\) 번의 시행에서 \\(X=x_i\\) 인 횟수는 \\(c_i\\), \\(Y=y_j\\) 인 횟수는 \\(r_j\\) 라 하자. 즉, \\[\np(X=x_i,\\, Y=y_j)=\\dfrac{n_{ij}}{N},\\quad p(X=x_i)=\\dfrac{c_i}{N},\\quad p(Y=y_j)=\\dfrac{r_j}{N}\\;.\n\\tag{1}\\]\n이다. 이 때,\n\\[\np(X=x_i)=\\sum_{j=1}^L p(X=x_i,\\, Y=y_j)\n\\tag{2}\\]\n이며 (자명하다) 이를 sum rule 이라 한다. 여기서 \\(P(X=x_i)\\) 를 개별 사건의 확률로 주변 확률(marginal probability) 라 하기도 한다.\n\n\n\n조건부 확률(Conditional probability)\n\\(X=x_i\\) 인 상황에서 \\(Y=y_j\\) 인 확률을 \\(p(Y=y_j \\mid X=x_i)\\) 라 쓰며 \\(X=x_i\\) 일 때 \\(Y=y_j\\) 에 대한 조건부 확률(conditional probability) 이라고 하고 다음과 같이 주어진다. \\[\np(Y=y_j\\mid X=x_i)=\\dfrac{n_{ij}}{c_i}\n\\tag{3}\\]\n\n\n\n확률의 곱의 법칙(Product rule of probability)\n\\[\np(X=x_i,\\, Y=y_j)=\\dfrac{n_{ij}}N=\\dfrac{n_{ij}}{c_i}\\dfrac{c_i}{N}=P(Y=y_j\\mid X=x_i)\\cdot p(X=x_i)\\;.\n\\tag{4}\\]\n\n\n\n합과 곱의 규칙\n\\[\n\\begin{aligned}\n\\textbf{sum rule}&\\qquad p(X)=\\sum_Y p(X,\\,Y)\\,, \\\\\n\\textbf{product rule}& \\qquad p(X,\\,Y)=p(Y\\mid X)p(X)\n\\end{aligned}\n\\tag{5}\\]\n\n\n\n베이즈 정리(Bayes’ theorem)\n\\[\np(Y\\mid X)=\\dfrac{p(X\\mid Y) \\, p(Y)}{p(X)}\\;.\n\\tag{6}\\]\nWith sum rule, \\[\nP(X)=\\sum_{Y}p(X \\mid Y)\\, p(Y)\\,.\n\\tag{7}\\]\n\n\n변수의 독립성(Independence of variable)\n확률변수 \\(X,\\,Y\\) 에 때해 \\(p(X,\\,Y)=p(X)\\, p(Y)\\) 일 때 \\(X\\) 와 \\(Y\\) 는 서로 독립적(independent) 이라고 한다. \\(X,\\,Y\\) 가 서로 독립적이면 식 식 5 으로 부터 \\(p(Y|X)=p(Y)\\) 임을 알 수 있다.\n\n\n\n\n확률 밀도 함수\n표적공간이 연속일 때 확률은 확률밀도함수 \\(p(x)\\) 로 기술된다.\n\n확률밀도함수와 확률\n확률밀도함수 \\(p(x)\\)는 다음 두 조건을 만족해야 한다. \\[\n\\begin{align}\np(x) & \\ge 0\\\\\n\\int_{-\\infty}^\\infty p(x)\\,dx &=1\n\\end{align}\n\\tag{8}\\]\n연속확률변수일 때 \\(x\\in (a,\\,b)\\) 일 확률 \\(p(x\\in (a,\\,b))\\) 는 \\[\np(x\\in (a,\\,b))=\\int_a^b p(x)\\,dx\n\\tag{9}\\] 이다.\n\n\n\n변수의 변환\n\\(x=g(y)\\) 이며 \\(y\\) 에 대한 확률분포를 알고 싶을 때, 이 확률분포를 \\(p_y(y)\\) 라 하면, \\[\np_y(y)=p(x)\\left|\\dfrac{dx}{dy}\\right|=p(g(y))|g'(y)\n\\tag{10}\\] 임을 쉽게 보일 수 있다.\n\n\n\n누적 분포 함수\n\\(P(z)=p(x\\in (-\\infty,\\,z))\\) 를 누적 분포 함수(cumulative distribution function) 이라 하며, \\[\nP(z) = \\int_{-\\infty}^z p(x)\\, dx\n\\tag{11}\\]\n로 정의된다. \\(P'(x)=p(x)\\) 임은 십게 알 수 있다.\n다변수 \\(\\boldsymbol{x}=(x_1,\\ldots,\\,x_D)\\) 에 대한 확률분포는 \\(\\boldsymbol{x}\\) 를 포함하는 infinitesimal volume \\(\\delta \\boldsymbol{x}\\) 에 대해 \\(p(\\boldsymbol{x})\\,\\delta \\boldsymbol{x}\\) 로 주어지며 다음과 같은 성질을 만족한다.\n\\[\n\\begin{aligned}\np(\\boldsymbol{x}) & \\ge 0  \\\\\n\\int p(\\boldsymbol{x})\\,d\\boldsymbol{x}&= 1\n\\end{aligned}\n\\tag{12}\\]\n연속적인 변수, 이산적인 변수 모두에 대한 확률 분포함수를 probability density function 이라 하기도 하고, 이산적인 변수에 대해서 probability mass function 이라고 구분하여 부르기도 한다.\nSum rule과 Bayes’ theorem 을 생각하면 다음이 성립함을 알 수 있다. \\[\n\\begin{aligned}\np(x) &= \\int p(x,\\,y)\\, dy \\\\\np(x,\\,y)&=p(y| x)\\,p(x)\n\\end{aligned}\n\\tag{13}\\]\n\n\n\n\n기댓값과 공분산\n\n기댓값\n확률변수 \\(X\\) 에 대한 확률분포가 \\(p(x)\\) 일 때 \\(x\\) 에 대한 함수 \\(f(x)\\) 의 평균값을 \\(f\\) 에 대한 기댓값(expectation) 이라 하며 \\(\\mathbb{E}[f]\\) 로 표기하고 다음과 같다. \\[\n\\begin{align}\n\\mathbb{E}[f]&:=\\sum_x p(x) f(x) &&\\text{for descrete distribution,}\\\\\n&:=\\int  p(x) f(x)\\, dx& &\\text{for continuous distribution.}\n\\end{align}\n\\tag{14}\\]\n\\(N\\) 개의 sample 이 주어졌을 때 기댓값은 다음과 같이 근사 될 수 있다. \\[\n\\mathbb{E}[f] \\approx \\dfrac{1}{N} \\sum_{i=1}^N f(x_n).\n\\tag{15}\\]\n식 14 의 두 식은 식 15 의 \\(N \\to \\infty\\) 극한과 동일하다.\n다변수 확률분포에서 특정 변수에 대한 기댓값은 \\(\\mathbb{E}_x [f(x,\\,y)]\\) 와 같이 표기하며 다음과 같다. \\[\n\\mathbb{E}_x [f(x,\\,y)]=\\sum_x p (x,\\,y) f(x,\\,y) =\\int p(x,\\,y) f(x,\\,y)\\, dx\n\\tag{16}\\]\n\n\n\n조건부 기댓값\n\\(p(x\\,|\\,y)\\) 에 대한 \\(f(x)\\) 의 기댓값은 다음과 같다. \\[\n\\mathbb{E}_x [f \\mid y\\,]= \\sum_x p(x\\,|\\, y)\\, f(x)\n\\tag{17}\\]\n\n\n\n분산\n\\(f(x)\\) 에 대한 분산(variance) \\(\\text{Var}[f]\\) 는 다음과 같이 정의된다. \\[\n\\begin{aligned}\n\\operatorname{Var}[f] & := \\mathbb{E}\\left[(f(x)-\\mathbb{E}[f(x)])^2\\right] \\\\[0.3em]\n&=\\mathbb{E}[f(x)^2]-(\\mathbb{E}[f(x)])^2\\;\n\\end{aligned}\n\\tag{18}\\]\n이다. 변수 \\(x\\) 자체에 대한 분산 \\(\\text{Var}[x]\\) 는 다음과 같다. \\[\n\\operatorname{Var}[x]=\\mathbb{E}[x^2]-\\mathbb{E}[x]^2.\n\\tag{19}\\]\n\n\n\n공분산\n아래와 같이 정의되는 \\(\\text{Cov}[x,\\,y]\\) 를 \\(X,\\,Y\\) 에 대한 공분산(covariance) 라고 한다. \\[\n\\begin{align}\n\\operatorname{Cov}[x,\\,y]&:= \\mathbb{E}_{x,\\,y} \\left[(x-\\mathbb{E}[x]) (y-\\mathbb{E}[y])\\right] \\\\\n&=\\mathbb{E}_{x,\\,y}[xy] -\\mathbb{E}[x] \\mathbb{E}[y].\n\\end{align}\n\\tag{20}\\]\n\\(x,\\,y\\) 가 서로 독립이면 \\(\\operatorname{Cov}[x,\\,y]=0\\) 이다.\n두 확률 변수가 벡터 \\(\\boldsymbol{x},\\, \\boldsymbol{y}\\) 이면 \\[\n\\begin{aligned}\n\\operatorname{Cov}[\\boldsymbol{x},\\, \\boldsymbol{y}]&= \\mathbb{E}_{\\boldsymbol{x},\\, \\boldsymbol{y}}\\left[\\left( \\boldsymbol{x}-\\mathbb{E}[\\boldsymbol{x}]\\right)\\left( \\boldsymbol{y}^T-\\mathbb{E}[\\boldsymbol{y}^T]\\right)\\right] \\\\[0.3em]\n&=\\mathbb{E}_{\\boldsymbol{x},\\,\\boldsymbol{y}}[\\boldsymbol{x}\\boldsymbol{y}^T]-\\mathbb{E}[\\boldsymbol{x}]\\,\\mathbb{E}[\\boldsymbol{y}^T]\n\\end{aligned}\n\\tag{21}\\]\n이다. \\(\\operatorname{Cov}[\\boldsymbol{x}] := \\operatorname{Cov}[\\boldsymbol{x},\\,\\boldsymbol{x}]\\) 로 정의한다.",
    "crumbs": [
      "Home",
      "기계 학습"
    ]
  },
  {
    "objectID": "src/theory/optimization.html",
    "href": "src/theory/optimization.html",
    "title": "2  최적화",
    "section": "",
    "text": "1 최적화",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>최적화</span>"
    ]
  },
  {
    "objectID": "src/theory/optimization.html#최적화",
    "href": "src/theory/optimization.html#최적화",
    "title": "2  최적화",
    "section": "",
    "text": "1.1 최적화문제\n일반적으로 최적화 문제는 어떤 함수 \\(f:U \\subset \\mathbb{R}^n \\to \\mathbb{R}\\) 에 대해 아래의 \\(\\boldsymbol{\\theta}^\\ast\\) 문제를 구하는 것으로 주어진다.\n\\[\n\\boxed{\n\\begin{aligned}\n\\quad& \\boldsymbol{\\theta}^\\ast = \\argmin_{\\boldsymbol{\\theta}\\in U} && f(\\boldsymbol{\\theta}) \\\\[0.3em]\n&\\text{subject to} \\quad && g_i(\\boldsymbol{\\theta})\\le 0,\\qquad i = 1,\\ldots,\\,m\\\\[0.3em]\n&&& h_j(\\boldsymbol{\\theta})= 0,\\qquad j=1,\\ldots,\\,k.\\quad\n\\end{aligned}\n}\n\\tag{1}\\]\n\n\n3가지 기본 요소\n (\\(1\\)) 변수 (Decesion variable or unknown) \\(\\boldsymbol{\\theta}\\in \\mathbb{R}^n\\)\n (\\(2\\)) 목적함수 (objective function) \\(f:\\mathbb{R}^n \\to \\mathbb{R}\\)\n (\\(3\\)) 제약 조건 (Constraint) : 식 1 에 주어진 \\(g_i(\\boldsymbol{\\theta}) \\le 0,\\, h_j(\\boldsymbol{\\theta})=0\\) 의 조건들.\n\n\n\n과정\n (\\(1\\)) 모델링 : 목적함수, 변수, 제약조건을 찾고 확인한다.\n (\\(2\\)) 모델을 만든 후 최적화 알고리즘을 사용하여 해를 구한다.\n\n\n\n\n1.2 최적화의 수학 모델\n\n수학적 표준 모델\n\n제약조건을 만족하는 \\(\\mathcal{C}\\subset \\mathbb{R}^n\\) 를 가능해 영역(feasible region) 이라고 한다. 식 1 과 같은 최적화 문제에 대해 \\(\\mathcal{C}\\) 는 아래와 같다. \\[\n\\mathcal{C} = \\{\\boldsymbol{\\theta}\\in U : g_i(\\boldsymbol{\\theta})\\le 0,\\,i=1,\\ldots,\\,m,\\, h_j(\\boldsymbol{\\theta})=0,\\, j=1,\\ldots,\\,k\\}.\n\\tag{2}\\]\n식 1 을 짧게 쓰면 가능해 영역 \\(\\mathcal{C}\\) 에 대해 \\(\\displaystyle \\boldsymbol{\\theta}^\\ast = \\argmin_{\\boldsymbol{\\theta}\\in \\mathcal{C}} f(\\boldsymbol{\\theta})\\) 를 찾는 문제이다. 이 \\(\\boldsymbol{\\theta}^\\ast\\) 를 최적해 (optimal solution) 이라고 한다.\n\\(\\{g_i\\}\\) 나 \\(\\{h_j\\}\\) 와 같은 제약조건이 없다면 unconstrained 라고 하며, 그렇지 않다면 constrained 라고 한다.\n\n\n\n\n등가 변환\n\n우리가 구하고자 하는 문제가 \\(f(\\boldsymbol{\\theta})\\) 를 최소화 하는 것이 아닌 최대로 하는 \\(\\boldsymbol{\\theta}\\) 를 찾는 문제라면 \\(-f(\\boldsymbol{\\theta})\\) 를 최소화 하는 문제이다.\nconstraint 가 \\(g_i(\\boldsymbol{\\theta}) \\ge 0\\) 이라면 \\(-g_i(\\boldsymbol{\\theta})\\le 0\\) 으로 바꿀 수 있다.\n즉 수학적 표준 모델은 상당히 표면적으로 보이는 것보다 훨씬 넓은 범위의 문제를 포괄한다.\n\n\n\n\n\n1.3 전역적 최적화와 국소적 최적화\n함수 \\(f(x)\\) 가 아래 그림과 같다고 하자.\n\n\n\n\n\n\n그림 1: 전역적 최소와 국소적 최소\n\n\n\n전체 영역에서의 최소점은 \\(x_G\\) 이며 이를 전역적 최소점(global minimum) 이라고 한다. 그리고 \\(x_L\\) 같이 어떤 근방에서의 최소점을 국소적 최소점(local minimum) 혹은 극소점 이라고 한다. 함수 \\(f(x)\\) 가 단 하나의 국소적 최소점을 갖는다는 보장이 없으며, 또한 많은 알고리즘은 전역적 최소점이 아닌 국소적 최소점을 찾는다. \\(f(x)\\) 가 두번 미분 가능할 경우 국소적 최소점은 보통 미분이 \\(0\\) 이고 이차미분이 양수인 점이다. 다변수의 경우 \\(\\nabla f(\\boldsymbol{\\theta})=\\boldsymbol{0}\\) 이며 헤시안 행렬 \\(\\boldsymbol{H}_f\\) 가 positive definite 한 경우이다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>최적화</span>"
    ]
  },
  {
    "objectID": "src/theory/optimization.html#볼록-최적화-convex-optimization",
    "href": "src/theory/optimization.html#볼록-최적화-convex-optimization",
    "title": "2  최적화",
    "section": "2 볼록 최적화 (Convex optimization)",
    "text": "2 볼록 최적화 (Convex optimization)\n\n2.1 볼록 함수와 볼록 집합\n\n\n\n\n\n\n\n정의 1 (볼록 함수 (convex function)) \\(f:\\mathbb{R}^n\\to\\mathbb{R}\\) 이 다음을 만족하면 볼록 함수라고 한다. \\[\n\\forall s\\in [0,\\,1],\\, \\boldsymbol{x},\\, \\boldsymbol{y}\\in \\mathbb{R}^n \\implies f(s \\boldsymbol{x}+(1-s)\\boldsymbol{y}) \\le s f(\\boldsymbol{x}) + (1-s)f(\\boldsymbol{y})\n\\tag{3}\\]\n\n\n정의 2 (볼록 집합 (convex set)) \\(A\\subset\\mathbb{R}^n\\) 이 다음을 만족하면 볼록 집합이라 한다.\n\\[\n\\forall s\\in [0,\\,1],\\, \\boldsymbol{x},\\, \\boldsymbol{y}\\in A \\implies s \\boldsymbol{x}+(1-s)\\boldsymbol{y}\\in A\n\\tag{4}\\]\n\n\n\n\n\n\n\n2.2 볼록 최적화\n식 1 의 최적화 문제가 주어졌다고 하자. 이 때 목적함수가 볼록 함수 이고 가능해 영역 이 볼록 집합인 경우의 최적화 문제를 볼록 최적화 (convex optimization) 문제 라고 한다.\n\n\\(g_i(\\boldsymbol{\\theta})\\) 가 볼록 함수이고 \\(h_j(\\boldsymbol{\\theta})=\\boldsymbol{a}^T\\boldsymbol{\\theta}+b\\) 꼴이면 항상 볼록 최적화 문제이다.\n볼록 최적화에서의 모든 국소적 해는 전역적 해이다. (정리 1)\n\n\n\n\n정리 1 볼록 최적화 문제에서 목적함수 \\(f:\\mathbb{R}^n \\to \\mathbb{R}\\) 과 가능해 공간 \\(\\mathcal{C}\\) 에 대해 국소적 최소점은 전역적 최소점이다.\n\n\n\n\n(증명). \\(\\boldsymbol{\\theta}^\\ast\\) 가 국소적 최소점이며 \\(\\boldsymbol{\\theta}_G \\ne \\boldsymbol{\\theta}^\\ast\\) 가 전역적 최소점이라고 하자. 즉 \\(f(\\boldsymbol{\\theta}_G)&lt;f(\\boldsymbol{\\theta}^\\ast)\\) 이다. \\(s\\in [0,\\,1]\\) 에 대해 \\(s\\boldsymbol{\\theta}^\\ast + (1-s)\\boldsymbol{\\theta}_G\\in \\mathcal{C}\\) 이며\n\\[\n\\begin{aligned}\nf(s \\boldsymbol{\\theta}^\\ast + (1-s)\\boldsymbol{\\theta}_G) &\\le s f(\\boldsymbol{\\theta}^\\ast) + (1-s)f(\\boldsymbol{\\theta}_G) \\\\[0.3em]\n& &lt; s f(\\boldsymbol{\\theta}^\\ast) + (1-s)f(\\boldsymbol{\\theta}^\\ast) = f(\\boldsymbol{\\theta}^\\ast)\n\\end{aligned}\n\\]\n이다. 즉 \\(f(\\boldsymbol{\\theta}^\\ast)\\) 가 국소적 해라는 전제에 모순이므로 국소적 해와 다른 전역적 해는 존재하지 않는다. \\(\\square\\)\n\n\n국소적 최저점이 전역적 최저점이라고 해서 단 하나의 국소적 최저점만 가질 필요는 없다. 여러개의 최적해가 존재할 때 다음의 성질을 갖는다.\n\n\n\n정리 2 볼록 최적화 문제의 해 가 하나 이상일 때 해의 집합을 \\(X\\) 라고 하자. 즉 \\(\\displaystyle X = \\argmin_{\\boldsymbol{\\theta}\\in \\mathcal{C}} f(\\boldsymbol{\\theta})\\) 라고 하면 \\(X\\) 는 볼록집합이다.\n\n\n\n\n(증명). \\(\\boldsymbol{\\theta}_1,\\, \\boldsymbol{\\theta}_2\\in X\\) 라고 하자. \\(\\mathcal{C}\\) 가 볼록집합이므로 \\(s\\in [0,\\,1]\\) 에 대해 \\(s \\boldsymbol{\\theta}_1 + (1-s)\\boldsymbol{\\theta}_2 \\in \\mathcal{C}\\) 이다. 또한 \\(\\boldsymbol{\\theta}_1,\\,\\boldsymbol{\\theta}_2\\) 가 전역적 최소점이므로 \\(f(\\boldsymbol{\\theta}_1)=f(\\boldsymbol{\\theta}_2)=f_m\\) 이다. 이로부터\n\\[\n\\begin{aligned}\nf(s \\boldsymbol{\\theta}_1 + (1-s)\\boldsymbol{\\theta}_2) & \\le s f(\\boldsymbol{\\theta}_1) + (1-s)f(\\boldsymbol{\\theta}_2) = f_m\n\\end{aligned}\n\\]\n그런데 \\(f(s \\boldsymbol{\\theta}_1 + (1-s)\\boldsymbol{\\theta}_2) \\ge f_m\\) 이어야 하므로 \\(f(s\\boldsymbol{\\theta}_1 + (1-s)\\boldsymbol{\\theta}_2) =f_m\\) 이다. \\(\\square\\)",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>최적화</span>"
    ]
  },
  {
    "objectID": "src/theory/optimization.html#선형계획법",
    "href": "src/theory/optimization.html#선형계획법",
    "title": "2  최적화",
    "section": "3 선형계획법",
    "text": "3 선형계획법\n일반적으로 선형계획법 문제는 다음과 같은 형태로 주어진다.\n\\[\n\\boxed{\n\\begin{aligned}\n\\quad \\boldsymbol{\\theta}^\\ast = \\argmin_{\\boldsymbol{\\theta}\\in U} f(\\boldsymbol{x}), \\quad &&f(\\boldsymbol{\\theta}) = \\boldsymbol{c}^T\\boldsymbol{\\theta} \\\\[0.3em]\n&&\\text{subject to} \\quad & \\boldsymbol{g}_i^T\\boldsymbol{\\theta}\\le b_j,\\qquad && i = 1,\\ldots,\\,m,\\\\[0.3em]\n&&& \\boldsymbol{h}_j^T\\boldsymbol{\\theta}= a_j,\\qquad &&j=1,\\ldots,\\,k.\\quad\n\\end{aligned}\n}\n\\tag{5}\\]\n\n즉 선형계획법에서는\n\n목적함수는 변수에 대한 선형함수이며\n제한조건은 변수에 대한 affine 함수 (\\(\\boldsymbol{a}^T\\boldsymbol{\\theta}+b\\) 형태의 함수) 이다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>최적화</span>"
    ]
  },
  {
    "objectID": "src/theory/optimization.html#unconstrained-convex-optimizaiton-문제",
    "href": "src/theory/optimization.html#unconstrained-convex-optimizaiton-문제",
    "title": "2  최적화",
    "section": "4 Unconstrained convex optimizaiton 문제",
    "text": "4 Unconstrained convex optimizaiton 문제\n\n\\(\\nabla_\\boldsymbol{\\theta}f(\\boldsymbol{\\theta}^\\ast)=\\boldsymbol{0}\\) 인 \\(\\boldsymbol{\\theta}^\\ast\\) 를 찾는 문제이다.\n\n\\[\n\\nabla_\\boldsymbol{\\theta} f := \\begin{bmatrix} \\dfrac{\\partial f}{\\partial \\theta_1} \\\\ \\vdots \\\\ \\dfrac{\\partial f}{\\partial \\theta_n}\\end{bmatrix}\n\\tag{6}\\]\n이와 유사하게\n\\[\n\\dfrac{df}{d\\boldsymbol{\\theta}} := \\begin{bmatrix} \\dfrac{\\partial f}{\\partial \\theta_1} & \\cdots & \\dfrac{\\partial f}{\\partial \\theta_n}\\end{bmatrix}\n\\tag{7}\\]\n로 정의한다. 즉 \\(\\nabla_{\\boldsymbol{\\theta}}f\\) 는 열벡터이며 \\(\\dfrac{d f}{d\\boldsymbol{\\theta}}\\) 는 행벡터이다.\n\n\n4.1 Gradient\n\\(\\boldsymbol{\\theta} = \\begin{bmatrix}\\theta_1 & \\cdots & \\theta_n \\end{bmatrix}^T \\in \\mathbb{R}^n\\), \\(\\boldsymbol{a} \\in \\mathbb{R}^n\\), \\(\\boldsymbol{A}=\\mathcal{M}_{m \\times n}(\\mathbb{R})\\) 일 때 \\(\\boldsymbol{\\theta}\\) 에 대한 스칼라 함수의 gradient 는 다음과 같다.\n\\[\n\\begin{aligned}\n\\nabla_\\boldsymbol{\\theta} (\\boldsymbol{a}^T\\boldsymbol{\\theta}) &= \\boldsymbol{a}\\\\[0.3em]\n\\nabla_\\boldsymbol{\\theta} (\\boldsymbol{\\theta}^T\\boldsymbol{a}) &= \\boldsymbol{a}\\\\[0.3em]\n\\nabla_\\boldsymbol{\\theta} (\\boldsymbol{\\theta}^T\\boldsymbol{\\theta}) &= 2\\boldsymbol{\\theta}\\\\[0.3em]\n\\nabla_{\\boldsymbol{\\theta}} (\\boldsymbol{\\theta}^T\\boldsymbol{A\\theta}) &= (\\boldsymbol{A}^T +\\boldsymbol{A})\\boldsymbol{\\theta}\n\\end{aligned}\n\\tag{8}\\]\n\n\n\n4.2 직접법\n\n\\(\\nabla_\\boldsymbol{\\theta}f(\\boldsymbol{\\theta}^\\ast)=\\boldsymbol{0}\\) 인 \\(\\boldsymbol{\\theta}^\\ast\\) 를 직접 구한다.\n\n\n이제 몇가지 형태의 convex 함수인 목적함수에 대한 그래디언트 \\(\\nabla_{\\boldsymbol{\\theta}}f(\\boldsymbol{\\theta})\\) 와 헤시안 행렬 \\(\\boldsymbol{H}_f\\) 를 구해보자.\n\n\n예제 1 (Affine 형태의 목적함수) \\(f(\\boldsymbol{\\theta}) = \\boldsymbol{a}^T\\boldsymbol{\\theta} + \\boldsymbol{b}\\) 인 경우\n\\[\n\\nabla_\\boldsymbol{\\theta}f(\\boldsymbol{\\theta})=\\boldsymbol{a},\\qquad \\boldsymbol{H}_f = \\boldsymbol{0}.\n\\]\n이다. 따라서 \\(\\boldsymbol{a}=\\boldsymbol{0}\\) 인 특별한 경우가 아니면 최소값이 존재하지 않는다.\n\n\n\n\n\n예제 2 (Quadratic 형태의 목적함수) 대칭행렬 \\(\\boldsymbol{P}\\) 에 대해 \\(f(\\boldsymbol{\\theta}) = \\boldsymbol{\\theta}^T\\boldsymbol{P\\theta} + \\boldsymbol{b}^T\\boldsymbol{\\theta}+c\\) 인 경우\n\\[\n\\nabla_{\\boldsymbol{\\theta}}f(\\boldsymbol{\\theta})= 2\\boldsymbol{P\\theta} + \\boldsymbol{b},\\qquad \\boldsymbol{H}_f = 2\\boldsymbol{P}\n\\]\n이다.\n\n\n\n\n\n예제 3 (제곱 형태의 목적함수) 대칭행렬 \\(\\boldsymbol{P}\\) 에 대해 \\(f(\\boldsymbol{\\theta}) = \\|\\boldsymbol{A\\theta}-\\boldsymbol{b}\\|_2^2\\) 인 경우\n\\[\nf(\\boldsymbol{\\theta})= \\boldsymbol{\\theta}^T\\boldsymbol{A}^T\\boldsymbol{A\\theta} - \\boldsymbol{\\theta}^T\\boldsymbol{A}^T\\boldsymbol{b}-\\boldsymbol{b}^T\\boldsymbol{A\\theta}+\\boldsymbol{b}^T\\boldsymbol{b}\n\\]\n이므로 gradient 와 헤시안 행렬은 다음과 같다.\n\\[\n\\nabla_{\\boldsymbol{\\theta}}f(\\boldsymbol{\\theta})= 2\\boldsymbol{A}^T\\boldsymbol{A\\theta} -2\\boldsymbol{A}^T\\boldsymbol{b},\\qquad \\boldsymbol{H}_f = 2\\boldsymbol{A}^T\\boldsymbol{A}.\n\\]\n이 때 \\(\\boldsymbol{\\theta}^\\ast = (\\boldsymbol{A}^T\\boldsymbol{A})^{-1}\\boldsymbol{A}^T\\boldsymbol{b}\\) 이어야 한다. 이 때 \\((\\boldsymbol{A}^T\\boldsymbol{A})^{-1}\\boldsymbol{A}^T\\) 는 잘 알려진 무어-펜로즈 좌측 유사역행렬(left pseudoinverse matrix) 이다.\n\n\n\n\n\n4.3 경사 하강법(Gradient descent)\n미분 가능한 \\(f(\\boldsymbol{\\theta})\\) 에 대해 \\(\\boldsymbol{\\theta}_0\\) 가 주어졌으며 충분히 작은 값 \\(\\alpha_k\\) 에 대해 \\(\\boldsymbol{\\theta}_{k+1}\\) 이 다음과 같다고 하자.\n\\[\n\\boldsymbol{\\theta}_{k+1} = \\boldsymbol{\\theta}_k -\\alpha_k \\nabla_\\boldsymbol{\\theta} f(\\boldsymbol{\\theta}_k)\n\\]\n그렇다면 \\(f(\\boldsymbol{\\theta}_{k+1}) &lt; f(\\boldsymbol{\\theta}_k)\\) 가 될 것이고 이것을 계속 반복해 나가면 \\(f(\\boldsymbol{\\theta})\\) 의 국소적 최저점을 찾을 수 있다. 이것을 경사 하강법(gradient descent method) 이라고 한다.\n\n\n\n4.4 뉴턴법\n\\(f:U \\subset \\mathbb{R}\\to R\\) 인 함수에 대해 \\(f(\\theta)=0\\) 을 찾는 방법 가운데 뉴턴-랩슨 방법은 초기값 \\(\\theta_0\\) 를 주고\n\\[\n\\theta_{k+1} = \\theta_k - \\dfrac{f(\\theta_k)}{f'(\\theta_k)}\n\\]\n를 통해 점진적으로 \\(f(\\theta)=0\\) 을 찾는 방법이다. 만약 \\(f\\in C_2\\) 라면 \\(f'(\\theta^\\ast)=0\\) 의 해는 뉴턴-랩슨 방법을 사용하여\n\\[\n\\theta_{k+1}=\\theta_k - \\dfrac{f'(\\theta_k)}{f''(\\theta_k)}\n\\]\n를 통해 얻을 수 있다. 만약 \\(f:\\mathbb{R}^n \\to \\mathbb{R}\\) 이\n\\[\nf(\\boldsymbol{\\theta}) = \\|\\boldsymbol{A\\theta}-\\boldsymbol{b}\\|_2^2\n\\]\n으로 주어졌다면 예제 3 로 부터\n\\[\n\\boldsymbol{\\theta}_{k+1}= \\boldsymbol{\\theta}_k - \\left(\\boldsymbol{H}_f\\right)^{-1} \\nabla_\\boldsymbol{\\theta} f(\\boldsymbol{\\theta}_k) = \\boldsymbol{\\theta}_k - (\\boldsymbol{A}^T\\boldsymbol{A})^{-1}\\boldsymbol{A}^T(\\boldsymbol{A}\\boldsymbol{\\theta}_k-\\boldsymbol{b})\n\\]\n를 이용하여 반복적으로 최적해 \\(\\boldsymbol{\\theta}^\\ast\\) 를 찾는다. 뉴턴법은 경사하강법에 비해 수렴속도가 빠르지만 1) 헤세 행렬 \\(\\boldsymbol{H}_f\\) 를 구해야 하며, 2) 헤세 행렬에 대한 역행렬도 구해야 한다. 이 둘 모두 큰 계산량을 요구한다.\n\n\n\n4.5 준-뉴턴법(Quasi-Newton method)\n뉴턴법의 큰 계산량을 줄이기 위해 고안된 방법이다. \\(f(\\boldsymbol{\\theta})\\) 를 2차 근사하면 헤세 행렬 \\(\\boldsymbol{H}_f\\) 에 대해 다음과 같다.\n\n\\[\nf(\\boldsymbol{\\theta} + \\Delta \\boldsymbol{\\theta}) \\approx f(\\boldsymbol{\\theta}) + \\dfrac{df(\\boldsymbol{\\theta})}{d\\boldsymbol{\\theta}} \\cdot \\Delta \\boldsymbol{\\theta} + \\dfrac{1}{2} \\Delta \\boldsymbol{\\theta}^T \\boldsymbol{H}_f\\Delta \\boldsymbol{\\theta}\n\\]\n뉴턴법에서는 최적해 \\(\\boldsymbol{\\theta}^\\ast\\) 에 대한 추정값 \\(\\boldsymbol{\\theta}_0\\) 을 입력하고 헤세 행렬을 직접 계산했지만 여기서는 \\(\\boldsymbol{\\theta}_0\\) 뿐만 아니라 헤세 행렬에 대한 추정값 \\(\\boldsymbol{B}_0\\) 도 입력하며 \\(\\boldsymbol{\\theta}_k\\) 뿐만 아니라 헤세 행렬에 상응하는 행렬 \\(\\boldsymbol{B}_k\\) 도 계속 업데이트 한다.\n\\[\n\\begin{aligned}\nf(\\boldsymbol{\\theta}_k + \\boldsymbol{\\epsilon}_k) &\\approx f(\\boldsymbol{\\theta}_k) + \\dfrac{df(\\boldsymbol{\\theta})}{d\\boldsymbol{\\theta}} \\cdot \\boldsymbol{\\epsilon}_k + \\dfrac{1}{2} (\\boldsymbol{\\epsilon}_k)^T\\cdot  \\boldsymbol{B}_k \\cdot ( \\boldsymbol{\\epsilon}_k) \\\\[0.3em]\n\\nabla_{\\boldsymbol{\\epsilon}_k} f(\\boldsymbol{\\theta}_k + \\boldsymbol{\\epsilon}_k) &\\approx  \\nabla_{\\boldsymbol{\\theta}}f(\\boldsymbol{\\theta}_k) + \\boldsymbol{B}_k\\boldsymbol{\\epsilon}_k\n\\end{aligned}\n\\]\n을 이용한다. 위의 식 가운데 두번째에서 \\(\\boldsymbol{\\theta}_k + \\boldsymbol{\\epsilon}_k\\) 가 극소점에 다가가면 \\(0\\) 에 가깝게 될 것이므로 \\(\\boldsymbol{\\epsilon}_k = - \\boldsymbol{B}_k^{-1}\\cdot \\nabla_{\\boldsymbol{\\theta}}f(\\boldsymbol{\\theta}_k)\\) 로 근사한다. 그렇다면\n\\[\n\\boldsymbol{\\theta}_{k+1} = \\boldsymbol{\\theta}_k +\\boldsymbol{\\epsilon}_k = \\boldsymbol{\\theta}_k -\\boldsymbol{B}_k^{-1} \\cdot \\nabla_{\\boldsymbol{\\theta}}f(\\boldsymbol{\\theta})\n\\]\n로 업데이트 한다. 이것은 뉴턴법과 차이가 없지만 준 뉴턴법은 \\(\\boldsymbol{B}_k\\) 를 구하는 방법에 따라 BFGS, DFP, SR1, Broyden 등의 여러가지 세부 방법이 있다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>최적화</span>"
    ]
  },
  {
    "objectID": "src/theory/optimization.html#등식-제약이-주어졌을-때",
    "href": "src/theory/optimization.html#등식-제약이-주어졌을-때",
    "title": "2  최적화",
    "section": "5 등식 제약이 주어졌을 때",
    "text": "5 등식 제약이 주어졌을 때\n\n5.1 라그랑주 승수법\n라그랑주 승수법은 다음과 같이 기술되는 문제에 사용된다. 즉 제한조건이 등식 형태로만 주어진 경우이다.\n\\[\n\\boxed{\n\\begin{aligned}\n\\quad&\\min_{\\boldsymbol{\\theta}} && f(\\boldsymbol{\\theta}) \\\\[0.3em]\n&\\text{subject to} \\quad && h_j(\\boldsymbol{\\theta})= 0,\\qquad j=1,\\ldots,\\,k.\\quad\n\\end{aligned}\n}\n\\tag{9}\\]\n아래의 정리는 잘 알려져 있다.\n\n\n\n정리 3 (라그랑주 승수법) \\(\\mathbb{R}^n\\) 에서의 열린 영역 \\(U\\) 에서 정의된 미분가능한 \\(f:U \\to \\mathbb{R}\\) 와 \\(C_1\\) 급 함수 \\(h_i : U \\to \\mathbb{R},\\, i=1,\\ldots,\\,M\\) 에 대해 가능해 영역 \\(\\mathcal{C}\\) 가 다음과 같이 \\(h_i(\\boldsymbol{\\theta})=0\\) 을 만족하는 형태로만 주어졌다고 하자.\n\\[\n\\mathcal{C} = \\{\\boldsymbol{\\theta}\\in U: \\boldsymbol{\\theta}\\in h_i(\\boldsymbol{\\theta})=0,\\, i=1,\\ldots,\\,M\\}\n\\]\n각각의 \\(\\boldsymbol{\\theta}\\in \\mathcal{C}\\) 에 대해 \\(\\nabla_{\\boldsymbol{\\theta}} h_1(\\boldsymbol{\\theta}),\\ldots,\\,\\nabla_{\\boldsymbol{\\theta}}h_M(\\boldsymbol{\\theta})\\) 가 선형 독립일 때 \\(f\\) 를 \\(\\mathcal{C}\\) 로 제한한 \\(f|_{\\mathcal{C}}\\) 의 극점 \\(\\boldsymbol{\\theta}^\\ast\\) 가 존재한다면\n\\[\n\\nabla_{\\boldsymbol{\\theta}}f(\\boldsymbol{\\theta}^\\ast) = \\sum_{i=1}^M \\lambda_i \\nabla_\\boldsymbol{\\theta}h_i(\\boldsymbol{\\theta}^\\ast)\n\\tag{10}\\]\n인 \\(\\lambda_i,\\, i=1,\\ldots,\\,M\\) 가 존재한다.\n\n\n\n목적함수 \\(f(\\boldsymbol{\\theta})\\) 에 대해 \\(h_i(\\boldsymbol{\\theta})=0,\\, (i=1,\\ldots,\\,M)\\) 의 제약조건이 주어졌다고 하자. 이 때 식 10 을 만족하는 \\(\\boldsymbol{\\theta}^\\ast\\) 는 가능해 영역 \\(\\mathcal{C}\\) 에서의 \\(f(\\boldsymbol{\\theta})\\) 의 stationary point 이다. 극소점일 수도, 극대점일 수도 saddle point 일 수도 있다.\n\n극소점인지 확인해야 한다.\n만약 \\(U\\) 의 경계를 포함하는 영역에서의 극소점을 찾는다면 경계에서의 값은 별도로 찾아서 비교해야 한다.\n\n\n\n\n5.2 KKH\n문제가 다음과 같이 주어졌다고 하자.\n\\[\n\\boxed{\n\\begin{aligned}\n\\quad&\\min_{\\boldsymbol{\\theta}} && f(\\boldsymbol{\\theta}) \\\\[0.3em]\n&\\text{subject to} \\quad && g_i(\\boldsymbol{\\theta})\\le 0,\\qquad i = 1,\\ldots,\\,m\\\\[0.3em]\n&&& h_j(\\boldsymbol{\\theta})= 0,\\qquad j=1,\\ldots,\\,k.\\quad\n\\end{aligned}\n}\n\\tag{11}\\]\nKKH 조건, 즉 Karush-Kuhn-Tucker conditions 는 \\(\\boldsymbol{\\theta}^\\ast\\) 의 필요조건의 나열이다.\n (\\(1\\)) \\(\\displaystyle \\nabla_{\\boldsymbol{\\theta}} f(\\boldsymbol{\\theta}) + \\sum_{i=1}^m \\lambda_i \\nabla_{\\boldsymbol{\\theta}}g_i(\\boldsymbol{\\theta}) + \\sum_{j=1}^k \\nabla_{\\boldsymbol{\\theta}} \\mu_j h_j(\\boldsymbol{\\theta})=0\\) 을 만족하는 \\(\\{\\lambda_i\\}\\) 와 \\(\\{\\mu_j\\}\\) 가 존재한다.\n (\\(2\\)) \\(\\mu_j h_j(\\boldsymbol{\\theta})\\) 이다. 즉 \\(\\mu_j\\) 와 \\(h_j(\\boldsymbol{\\theta})\\) 가운데 하나는 \\(0\\) 이다.\n (\\(3\\)) \\(j=1,\\ldots,\\,k\\) 에 대해 \\(\\mu_j\\ge 0\\) 이다.",
    "crumbs": [
      "Home",
      "기계 학습",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>최적화</span>"
    ]
  }
]