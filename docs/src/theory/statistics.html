<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; 통계학 이론 – MachineLearning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../src/theory/ML_basics.html" rel="next">
<link href="../../src/theory/regression.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-b467865d89f01302b3bb45791fa41ab5.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "일치 없음",
    "search-matching-documents-text": "일치된 문서",
    "search-copy-link-title": "검색 링크 복사",
    "search-hide-matches-text": "추가 검색 결과 숨기기",
    "search-more-match-text": "추가 검색결과",
    "search-more-matches-text": "추가 검색결과",
    "search-clear-button-title": "제거",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "취소",
    "search-submit-button-title": "검색",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">MachineLearning</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="탐색 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../about.qmd"> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="사이드바 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../src/theory/ML.html">기계학습</a></li><li class="breadcrumb-item"><a href="../../src/theory/statistics.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">통계학 이론</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="사이드바 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">MachineLearning</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../src/theory/ML.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">기계학습</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/theory/optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">최적화</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/theory/regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">선형 회귀</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/theory/statistics.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">통계학 이론</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/theory/ML_basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">기계학습의 기초</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/theory/classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">퍼셉트론과 분류</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/theory/perceptron_and_ann.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">퍼셉트론과 인공신경망</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/theory/cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">합성곱 신경망</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">목차</h2>
   
  <ul>
  <li><a href="#통계학의-기본" id="toc-통계학의-기본" class="nav-link active" data-scroll-target="#통계학의-기본"><span class="header-section-number">3.1</span> 통계학의 기본</a>
  <ul class="collapse">
  <li><a href="#기본-개념" id="toc-기본-개념" class="nav-link" data-scroll-target="#기본-개념"><span class="header-section-number">3.1.1</span> 기본 개념</a></li>
  <li><a href="#sec-ML_probability_discrete_variable" id="toc-sec-ML_probability_discrete_variable" class="nav-link" data-scroll-target="#sec-ML_probability_discrete_variable"><span class="header-section-number">3.1.2</span> 이산 확률 변수</a></li>
  <li><a href="#sec-ML_probability_continuous_variable" id="toc-sec-ML_probability_continuous_variable" class="nav-link" data-scroll-target="#sec-ML_probability_continuous_variable"><span class="header-section-number">3.1.3</span> 연속 확률 변수</a></li>
  <li><a href="#sec-ML_probability_expectation_value" id="toc-sec-ML_probability_expectation_value" class="nav-link" data-scroll-target="#sec-ML_probability_expectation_value"><span class="header-section-number">3.1.4</span> 기댓값과 공분산</a></li>
  </ul></li>
  <li><a href="#확률-분포" id="toc-확률-분포" class="nav-link" data-scroll-target="#확률-분포"><span class="header-section-number">3.2</span> 확률 분포</a>
  <ul class="collapse">
  <li><a href="#sec-ML_statistics_bernoulli_distribution" id="toc-sec-ML_statistics_bernoulli_distribution" class="nav-link" data-scroll-target="#sec-ML_statistics_bernoulli_distribution"><span class="header-section-number">3.2.1</span> 베르누이 분포 (Bernoulli distribution)</a></li>
  <li><a href="#sec-ML_statistics_normal_distribution" id="toc-sec-ML_statistics_normal_distribution" class="nav-link" data-scroll-target="#sec-ML_statistics_normal_distribution"><span class="header-section-number">3.2.2</span> 정규분포(가우스 분포)</a></li>
  </ul></li>
  <li><a href="#정보-이론" id="toc-정보-이론" class="nav-link" data-scroll-target="#정보-이론"><span class="header-section-number">3.3</span> 정보 이론</a>
  <ul class="collapse">
  <li><a href="#sec-ML_statistics_shannon_entropy" id="toc-sec-ML_statistics_shannon_entropy" class="nav-link" data-scroll-target="#sec-ML_statistics_shannon_entropy"><span class="header-section-number">3.3.1</span> Self-Information 과 셰넌 엔트로피</a></li>
  </ul></li>
  <li><a href="#베이지안-통계" id="toc-베이지안-통계" class="nav-link" data-scroll-target="#베이지안-통계"><span class="header-section-number">3.4</span> 베이지안 통계</a></li>
  <li><a href="#the-gaussian-distribution-normal-distribution" id="toc-the-gaussian-distribution-normal-distribution" class="nav-link" data-scroll-target="#the-gaussian-distribution-normal-distribution"><span class="header-section-number">3.5</span> The Gaussian Distribution (Normal Distribution)</a>
  <ul class="collapse">
  <li><a href="#변수-가우스분포에서의-mu와-sigma2-의-추정---최대-가능도" id="toc-변수-가우스분포에서의-mu와-sigma2-의-추정---최대-가능도" class="nav-link" data-scroll-target="#변수-가우스분포에서의-mu와-sigma2-의-추정---최대-가능도"><span class="header-section-number">3.5.1</span> 1-변수 가우스분포에서의 <span class="math inline">\(\mu\)</span>와 <span class="math inline">\(\sigma^2\)</span> 의 추정 - 최대 가능도</a></li>
  <li><a href="#curve-fitting-revisited" id="toc-curve-fitting-revisited" class="nav-link" data-scroll-target="#curve-fitting-revisited"><span class="header-section-number">3.5.2</span> Curve Fitting Revisited</a></li>
  <li><a href="#bayesian-curve-fitting" id="toc-bayesian-curve-fitting" class="nav-link" data-scroll-target="#bayesian-curve-fitting"><span class="header-section-number">3.5.3</span> Bayesian Curve Fitting</a></li>
  </ul></li>
  <li><a href="#model-selection" id="toc-model-selection" class="nav-link" data-scroll-target="#model-selection"><span class="header-section-number">3.6</span> Model Selection</a></li>
  <li><a href="#차원의-저주" id="toc-차원의-저주" class="nav-link" data-scroll-target="#차원의-저주"><span class="header-section-number">3.7</span> 차원의 저주</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../src/theory/ML.html">기계학습</a></li><li class="breadcrumb-item"><a href="../../src/theory/statistics.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">통계학 이론</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">통계학 이론</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="hidden">
<p>% %</p>
%
<p><span class="math display">\[
\DeclarePairedDelimiters{\set}{\{}{\}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\]</span></p>
</div>
<p><br></p>
<section id="통계학의-기본" class="level2 page-columns page-full" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="통계학의-기본"><span class="header-section-number">3.1</span> 통계학의 기본</h2>
<p><br></p>
<section id="기본-개념" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="기본-개념"><span class="header-section-number">3.1.1</span> 기본 개념</h3>
<ol type="1">
<li><p><strong>표본 공간 (sample space) <span class="math inline">\(\Omega\)</span></strong> : 실험/측정에 있어서 가능한 모든 결과값의 집합. <span class="math inline">\(\Omega\)</span> 의 각 원소들은 각각이 식별 가능하며, 상호 배타적(동시에 발생할 수 없음) 이어야 한다. 특정 결과값 <span class="math inline">\(\omega\)</span> 는 <span class="math inline">\(\Omega\)</span> 의 원소이다.</p></li>
<li><p><strong>사건 공간 (evant space) <span class="math inline">\(\mathcal{A}\)</span></strong> : 실험/측정의 잠재적인 결과의 집합. 당연히 표본 공간 <span class="math inline">\(\Omega\)</span> 의 부분집합.</p></li>
<li><p><strong>확률 (probability)</strong> : <span class="math inline">\(A\in \mathcal{A}\)</span> 에 대해 <span class="math inline">\(A\)</span> 의 사건이 발생할 확률을 <span class="math inline">\(P(A)\)</span> 라고 한다. 임의의 <span class="math inline">\(A\in \mathcal{A}\)</span> 에 대해 <span class="math inline">\(0\le p(A)\le 1\)</span> 이며 <span class="math inline">\(\sum_{A\in \Omega} P(A)=1\)</span> 이다.</p></li>
<li><p><strong>표적 공간 (target space)</strong> <span class="math inline">\(\mathcal{T}\)</span> : 우리가 관심있는 정량화된 값. 서로 구별되는 표적공간의 원소를 <strong>상태(state)</strong> 라고 한다.</p></li>
<li><p><strong>확률 변수 (random variable)</strong> : 표본공간의 성분 <span class="math inline">\(\omega\)</span> 와 표적공간의 성분 <span class="math inline">\(t\)</span> 를 연결하는 함수 <span class="math inline">\(X:\Omega \to \mathcal{T}\)</span> 가 존재하며 이 <span class="math inline">\(X\)</span> 를 확률변수 라고 한다.</p></li>
</ol>
<p>예를 들어 두개의 동전을 던져 이중 몇개의 동전이 앞면이 나오는 지 관심있다고 하자. 앞면을 <span class="math inline">\(u\)</span>, 뒷면을 <span class="math inline">\(d\)</span> 라고 하면 <span class="math inline">\(\Omega = \mathcal{A} = \{ uu,\, ud,\,du,\,dd\}\)</span> 이며 <span class="math inline">\(\mathcal{T}=\{0,\,1,\,2\}\)</span> 가 된다. 이제 사건공간이 아닌 표적공간의 부분집합에 대한 확률에 관심을 갖게 된다. 즉 <span class="math inline">\(S\in \mathcal{T}\)</span> 에 대해 <span class="math inline">\(p(S)\)</span> 가 우리의 주요 관심사이다.</p>
<p>표적공간 <span class="math inline">\(\mathcal{T}\)</span> 가 이산공간일 때 <span class="math inline">\(X\)</span> 를 이산확률변수라고 하고 <span class="math inline">\(\mathbb{R}\)</span> 과 같이 연속일 때 연속확률변수라고 한다.</p>
<p><br></p>
</section>
<section id="sec-ML_probability_discrete_variable" class="level3 page-columns page-full" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="sec-ML_probability_discrete_variable"><span class="header-section-number">3.1.2</span> 이산 확률 변수</h3>
<section id="결합-확률joint-probability" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="결합-확률joint-probability"><strong>결합 확률(Joint Probability)</strong></h4>
<p>확률변수 <span class="math inline">\(X,\,Y\)</span> 에 대해 <span class="math inline">\(X\)</span> 는 <span class="math inline">\(x_1,\ldots,\,x_M\)</span> 값을 가질 수 있으며, <span class="math inline">\(Y\)</span> 는 <span class="math inline">\(y_1,\ldots,\,y_L\)</span> 값을 가질 수 있다고 하자. 모두 <span class="math inline">\(N\)</span> 번의 시행에서 <span class="math inline">\(X=x_i,\, Y=y_j\)</span> 가 나온 횟수를 <span class="math inline">\(n_{ij}\)</span> 라 하자. <span class="math inline">\(N\)</span> 번의 시행에서 <span class="math inline">\(X=x_i\)</span> 인 횟수는 <span class="math inline">\(c_i\)</span>, <span class="math inline">\(Y=y_j\)</span> 인 횟수는 <span class="math inline">\(r_j\)</span> 라 하자. 즉, <span id="eq-ML_statistics_joint_probability_1"><span class="math display">\[
P(X=x_i,\, Y=y_j)=\dfrac{n_{ij}}{N},\quad P(X=x_i)=\dfrac{c_i}{N},\quad P(Y=y_j)=\dfrac{r_j}{N}\;.
\tag{3.1}\]</span></span></p>
<p>이다. 이 때,</p>
<p><span id="eq-ML_statistics_joint_probability"><span class="math display">\[
P(X=x_i)=\sum_{j=1}^L P(X=x_i,\, Y=y_j)
\tag{3.2}\]</span></span></p>
<div class="page-columns page-full"><p>이며 (자명하다) 이를 <strong>sum rule</strong> 이라 한다. 여기서 <span class="math inline">\(P(X=x_i)\)</span> 를 개별 사건의 확률로 <strong>주변 확률(marginal probability)</strong> 라 하기도 한다. </p><div class="no-row-height column-margin column-container"><span class="margin-aside">이것을 <em>marginal</em> 이라고 부르는 이유는 표에 <span class="math inline">\(X,\,Y\)</span> 두 변수에 대한 확률을 격자처럼 기록 할 때 여백에 <span class="math inline">\(P(X=x_i)\)</span> 나 <span class="math inline">\(P(Y=y_j)\)</span> 값을 병기했던 습관 때문이다(<span class="citation" data-cites="Goodfellow2016">Goodfellow, Bengio, and Courville (<a href="ML.html#ref-Goodfellow2016" role="doc-biblioref">2016</a>)</span>). 즉 주변 확률 보다는 여백 확률이라고 부르는 것이 더 정확한 이름일 것이다.</span></div></div>
<p><br></p>
</section>
<section id="조건부-확률conditional-probability" class="level4">
<h4 class="anchored" data-anchor-id="조건부-확률conditional-probability"><strong>조건부 확률(Conditional probability)</strong></h4>
<p><span class="math inline">\(X=x_i\)</span> 인 상황에서 <span class="math inline">\(Y=y_j\)</span> 인 확률을 <span class="math inline">\(p(Y=y_j \mid X=x_i)\)</span> 라 쓰며 <span class="math inline">\(X=x_i\)</span> 일 때 <span class="math inline">\(Y=y_j\)</span> 에 대한 <strong>조건부 확률(conditional probability)</strong> 이라고 하고 다음과 같이 주어진다. <span id="eq-ML_statistics_conditional_probability"><span class="math display">\[
P(Y=y_j\mid X=x_i)=\dfrac{n_{ij}}{c_i}
\tag{3.3}\]</span></span></p>
<p><br></p>
</section>
<section id="확률의-곱의-법칙product-rule-of-probability" class="level4">
<h4 class="anchored" data-anchor-id="확률의-곱의-법칙product-rule-of-probability"><strong>확률의 곱의 법칙(Product rule of probability)</strong></h4>
<p><span id="eq-ML_statistics_product_rule_of_probability"><span class="math display">\[
P(X=x_i,\, Y=y_j)=\dfrac{n_{ij}}N=\dfrac{n_{ij}}{c_i}\dfrac{c_i}{N}=P(Y=y_j\mid X=x_i)\cdot p(X=x_i)\;.
\tag{3.4}\]</span></span></p>
<p><br></p>
</section>
<section id="합과-곱의-규칙" class="level4">
<h4 class="anchored" data-anchor-id="합과-곱의-규칙"><strong>합과 곱의 규칙</strong></h4>
<p><span id="eq-ML_statistics_summary"><span class="math display">\[
\begin{aligned}
\textbf{sum rule}&amp;\qquad P(X)=\sum_Y P(X,\,Y)\,, \\
\textbf{product rule}&amp; \qquad P(X,\,Y)=P(Y\mid X)p(X)
\end{aligned}
\tag{3.5}\]</span></span></p>
<p><br></p>
</section>
<section id="베이즈-정리bayes-theorem" class="level4">
<h4 class="anchored" data-anchor-id="베이즈-정리bayes-theorem"><strong>베이즈 정리(Bayes’ theorem)</strong></h4>
<p><span id="eq-ML_statistics_bayse_theorem"><span class="math display">\[
P(Y\mid X)=\dfrac{P(X\mid Y) \, P(Y)}{P(X)}\;.
\tag{3.6}\]</span></span></p>
<p>With sum rule, <span id="eq-ML_statistics_sum_rule"><span class="math display">\[
P(X)=\sum_{Y}P(X \mid Y)\, P(Y)\,.
\tag{3.7}\]</span></span></p>
</section>
<section id="변수의-독립성" class="level4">
<h4 class="anchored" data-anchor-id="변수의-독립성"><strong>변수의 독립성</strong></h4>
<p>확률변수 <span class="math inline">\(X,\,Y\)</span> 에 대해 <span class="math inline">\(P(X,\,Y)=P(X)\, P(Y)\)</span> 일 때 <span class="math inline">\(X\)</span> 와 <span class="math inline">\(Y\)</span> 는 서로 <strong>독립적(independent)</strong> 이라고 한다. <span class="math inline">\(X,\,Y\)</span> 가 서로 독립적이면 식 <a href="#eq-ML_statistics_summary" class="quarto-xref">식&nbsp;<span>3.5</span></a> 으로 부터 <span class="math inline">\(P(Y|X)=P(Y)\)</span> 임을 알 수 있다.</p>
<p>다른 확률 변수 <span class="math inline">\(Z\)</span> 가 존재할 때 <span class="math inline">\(P(X,\, Y |Z) = P(X|Z)P(Y|Z)\)</span> 일 때 <span class="math inline">\(X\)</span> 와 <span class="math inline">\(Y\)</span> 는 <span class="math inline">\(Z\)</span> 에 대해 <strong>조건부 독립(conditionally independent)</strong> 이라고 한다.</p>
<p><br></p>
</section>
</section>
<section id="sec-ML_probability_continuous_variable" class="level3" data-number="3.1.3">
<h3 data-number="3.1.3" class="anchored" data-anchor-id="sec-ML_probability_continuous_variable"><span class="header-section-number">3.1.3</span> 연속 확률 변수</h3>
<p>표적공간이 연속일 때 확률은 확률밀도함수 <span class="math inline">\(P(x)\)</span> 로 기술된다.</p>
<section id="확률밀도함수와-확률" class="level4">
<h4 class="anchored" data-anchor-id="확률밀도함수와-확률"><strong>확률밀도함수와 확률</strong></h4>
<p>확률밀도함수 <span class="math inline">\(p(x)\)</span>는 다음 두 조건을 만족해야 한다. <span id="eq-ML_statistics_conditions_for_probability_density"><span class="math display">\[
\begin{align}
P(x) &amp; \ge 0\\
\int_{-\infty}^\infty P(x)\,dx &amp;=1
\end{align}
\tag{3.8}\]</span></span></p>
<p>연속확률변수일 때 <span class="math inline">\(x\in (a,\,b)\)</span> 일 확률 <span class="math inline">\(P(x\in (a,\,b))\)</span> 는 <span id="eq-ML_ststistics_probability_for_continuous_variable"><span class="math display">\[
P(x\in (a,\,b))=\int_a^b P(x)\,dx
\tag{3.9}\]</span></span> 이다.</p>
<p><br></p>
</section>
<section id="변수의-변환" class="level4">
<h4 class="anchored" data-anchor-id="변수의-변환"><strong>변수의 변환</strong></h4>
<p><span class="math inline">\(x=g(y)\)</span> 이며 <span class="math inline">\(y\)</span> 에 대한 확률분포를 알고 싶을 때, 이 확률분포를 <span class="math inline">\(P_y(y)\)</span> 라 하면, <span id="eq-ML_statistics_change_of_variable"><span class="math display">\[
P_y(y)=P(x)\left|\dfrac{dx}{dy}\right|=P(g(y))|g'(y)|
\tag{3.10}\]</span></span> 임을 쉽게 보일 수 있다.</p>
<p><br></p>
</section>
<section id="누적-분포-함수" class="level4">
<h4 class="anchored" data-anchor-id="누적-분포-함수"><strong>누적 분포 함수</strong></h4>
<p><span class="math inline">\(P(z)=P(x\in (-\infty,\,z))\)</span> 를 <strong>누적 분포 함수(cumulative distribution function)</strong> 이라 하며, <span id="eq-ML_statistics_cumulative_distribution_function"><span class="math display">\[
P(z) = \int_{-\infty}^z P(x)\, dx
\tag{3.11}\]</span></span></p>
<p>로 정의된다. <span class="math inline">\(P'(x)=P(x)\)</span> 임은 쉽게 알 수 있다.</p>
<p>다변수 <span class="math inline">\(\boldsymbol{x}=(x_1,\ldots,\,x_D)\)</span> 에 대한 확률분포는 <span class="math inline">\(\boldsymbol{x}\)</span> 를 포함하는 infinitesimal volume <span class="math inline">\(\delta \boldsymbol{x}\)</span> 에 대해 <span class="math inline">\(P(\boldsymbol{x})\,\delta \boldsymbol{x}\)</span> 로 주어지며 다음과 같은 성질을 만족한다.</p>
<p><span id="eq-ML_statistics_properties_of_probability_density"><span class="math display">\[
\begin{aligned}
P(\boldsymbol{x}) &amp; \ge 0  \\
\int P(\boldsymbol{x})\,d\boldsymbol{x}&amp;= 1
\end{aligned}
\tag{3.12}\]</span></span></p>
<p>연속적인 변수, 이산적인 변수 모두에 대한 확률 분포함수를 probability density function 이라 하기도 하고, 이산적인 변수에 대해서 probability mass function 이라고 구분하여 부르기도 한다.</p>
<p>Sum rule과 Bayes’ theorem 을 생각하면 다음이 성립함을 알 수 있다. <span id="eq-ML_statistics_rules_for_probability_density"><span class="math display">\[
\begin{aligned}
P(x) &amp;= \int P(x,\,y)\, dy \\
P(x,\,y)&amp;=P(y| x)\,P(x)
\end{aligned}
\tag{3.13}\]</span></span></p>
<p><br></p>
</section>
</section>
<section id="sec-ML_probability_expectation_value" class="level3" data-number="3.1.4">
<h3 data-number="3.1.4" class="anchored" data-anchor-id="sec-ML_probability_expectation_value"><span class="header-section-number">3.1.4</span> 기댓값과 공분산</h3>
<section id="기댓값" class="level4">
<h4 class="anchored" data-anchor-id="기댓값"><strong>기댓값</strong></h4>
<p>확률변수 <span class="math inline">\(X\)</span> 에 대한 확률분포가 <span class="math inline">\(P(x)\)</span> 일 때 <span class="math inline">\(x\)</span> 에 대한 함수 <span class="math inline">\(f(x)\)</span> 의 평균값을 <span class="math inline">\(f\)</span> 에 대한 <strong>기댓값(expectation)</strong> 이라 하며 <span class="math inline">\(\mathbb{E}[f]\)</span> 로 표기하고 다음과 같다. <span id="eq-ML_statistics_expectation_value"><span class="math display">\[
\begin{align}
\mathbb{E}[f]&amp;:=\sum_x P(x) f(x) &amp;&amp;\text{for descrete distribution,}\\
&amp;:=\int  P(x) f(x)\, dx&amp; &amp;\text{for continuous distribution.}
\end{align}
\tag{3.14}\]</span></span></p>
<p><span class="math inline">\(N\)</span> 개의 sample 이 주어졌을 때 기댓값은 다음과 같이 근사 될 수 있다. <span id="eq-ML_statistics_approximation_of_expectation"><span class="math display">\[
\mathbb{E}[f] \approx \dfrac{1}{N} \sum_{i=1}^N f(x_n).
\tag{3.15}\]</span></span></p>
<p><a href="#eq-ML_statistics_expectation_value" class="quarto-xref">식&nbsp;<span>3.14</span></a> 의 두 식은 <a href="#eq-ML_statistics_approximation_of_expectation" class="quarto-xref">식&nbsp;<span>3.15</span></a> 의 <span class="math inline">\(N \to \infty\)</span> 극한과 동일하다.</p>
<p>다변수 확률분포에서 특정 변수에 대한 기댓값은 <span class="math inline">\(\mathbb{E}_x [f(x,\,y)]\)</span> 와 같이 표기하며 다음과 같다. <span id="eq-ML_statistics_expectation_for_multivariables"><span class="math display">\[
\mathbb{E}_x [f(x,\,y)]=\sum_x p (x,\,y) f(x,\,y) =\int p(x,\,y) f(x,\,y)\, dx
\tag{3.16}\]</span></span></p>
<p><br></p>
</section>
<section id="조건부-기댓값" class="level4">
<h4 class="anchored" data-anchor-id="조건부-기댓값"><strong>조건부 기댓값</strong></h4>
<p><span class="math inline">\(p(x\,|\,y)\)</span> 에 대한 <span class="math inline">\(f(x)\)</span> 의 기댓값은 다음과 같다. <span id="eq-ML_statistics_conditional_expectation"><span class="math display">\[
\mathbb{E}_x [f \mid y\,]= \sum_x p(x\,|\, y)\, f(x)
\tag{3.17}\]</span></span></p>
<p><br></p>
</section>
<section id="분산" class="level4">
<h4 class="anchored" data-anchor-id="분산"><strong>분산</strong></h4>
<p><span class="math inline">\(f(x)\)</span> 에 대한 <strong>분산(variance)</strong> <span class="math inline">\(\text{Var}[f]\)</span> 는 다음과 같이 정의된다. <span id="eq-ML_statistics_variance_of_function"><span class="math display">\[
\begin{aligned}
\operatorname{Var}[f] &amp; := \mathbb{E}\left[(f(x)-\mathbb{E}[f(x)])^2\right] \\[0.3em]
&amp;=\mathbb{E}[f(x)^2]-(\mathbb{E}[f(x)])^2\;
\end{aligned}
\tag{3.18}\]</span></span></p>
<p>이다. 변수 <span class="math inline">\(x\)</span> 자체에 대한 분산 <span class="math inline">\(\text{Var}[x]\)</span> 는 다음과 같다. <span id="eq-ML_statistics_variance_of_variable"><span class="math display">\[
\operatorname{Var}[x]=\mathbb{E}[x^2]-\mathbb{E}[x]^2.
\tag{3.19}\]</span></span></p>
<p>같은 방법으로 <span class="math inline">\(f(x)\)</span> 에 대한 분산을 구할 수 있다.</p>
<p><span id="eq-ML_statistics_variance_of_function"><span class="math display">\[
\text{Var}[f(x)] = \mathbb{E}\left[(f(x)-\mathbb{E}[f(x)])^2\right]
\tag{3.20}\]</span></span></p>
<p><br></p>
</section>
<section id="공분산" class="level4">
<h4 class="anchored" data-anchor-id="공분산"><strong>공분산</strong></h4>
<p>아래와 같이 정의되는 <span class="math inline">\(\text{Cov}[x,\,y]\)</span> 를 <span class="math inline">\(X,\,Y\)</span> 에 대한 <strong>공분산(covariance)</strong> 라고 한다. <span id="eq-ML_statistics_covariance"><span class="math display">\[
\begin{align}
\operatorname{Cov}[x,\,y]&amp;:= \mathbb{E}_{x,\,y} \left[(x-\mathbb{E}[x]) (y-\mathbb{E}[y])\right] \\
&amp;=\mathbb{E}_{x,\,y}[xy] -\mathbb{E}[x] \mathbb{E}[y].
\end{align}
\tag{3.21}\]</span></span></p>
<p><span class="math inline">\(x,\,y\)</span> 가 서로 독립이면 <span class="math inline">\(\operatorname{Cov}[x,\,y]=0\)</span> 이다. 그러나 그 역은 성립하지 않는다.</p>
<p>두 확률 변수가 벡터 <span class="math inline">\(\boldsymbol{x},\, \boldsymbol{y}\)</span> 이면 <span id="eq-ML_statistics_covariance_matrix_form"><span class="math display">\[
\begin{aligned}
\operatorname{Cov}[\boldsymbol{x},\, \boldsymbol{y}]&amp;= \mathbb{E}_{\boldsymbol{x},\, \boldsymbol{y}}\left[\left( \boldsymbol{x}-\mathbb{E}[\boldsymbol{x}]\right)\left( \boldsymbol{y}^T-\mathbb{E}[\boldsymbol{y}^T]\right)\right] \\[0.3em]
&amp;=\mathbb{E}_{\boldsymbol{x},\,\boldsymbol{y}}[\boldsymbol{x}\boldsymbol{y}^T]-\mathbb{E}[\boldsymbol{x}]\,\mathbb{E}[\boldsymbol{y}^T]
\end{aligned}
\tag{3.22}\]</span></span></p>
<p>이다. <span class="math inline">\(\operatorname{Cov}[\boldsymbol{x}] := \operatorname{Cov}[\boldsymbol{x},\,\boldsymbol{x}]\)</span> 로 정의한다. <span class="math inline">\(\boldsymbol{x}\in \mathbb{R}^n\)</span> 일 때 공분산 행렬(covariance matrix) <span class="math inline">\(\text{Cov}(\boldsymbol{x})\)</span> 는 다음과 같이 정의된다.</p>
<p><span id="eq-ML_statistics_covariance_matrix"><span class="math display">\[
[\text{Cov}(\boldsymbol{x})]_{ij} = \text{Cov}[x_i, x_j]
\tag{3.23}\]</span></span></p>
<p><br></p>
<p>마찬가지로 함수에 대한 공분산도 정의 할 수 있다.</p>
<p><span id="eq-ML_statistics_covariance_for_functions"><span class="math display">\[
\text{Cov}[f(x),\, g(y)] = \mathbb{E}_{x, y}\left[(f(x) - \mathbb{E}_x[f(x)])(g(y) - \mathbb{E}_y[g(y)])\right]
\tag{3.24}\]</span></span></p>
<p><br></p>
</section>
</section>
</section>
<section id="확률-분포" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="확률-분포"><span class="header-section-number">3.2</span> 확률 분포</h2>
<section id="sec-ML_statistics_bernoulli_distribution" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="sec-ML_statistics_bernoulli_distribution"><span class="header-section-number">3.2.1</span> 베르누이 분포 (Bernoulli distribution)</h3>
<p>사건공간 <span class="math inline">\(\mathcal{A}\)</span> 가 단 두개의 원소로 이루어진 이진 확률 변수에 대한 분포이다. <span class="math inline">\(\mathcal{A}=\{0,\,1\}\)</span> 이며 <span class="math inline">\(P(1)=\phi\)</span> 라고 하자. <span class="math inline">\(P(0)=1-\phi\)</span> 이며 다음이 성립한다.</p>
<p><span class="math display">\[
\begin{aligned}
P(x) &amp;= \phi^x (1-\phi^x), \\[0.3em]
\mathbb{E}[x]&amp;=\phi, \\[0.3em]
\text{Var}[x] &amp;= \phi (1-\phi).
\end{aligned}
\]</span>{# eq-ML_statistics_Bernoulli_distribution}</p>
<p><br></p>
</section>
<section id="sec-ML_statistics_normal_distribution" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="sec-ML_statistics_normal_distribution"><span class="header-section-number">3.2.2</span> 정규분포(가우스 분포)</h3>
<p>평균 (mean) <span class="math inline">\(\mu\)</span> 와 분산 <span class="math inline">\(\sigma^2\)</span> 에 대한 1차원 가우시안 분포 <span class="math inline">\(\mathcal{N}(x\mid \mu,\,\sigma^2)\)</span> 는 다음과 같다. <span id="eq-ML_ststistics_1d_gaussian_distribution"><span class="math display">\[
\mathcal{N} (x ;  \mu,\,\sigma^2) = \dfrac{1}{ \sqrt{2\pi \sigma^2 }} \exp \left[-\dfrac{(x-\mu)^2}{2\sigma^2}\right]
\tag{3.25}\]</span></span></p>
<p>가우시안 분포 <span class="math inline">\(\mathcal{N}(x\mid \mu,\,\sigma^2)\)</span> 는 다음과 같은 성질을 갖는다.</p>
<p><span id="eq-ML_ststistics_properties_of_1d_gaussian_distribution"><span class="math display">\[
\begin{align}
\mathcal{N}&amp;(x ;\mu,\,\sigma^2)  \ge 0\,,\\
\int_{-\infty}^\infty &amp;\mathcal{N}(x ; \mu,\,\sigma^2)\, dx = 1,\, \\
\mathbb{E}[x] &amp;=\int_{-\infty}^\infty x\, \mathcal{N}(x ; \mu,\,\sigma^2)\,dx=\mu\;, \\
\mathbb{E}[x^2] &amp;= \int_{-\infty}^\infty x^2 \mathcal{N}(x ; \mu,\,\sigma^2)\,dx=\mu^2+\sigma^2\;,\\
\operatorname{Var}[f] &amp;=\mathbb{E}[x^2]-\left(\mathbb{E}[x]\right)^2=\sigma^2 \;.
\end{align}
\tag{3.26}\]</span></span></p>
<p><span class="math inline">\(\mathbb{R}^\mathcal{K}\)</span> 에서 평균 <span class="math inline">\(\boldsymbol{\mu}\)</span> 와 공분산 행렬 <span class="math inline">\(\boldsymbol{\Sigma}\)</span> (<a href="#eq-ML_statistics_covariance_matrix" class="quarto-xref">식&nbsp;<span>3.23</span></a>) 를 갖는 가우스 분포는 다음과 같다.</p>
<p><span id="eq-ML_ststistics_properties_of_gaussian_distribution"><span class="math display">\[
\mathcal{N}(\boldsymbol{x} ; \boldsymbol{\mu},\,\boldsymbol{\Sigma}) = \dfrac{1}{(2\pi)^{K/2}}\dfrac{1}{(\det(\boldsymbol{\Sigma}))^{1/2}} \exp \left[-\dfrac{1}{2} (\boldsymbol{x}-\boldsymbol{\mu})^T \boldsymbol{\Sigma} (\boldsymbol{x}-\boldsymbol{\mu})\right]
\tag{3.27}\]</span></span></p>
<p><br></p>
</section>
</section>
<section id="정보-이론" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="정보-이론"><span class="header-section-number">3.3</span> 정보 이론</h2>
<section id="sec-ML_statistics_shannon_entropy" class="level3" data-number="3.3.1">
<h3 data-number="3.3.1" class="anchored" data-anchor-id="sec-ML_statistics_shannon_entropy"><span class="header-section-number">3.3.1</span> Self-Information 과 셰넌 엔트로피</h3>
<p>정보 이론은 어떤 신호에 얼마나 많은 정보가 표현되어 있는지, 혹은 표현 할 수 있는지를 정량화 하는 것에 관련된 응용 수학의 분야이다. 정보 이론은 원래 잡음이 있는 채널을 통해 이산적인 알파벳으로 구성된 메시지를 전송하는 방법을 연구하기 위해 고안되었으며 이러한 맥락에서 최적의 부호를 설계하고, 특정 확률 분포에서 샘플링된 메시지들의 예상 길이를 다양한 인코딩 방식으로 계산하는 방법을 제시하였다. 머신러닝의 맥락에서는 이러한 정보 이론을 연속 변수에도 적용할 수 있으며, 이 경우에는 메시지 길이에 대한 해석이 항상 성립하지는 않는다(<span class="citation" data-cites="Goodfellow2016">Goodfellow, Bengio, and Courville (<a href="ML.html#ref-Goodfellow2016" role="doc-biblioref">2016</a>)</span>).</p>
<p>일단 <span class="citation" data-cites="Goodfellow2016">Goodfellow, Bengio, and Courville (<a href="ML.html#ref-Goodfellow2016" role="doc-biblioref">2016</a>)</span> 를 따라가면 정보의 개념을 수학적으로 정량화 하기 위한 기준은 다음과 같다.</p>
<ul>
<li><p>일어날 가능성이 높은 사건은 정보량이 적어야 하며, 극단적인 경우로 확실히 일어나는 사건은 정보량이 전혀 없어야 한다.</p></li>
<li><p>일어날 가능성이 낮은 사건일수록 더 많은 정보를 가져야 한다.</p></li>
<li><p>독립적인 사건들은 정보량이 더해져야 합니다. 예를 들어, 동전을 던져 앞면이 한 번 나왔다는 사실보다 두 번 연속 앞면이 나왔다는 사실이 두 배의 정보를 전달해야 한다.</p></li>
</ul>
<p>위의 세 성질을 만족하는 <em>self-information</em> 을 아래와 같이 정의한다.</p>
<p><span id="eq-ML-statistics_definition_of_self_information"><span class="math display">\[
\boxed{I(x) := - \log_b P(X=x).}
\tag{3.28}\]</span></span></p>
<p><span class="math inline">\(b=2\)</span> 인 경우 단위는 <span class="math inline">\(\text{Sh}\)</span> (Shannon) 이며 <span class="math inline">\(b=10\)</span> 을 사용하면 단위는 <span class="math inline">\(\text{Hart}\)</span> (Hartley) 라고 한다. <span class="math inline">\(b=e\)</span> 인 경우 단위는 <span class="math inline">\(\text{nat}\)</span> 이며 <em>natural unit of information</em> 을 의미한다(From <a href="https://en.wikipedia.org/wiki/Information_content">Wikipedia</a>). 앞으로는 특별한 언급이 없는 한 <span class="math inline">\(\text{nat}\)</span> 단위를 사용하도록 한다.</p>
<p>Self-information 은 하나의 사건만을 다룬다. 불확실성의 척도를 전체 확률분포에서 다룬 것을 셰넌 앤트로피(Shannon entropy) 라고 하며, 셰넌 앤트로피 <span class="math inline">\(H(x)\)</span> 는 아래와 같이 정의된다.</p>
<p><span id="eq-ML-statistics_definition_of_shannon_entropy"><span class="math display">\[
\boxed{ H(x) := \mathbb{E}[I(x)] = -\mathbb{E}(\ln P(X=x)).}
\tag{3.29}\]</span></span></p>
<div id="fig-ML_statistics_shannon_entropy" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ML_statistics_shannon_entropy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="figure/shannon_entropy.png" class="img-fluid figure-img" width="400">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ML_statistics_shannon_entropy-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
그림&nbsp;3.1: 2진 확률 변수에 대한 셰넌 엔트로피
</figcaption>
</figure>
</div>
<p>즉 확률 분포 <span class="math inline">\(P\)</span> 에 대한 셰넌 앤트로피는 이 분포에서 가능한 사건에 포함된 정보의 총량이다. Self-information 에서 <span class="math inline">\(\text{Sh}\)</span> 단위를 사용할 경우 이 값은 확률 분포 <span class="math inline">\(P\)</span> 로부터 샘플링된 기호들을 인코딩할 때, 평균적으로 필요한 비트 수의 하한이다. <span class="math inline">\(X\)</span> 가 연속 확률 변수일 때 셰넌 앤트로피를 <strong>미분 엔트로피(differential entropy)</strong>라고 한다.</p>
<p><br></p>
</section>
</section>
<section id="베이지안-통계" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="베이지안-통계"><span class="header-section-number">3.4</span> 베이지안 통계</h2>
<p>지금까지 우리는 확률을 무작위성(randomness) 과 반복적인 사건(repeated events) 이라는 <strong>고전적(classica)</strong> 혹은 <strong>빈도적(frequencies)</strong> 이라고 불리는 관점에서 봤다. 이제 우리는 확률을 이용하여 불확실성을 정량화하는 <strong>Bayesian</strong> 관점을 학습할 것이다.</p>
<p>커브 피팅 혹은 모델링을 생각하자. 즉 측정된 값 <span class="math inline">\(\mathcal{D}=\{t_1,\ldots,\,t_n\}\)</span> 을 통해 측정값을 가장 잘 기술하는 함수 <span class="math inline">\(y(\boldsymbol{x};\,\boldsymbol{w})\)</span> 를 결정한다고하자. 여기서 <span class="math inline">\(\boldsymbol{w}\)</span> 는 모델 매개변수이다. 빈도주의적 입장에서 <span class="math inline">\(\boldsymbol{w}\)</span> 는 확률이 아닌 우리가 알 내야 하는 값이 된다. 이에 대한 베이즈 정리는 다음과 같다. <span class="math display">\[
P(\boldsymbol{w}\,|\, \mathcal{D})=\dfrac{P(\mathcal{D}\,|\,\boldsymbol{w}) \cdot P(\boldsymbol{w})}{P(\mathcal{D})}.
\]</span></p>
<p>여기서 <span class="math inline">\(P(\mathcal{D}\,|\,\boldsymbol{w})\)</span> 를 <strong>가능도</strong> 혹은 <strong>우도 (likelihood function)</strong> 라고 하고 <span class="math inline">\(p(\boldsymbol{w})\)</span> 를 <strong>사전 확률 분포 (prior distribution)</strong> 라고 한다. <span class="math inline">\(p(\mathcal{D})\)</span> 는 정규화 상수(normalization constant) 이다. <span class="math inline">\(p(\mathcal{D})\)</span> 는 실험 결과에 따라 정해지는 확률이기 때문에 실험이 종료된 상황에서는 상수일 뿐이다.</p>
<p><br></p>
<section id="고전적빈도주의적-입장" class="level4">
<h4 class="anchored" data-anchor-id="고전적빈도주의적-입장"><strong>고전적/빈도주의적 입장</strong></h4>
<p>고전적 입장에서는 <span class="math inline">\(p(\boldsymbol{w})=1\)</span> 이다. 따라서 <span class="math inline">\(p(\boldsymbol{w}|\mathcal{D})\)</span> 를 최대화 하는 것은 <span class="math inline">\(p(\mathcal{D}|\boldsymbol{w})\)</span> 를 최대화 하는 것이다. 보통 기계학습에서 에러 함수 <span class="math inline">\(L(\boldsymbol{w})=-\ln p(\mathcal{D}|\boldsymbol{w})\)</span> 이므로 에러 함수를 최소화 하는 것은 가능도를 최대로 하는 것과 동치이다.</p>
<p><br></p>
</section>
<section id="베이지언적-입장" class="level4">
<h4 class="anchored" data-anchor-id="베이지언적-입장"><strong>베이지언적 입장</strong></h4>
<p>매개변수 <span class="math inline">\(\boldsymbol{w}\)</span> 는 고정된 값이 아닌 확률로 표현되는 값이다. 데이터를 보기 전에 <span class="math inline">\(p(\boldsymbol{w})\)</span> 에 대해 임시로 정한다. <span class="math inline">\(\mathcal{D}=\{t_1,\ldots,\,t_N\}\)</span> 는 <span class="math inline">\(p(\mathcal{D}\,|\,\boldsymbol{w})\)</span> 에 반영된다.</p>
<ul>
<li><p>빈도주의적이든 베이즈적이든 <span class="math inline">\(p(\mathcal{D}|\boldsymbol{w})\)</span> 가 중심적인 역할을 하지만 이에 대한 두 입장의 견해는 매우 다르다. 빈도주의 입장에서는 <span class="math inline">\(\boldsymbol{w}\)</span> 는 고정된 매개변수 이며 그 값과 에러는 <span class="math inline">\(\mathcal{D}\)</span> 의 분포를 고려하여 얻어진다. 그러나 베이즈주의적 입장에서는 유일한 <span class="math inline">\(\mathcal{D}\)</span> 가 존재하며 매개변수 <span class="math inline">\(\boldsymbol{w}\)</span> 가 확률 분포 <span class="math inline">\(p(\boldsymbol{w})\)</span> 로서 표현된다.</p></li>
<li><p>널리 사용되는 빈도주의자들의 estimator는 <em>최대 가능도</em> 혹은 <em>최대 우도 (maximum likelihood)</em> 이다. 이 입장에서는 <span class="math inline">\(p(\boldsymbol{w})=1\)</span> 이므로 <span class="math inline">\(p(\mathcal{D}\,|\,\boldsymbol{w})\)</span> 를 최대화하면 자연스럽게 <span class="math inline">\(p(\boldsymbol{w}\,|\,\mathcal{D})\)</span> 가 최대화 된다. ML 에서는 <span class="math inline">\(-\ln p(D\,|\,\boldsymbol{w})\)</span> 를 <em>error function</em> 이라 한다. 따라서 likelihood 를 최대화 하는것은 error function 을 최소화 하는 것이다.</p></li>
<li><p>예를 들어 동전을 던졌을 때 앞면이 나올 확률을 <span class="math inline">\(q\)</span> 라 하자. 세번의 동전을 던져 셋 다 앞면이 나왔을 때, 빈도주의적 접근에 의하면, Likelihood function 은 <span class="math display">\[
p(\text{3 up}\,|\,q)=q^3
\]</span> 이므로 <span class="math inline">\(p(\text{3 up}|q)\)</span> 를 최대화 하는 것은 <span class="math inline">\(q=1\)</span> 이다. 이것은 매우 극단적인 결과이다.</p></li>
<li><p>그런데 베이지언에서는 <span class="math inline">\(\boldsymbol{w}\)</span> 에 받아들일만 한 사전확률분포 <span class="math inline">\(p(\boldsymbol{w})\)</span> 을 부여하므로 덜 극단적인 결론에 도달할 수 있다.</p></li>
<li><p>베이지언에 대한 가장 일반적인 비판중의 하나는 사전확률분포 <span class="math inline">\(p(\boldsymbol{w})\)</span> 를 선택할 때 수학적인 편리성이나 편견에 의해 결과가 왜곡 될 수 있다는 것이다. 이러한 주관성을 개선하기 위해 소위 <strong>non-informative priors</strong> 가 도입되기도 한다.</p></li>
</ul>
<p><br></p>
</section>
</section>
<section id="the-gaussian-distribution-normal-distribution" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="the-gaussian-distribution-normal-distribution"><span class="header-section-number">3.5</span> The Gaussian Distribution (Normal Distribution)</h2>
<p>평균 (mean) <span class="math inline">\(\mu\)</span> 와 분산 <span class="math inline">\(\sigma^2\)</span> 에 대한 1차원 가우시안 분포 <span class="math inline">\(\mathcal{N}(x\mid \mu,\,\sigma^2)\)</span> 는 다음과 같다. <span id="eq-ML_ststistics_1d_gaussian_distribution"><span class="math display">\[
\mathcal{N} (x\mid \mu,\,\sigma^2) = \dfrac{1}{\sigma \sqrt{2\pi }} \exp \left[-\dfrac{(x-\mu)^2}{2\sigma^2}\right]
\tag{3.30}\]</span></span></p>
<p>가우시안 분포 <span class="math inline">\(\mathcal{N}(x\mid \mu,\,\sigma^2)\)</span> 는 다음과 같은 성질을 갖는다.</p>
<p><span id="eq-ML_ststistics_properties_of_1d_gaussian_distribution"><span class="math display">\[
\begin{align}
\mathcal{N}&amp;(x\mid \mu,\,\sigma^2)  \ge 0\,,\\
\int_{-\infty}^\infty &amp;\mathcal{N}(x\mid \mu,\,\sigma^2)\, dx = 1,\, \\
\mathbb{E}[x] &amp;=\int_{-\infty}^\infty x\, \mathcal{N}(x\mid \mu,\,\sigma^2)\,dx=\mu\;, \\
\mathbb{E}[x^2] &amp;= \int_{-\infty}^\infty x^2 \mathcal{N}(x\mid \mu,\,\sigma^2)\,dx=\mu^2+\sigma^2\;,\\
\operatorname{var}[f] &amp;=\mathbb{E}[x^2]-\left(\mathbb{E}[x]\right)^2=\sigma^2 \;.
\end{align}
\tag{3.31}\]</span></span></p>
<p><span class="math inline">\(\mathbb{R}^\mathcal{D}\)</span> 에서 평균 <span class="math inline">\(\boldsymbol{\mu}\)</span> 와 공분산 <span class="math inline">\(\boldsymbol{\Sigma}\)</span> 를 갖는 가우스 분포는 다음과 같다.</p>
<p><span id="eq-ML_ststistics_properties_of_gaussian_distribution"><span class="math display">\[
\mathcal{N}(\boldsymbol{x}\mid \boldsymbol{\mu},\,\boldsymbol{\Sigma}) = \dfrac{1}{(2\pi)^{\mathcal{D}/2}}\dfrac{1}{\left|\boldsymbol{\Sigma}\right|^{1/2}} \exp \left[-\dfrac{1}{2} (\boldsymbol{x}-\boldsymbol{\mu})^T \boldsymbol{\Sigma} (\boldsymbol{x}-\boldsymbol{\mu})\right]
\tag{3.32}\]</span></span></p>
<p><br></p>
<section id="변수-가우스분포에서의-mu와-sigma2-의-추정---최대-가능도" class="level3" data-number="3.5.1">
<h3 data-number="3.5.1" class="anchored" data-anchor-id="변수-가우스분포에서의-mu와-sigma2-의-추정---최대-가능도"><span class="header-section-number">3.5.1</span> 1-변수 가우스분포에서의 <span class="math inline">\(\mu\)</span>와 <span class="math inline">\(\sigma^2\)</span> 의 추정 - 최대 가능도</h3>
<p>스칼라 변수 <span class="math inline">\(x\)</span> 에 대해 <span class="math inline">\(N\)</span> 번 측정한 것을 <span class="math inline">\(\boldsymbol{x}=\begin{bmatrix}x_1 &amp;\ldots &amp;x_N\end{bmatrix}^T\)</span> 라 하자. 이 관측은 평균이 <span class="math inline">\(\mu\)</span> 이며 분산이 <span class="math inline">\(\sigma^2\)</span> 인 가우시안 분포를 따르는 변수에 대한 각각 독립적인 측정이라고 하자.</p>
<p>우선 <span class="math inline">\(N\)</span> 측정에서 <span class="math inline">\(\boldsymbol{x}\)</span> 가 관측될 확률은 <span id="eq-ML_ststistics_gaussian_likelihood_function"><span class="math display">\[
p(\boldsymbol{x}\mid \mu,\,\sigma^2)= \prod_{n=1}^N \mathcal{N}(x_n\mid \mu,\,\sigma^2)
\tag{3.33}\]</span></span></p>
<p>이며 <em>likelihood function for the Gaussian</em> (가우시안 가능도 함수)이라 불리운다.</p>
<p>어쨋든, <a href="#eq-ML_ststistics_gaussian_likelihood_function" class="quarto-xref">식&nbsp;<span>3.33</span></a> 의 우도함수를 최대화하는 <span class="math inline">\(\mu,\,\sigma^2\)</span> 를 정하자. 계산의 편의를 위해 로그함수를 사용한다. <span class="math display">\[
\ln p(\boldsymbol{x}\mid \mu,\,\sigma^2)= - \dfrac{1}{2\sigma^2}\sum_{n=1}^N (x_n-\mu)^2-\dfrac{N}{2} \ln \sigma^2 - \dfrac{N}{2} \ln 2\pi
\]</span></p>
<p>이 때 <span class="math inline">\(p (\boldsymbol{x}\mid \mu,\,\sigma^2)\)</span> 를 최대화 하는 <span class="math inline">\(\mu\)</span> 와 <span class="math inline">\(\sigma^2\)</span> 를 <span class="math inline">\(\mu_{ML},\,\sigma_{ML}^2\)</span> 라 할 때 다음과 같다.</p>
<p><span id="eq-ML_statiscis_maximum_likelihood_mean_and_variance_of_gaussian"><span class="math display">\[
\begin{align}
\mu_{ML} &amp;= \dfrac{1}{N}\sum_{n=1}^N x_n \;,\\
\sigma_{ML}^2 &amp;= \dfrac{1}{N} \sum_{n=1}^N (x_n-\mu_{ML})^2\;
\end{align}
\tag{3.34}\]</span></span></p>
<p><br></p>
<section id="편항" class="level4">
<h4 class="anchored" data-anchor-id="편항"><strong>편항</strong></h4>
<p>위와 같은 최대 가능도로부터 얻어진 분산은 원래 분포의 분산보다 작은데 하는데 이런 현상을 편향(bias)이라 한다. 표본의 평균과 분산의 기대값은 다음과 같다. <span id="eq-ML_stastistics_mean_and_variance_of_sample_and_population"><span class="math display">\[
\begin{align}
\mathbb{E}[\mu_{ML}]&amp; =\mu \\
\mathbb{E}\left[\sigma_{ML}^2\right] &amp; =\left(\dfrac{N-1}{N}\right)\sigma^2.
\end{align}
\tag{3.35}\]</span></span></p>
<p>식 (1.58)에서 보듯이 <span class="math inline">\(\mathbb{E}\left[\sigma^2_{ML}\right]&lt;\sigma^2\)</span> 이다. 따라서 아래와 같이 정의된 <span class="math inline">\(\widetilde{\sigma\,}^2\)</span> 는 samples 로 부터 추정한 모집단의 분산과 같다. (즉 unbiased.) 이를 표본분산이라 한다. <span id="eq-ML_statistics_population_variance"><span class="math display">\[
\widetilde{\sigma\,}^2 = \dfrac{N}{N-1}\sigma_{ML}^2 = \dfrac{1}{N-1} \sum_{n=1}^N\left(x_n-\mu_{ML}\right)^2
\tag{3.36}\]</span></span></p>
<p><span class="math inline">\(N\to \infty\)</span> 일 때 <span class="math inline">\(\sigma_{ML}^2 \to \sigma^2\)</span> 임은 쉽게 알 수 있다. 실제로 <span class="math inline">\(N\)</span> 이 작지만 않으면 큰 문제는 되지 않는다.</p>
<p><br></p>
</section>
</section>
<section id="curve-fitting-revisited" class="level3" data-number="3.5.2">
<h3 data-number="3.5.2" class="anchored" data-anchor-id="curve-fitting-revisited"><span class="header-section-number">3.5.2</span> Curve Fitting Revisited</h3>
<p><span class="math inline">\(N\)</span> 개의 입력 변수 <span class="math inline">\(\boldsymbol{x} = \begin{bmatrix} x_1 &amp;\ldots &amp; x_N \end{bmatrix}^T\)</span> 와 표적값 <span class="math inline">\(\boldsymbol{t}=\begin{bmatrix} t_1 &amp;\ldots &amp;t_N\end{bmatrix}^T\)</span> 사이에 다항식 <span class="math inline">\(t=y(x;\boldsymbol{w})=w_0 + w_1x+ \cdots +w_nx^n\)</span> 의 관계를 가정한다. 표적값의 불확도를 확률분포로서 표현하자. 이를 위해 주어진 <span class="math inline">\(x\)</span> 에 대해 표적값의 확률은 <span class="math inline">\(y(\boldsymbol{x},\,\boldsymbol{w})\)</span> 를 중심으로 분산이 <span class="math inline">\(\beta^{-1}\)</span> 인 가우시안분포를 따른다고 가정한다. 즉,</p>
<p><span id="eq-ML_statistics_parameter_distribution"><span class="math display">\[
p(t\mid x,\,\boldsymbol{w},\, \beta)=\mathcal{N}(t\mid y(x,\,\boldsymbol{w}),\,\beta^{-1})
\tag{3.37}\]</span></span></p>
<p>이다.</p>
<p>훈련 데이터 <span class="math inline">\(\{\boldsymbol{x},\,\boldsymbol{t}\}\)</span> 를 이용하여 미지의 매개변수 <span class="math inline">\(\boldsymbol{w}\)</span> 와 <span class="math inline">\(\beta\)</span> 를 결정하자. 그렇다면 가능도 함수는 다음과 같이 주어진다. <span id="eq-ML_statistics_curve_fitting_likelihood"><span class="math display">\[
p(\boldsymbol{t}\mid \boldsymbol{x},\,\boldsymbol{w},\,\beta)=\prod_{n=1}^N \mathcal{N}(t_n\mid y(x_n,\, \boldsymbol{w}),\, \beta^{-1}).
\tag{3.38}\]</span></span></p>
<p>앞서와 같이 <span class="math inline">\(\ln\)</span> 을 취하면</p>
<p><span id="eq-ML_statistics_curve_fitting_likelihood_log"><span class="math display">\[
\ln p(\boldsymbol{t}\mid \boldsymbol{x},\, \boldsymbol{w},\,\beta)= -\dfrac{\beta}{2} \sum_{n=1}^N \left[y(x_n,\,\boldsymbol{w})-t_n\right]^2+\dfrac{N}{2} \ln \beta - \dfrac{N}{2} \ln (2\pi)
\tag{3.39}\]</span></span></p>
<p>이 된다.</p>
<ul>
<li><p><a href="#eq-ML_statistics_curve_fitting_likelihood_log" class="quarto-xref">식&nbsp;<span>3.39</span></a> 로부터 고정된 <span class="math inline">\(\beta\)</span> 에 대해 <span class="math inline">\(p(\boldsymbol{t}\mid \boldsymbol{x},\, \boldsymbol{w},\,\beta)\)</span> 를 최대화 하는 것과 <span class="math inline">\(\displaystyle \dfrac{1}{2}\sum_{n=1}^N \left[ y(x_n,\,\boldsymbol{w})-t_n\right]^2\)</span> 를 최소화하는 것, 즉 제곱합 오차를 최소화 하는것은 동치라는 것을 알 수 있다. 이 <span class="math inline">\(\boldsymbol{w}\)</span> 를 <span class="math inline">\(\boldsymbol{w}_{ML}\)</span>이라 하자.</p></li>
<li><p>또한 <span class="math inline">\(\beta\)</span> 에 대해 미분하여 <span class="math inline">\(p\)</span> 를 최대화 하는 <span class="math inline">\(\beta\)</span> 를 찾아 <span class="math inline">\(\beta_{ML}\)</span> 이라 하면, <span id="eq-ML_statistics_cuve_fitting_param_1"><span class="math display">\[
\dfrac{1}{\beta_{ML}}=\dfrac{1}{N}\sum_{n=1}^N \left[ y(x_n,\, \boldsymbol{w}_{ML})-t_n\right]^2
\tag{3.40}\]</span></span></p>
<p>이다. <span class="math inline">\(\beta\)</span> 역시 <span class="math inline">\(\boldsymbol{w}_{ML}\)</span> 이 결정된 상황에서 제곱합 오차를 최소화 할 때 확률을 최대화 하도록 결정된다.</p></li>
</ul>
<p>이제 우리는 주어진 데이터로부터 가장 잘 예측할 수 있는 확률 분포를 다음과 갇이 얻는다.</p>
<p><span id="eq-ML_statistics_cuve_fitting_most_likely_function"><span class="math display">\[
p(t\mid x,\,\boldsymbol{w}_{ML},\, \beta_{ML})=\mathcal{N}(t\mid  y(x,\,\boldsymbol{w}_{ML}),\,\beta_{ML}^{-1})
\tag{3.41}\]</span></span></p>
<p><br></p>
<section id="베이즈-통계를-위한-공식" class="level5 border" style="background-color:#F2F4F4  ;padding:5px;">
<h5 class="anchored" data-anchor-id="베이즈-통계를-위한-공식"><strong>베이즈 통계를 위한 공식</strong></h5>
<p><span class="math display">\[
\begin{align}
p(a|x)&amp;=\sum_y p(a| x,\,y)\, p(y| x)  \tag{B1} \\
p(a|x,\,y) &amp;= \dfrac{p(x|a,\,y)\, p(a|y)} {p(y|x)}  \tag{B2}
\end{align}
\]</span></p>
<hr>
<div class="proof">
<p><span class="proof-title"><em>(증명)</em>. </span>(<span class="math inline">\(B1\)</span>) <span class="math display">\[
\begin{aligned}
\sum_y p (a\,|\, x,\,y)\, p(y\mid x)&amp;=\sum_y \dfrac{p(a,\,x,\,y)}{p(x,y)} \cdot \dfrac{p(x,\,y)}{p(x)} =\sum_y \dfrac{p(a,\,x,\,y)}{p(x)} \\
&amp;=\dfrac{1}{p(x)}\sum_{y}p(a,\,x,\,y) = \dfrac{p(a,\,x)}{p(x)} \\
&amp;=p(a|x)
\end{aligned}
\]</span></p>
<p>(<span class="math inline">\(B2\)</span>) <span class="math display">\[
\begin{aligned}
\dfrac{p(x|a,\,y)\, p(a|y)}{p(y|x)} &amp;= \dfrac{p(a,\,x,\,y)}{p(a,\,y)} \cdot \dfrac{p(a,\,y)}{p(y)} \cdot \dfrac{p(y)}{p(x,\,y)}=\dfrac{p(a,\,x,\,y)}{p(x,\,y)}=p(a|x,\,y)
\end{aligned}
\]</span></p>
</div>
</section>
<p><br></p>
<p>이제 Bayesian 접근법을 좀 알아보자. 즉 <span class="math inline">\(\boldsymbol{w}\)</span> 에 대한 사전 분포 <span class="math inline">\(p(\boldsymbol{w})\)</span> 에 대한 것이다. <span class="math inline">\(\boldsymbol{w}\)</span> 가 아래와 같은 분포를 따른다고 하자.</p>
<p><span id="eq-statistics_bayesian_fitting_1"><span class="math display">\[
p(\boldsymbol{w}|\alpha)=\mathcal{N}(\boldsymbol{w}|\boldsymbol{0},\,\alpha^{-1}\boldsymbol{1}_{M+1})=\left(\dfrac{\alpha}{2\pi}\right)^{(M+1)/2} \exp \left(-\dfrac{\alpha}{2}\boldsymbol{w}^T \boldsymbol{w}\right)
\tag{3.42}\]</span></span></p>
<p>여기서 <span class="math inline">\(M\)</span> 은 다항식의 차수이며 이며 따라서 <span class="math inline">\(\boldsymbol{w}\)</span> 는 <span class="math inline">\(M+1\)</span> 개의 성분을 가진다. <span class="math inline">\(\alpha\)</span> 와 같이 모델 파라메터의 분포를 제어하는 변수를 <strong>초매개변수(hyperparameters)</strong> 라 한다.</p>
<p>베이즈 정리로 부터, <span class="math display">\[
[\boldsymbol{w} \text{ 에 대한 사후 확률}] \propto [\text{가능도}]\times[\boldsymbol{w}\text{ 의 사전 확률 분포}]
\]</span></p>
<p>임을 알고 있으므로,</p>
<p><span id="eq-ML_statistics_bayesian_fitting_2"><span class="math display">\[
p(\boldsymbol{w}\,|\,\boldsymbol{x},\,\boldsymbol{t},\,\alpha,\,\beta) \propto p(\boldsymbol{t}\,|\,\boldsymbol{x},\,\boldsymbol{w},\,\beta)\cdot p(\boldsymbol{w}\,|\,\alpha)
\tag{3.43}\]</span></span></p>
<p>이다. <a href="#eq-ML_statistics_bayesian_fitting_2" class="quarto-xref">식&nbsp;<span>3.43</span></a> 에 <span class="math inline">\(-\ln\)</span> 을 취하고 <a href="#eq-ML_statistics_curve_fitting_likelihood_log" class="quarto-xref">식&nbsp;<span>3.39</span></a>, <a href="#eq-ML_statistics_cuve_fitting_most_likely_function" class="quarto-xref">식&nbsp;<span>3.41</span></a> 를 대입하면, 사후확률을 극대화 하는 <span class="math inline">\(\boldsymbol{w}\)</span> 는 다음 식을 최소화 하는 것 <span class="math inline">\(\boldsymbol{w}\)</span> 이다.</p>
<p><span id="eq-ML_statistics_bayesian_fitting_3"><span class="math display">\[
\dfrac{\beta}{2}\sum_{n=1}^N \{y(x_n,\,\boldsymbol{w})-t_n\}^2+\dfrac{\alpha}{2} \boldsymbol{w}^T \boldsymbol{w}.
\tag{3.44}\]</span></span></p>
<p>즉 베이지안에서 사후확률분포를 최대화하는 것은 정규화된 제곱합 오차 함수를 최소화 하는 것과 동등하다.</p>
<p><br></p>
</section>
<section id="bayesian-curve-fitting" class="level3" data-number="3.5.3">
<h3 data-number="3.5.3" class="anchored" data-anchor-id="bayesian-curve-fitting"><span class="header-section-number">3.5.3</span> Bayesian Curve Fitting</h3>
<p>앞서 우리는 사전확률분포 <span class="math inline">\(p(\boldsymbol{w}|\alpha)\)</span> 에 대한 추정을 포함시켰지만, <span class="math inline">\(\boldsymbol{w}\)</span> 에 대한 point estimate 이므로 이것은 제대로 된 베이지안 처리가 아니다. 제대로 된 베이지언 처리는 확률에 대한 합과 곱의 규칙들을 일관되게 적용해야 하며, 이는 <span class="math inline">\(\boldsymbol{w}\)</span> 에 대한 모든 값에 대해 적분해야 함을 의미한다. 이러한 marginalizations 가 패턴 인식에서의 베이지언 방법의 핵심이다.</p>
<ul>
<li><p>일단 <span class="math inline">\(\alpha,\,\beta\)</span> 를 고정시키고 (편의를 위해 식에서는 일단 빼자.), test set <span class="math inline">\(\{\boldsymbol{x},\,\boldsymbol{t}\}\)</span> 만을 생각하자. 베이지안 방법은</p>
<p><span id="eq-ML_statistics_bayesian_fitting_4"><span class="math display">\[
p(t\,|\,x,\,\mathbf{x},\,\mathbf{t})=\int p(t\mid x,\,\mathbf{w})\, p(\mathbf{w}\mid\mathbf{x},\,\mathbf{t})\,d\mathbf{w}
\tag{3.45}\]</span></span></p>
<p>을 생각한다. 여기서 <span class="math inline">\(p(t\mid x,\,\boldsymbol{w})\)</span> 는 식 <a href="#eq-ML_statistics_parameter_distribution" class="quarto-xref">식&nbsp;<span>3.37</span></a> 에 나와 있으며 <span class="math inline">\(p(\boldsymbol{w}\mid \boldsymbol{x},\,\boldsymbol{t})\)</span> 는 사후확률분포이다. (<a href="#eq-ML_statistics_bayesian_fitting_2" class="quarto-xref">식&nbsp;<span>3.43</span></a> 을 보라.)</p></li>
<li><p>뒤에 보겠지만, curve fitting example 과 같은 문제에서 이 사후확률분포 은 Gaussian 이며 해석적으로 계산 할 수 있다. 비슷하게 <a href="#eq-ML_statistics_bayesian_fitting_4" class="quarto-xref">식&nbsp;<span>3.45</span></a> 도 해석적으로 적분될 수 있으며 그 결과는 아래와 같은 가우시한 형태로 주어진다.</p>
<p><span class="math display">\[
p(t\mid x,\,\boldsymbol{x},\,\boldsymbol{t}) =\mathcal{N}(t\mid m(x),\, s^2(x))
\]</span></p>
<p>여기서 평균 <span class="math inline">\(m(x)\)</span> 와 분산 <span class="math inline">\(s^2(x)\)</span> 는 다음과 같다. <span class="math display">\[
\begin{aligned}
m(x) &amp;=\beta \phi(x)^T \boldsymbol{S} \sum_{n=1}^N \boldsymbol{\phi} (x_n) t_n\\
s^2(x) &amp;=\beta^{-1}+ \boldsymbol{\phi}(x)^T\boldsymbol{S}\boldsymbol{\phi}(x) \\
\end{aligned}
\]</span></p>
<p>여기서 행렬 <span class="math inline">\(\boldsymbol{S}\)</span> 는 다음과 같고 <span class="math inline">\(\boldsymbol{\phi}(x) = \begin{bmatrix} x^0 &amp; \cdots &amp; x^M\end{bmatrix}^T\)</span> 이다.<br>
<span class="math display">\[
\begin{align}
\boldsymbol{S}^{-1} &amp;= \alpha \boldsymbol{I} + \beta \sum_{n=1}^N \boldsymbol{\phi}(x_n) \boldsymbol{\phi}(x_n)^T
\end{align}
\]</span></p></li>
</ul>
<p><br></p>
</section>
</section>
<section id="model-selection" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="model-selection"><span class="header-section-number">3.6</span> Model Selection</h2>
<ul>
<li>최소자승법을 이용한 Polynomial curve fitting 에서 보았듯이 best generalization을 주는 최적의 다항식의 order <span class="math inline">\(M\)</span> 이 존재한다. 다항식의 order는 모델에서 free parameters의 갯수를 제어한다. Regularization 을 사용하면 regularization coefficient <span class="math inline">\(\lambda\)</span> 는 모델의 유효 복잡도(effiective complexcity) 를 통제한다.</li>
<li>실제 응용에서 우리는 이러한 parameters 들을 결정해야 하며 이렇게 하는 주요 목적은 새로운 데이터에 대한 최소의 predictive performance를 얻기 위함이다. 또한 이렇게 complexicity parameters 에 대한 적당한 값을 찾는 것 뿐만 아니라, 특정 목표에 적합한 모델을 찾기 위해 다양한 모델을 고려할 필요가 있다.</li>
<li>MLA (maximum likelihood approach) 에서 보았듯이 training set 에 대한 performance 가 다른 데이터에 대한 예측력을 보장해주지 않는다. (overfitting). 만약 데이터가 많다면 가용한 데이터중 일부를 다양한 모델을 학습시키거나, 주어진 모델에 대해 complexicity parameters 를 다양한 범위에서 학습시키는데 사용하고 이것을 독립적인 데이터를 사용하여 predictive performance를 비교하여 수 도 있다. 이렇게 학습데이터와 독립적으로 사용되는 데이터를 <strong>validation set</strong> 이라 한다. 이렇게 수차례 반복한 다음에 <strong>test set</strong> 이라 불리는 별도의 독립적인 데이터를 사용하여 최종적으로 평가할 수도 있다.</li>
<li>보통은 training과 testing에 사용될 수 있는 데이터가 부족한데, 이 경우 좋은 모델을 만들기 위해 training에 가능한 많은 데이터를 사용하고자 할 수 있다. 그러나 만약 validation set이 부족하면 it will give a relatively noisy estimate of predictive performance. 이 딜레마에 대한 해결방법중 하나로 cross validation 방법이 있다.</li>
</ul>
<section id="cross-validation" class="level4">
<h4 class="anchored" data-anchor-id="cross-validation"><strong>Cross Validation</strong></h4>
<ul>
<li><p>전체 데이터를 <span class="math inline">\(S\)</span> 개의 group으로 나눈다. <span class="math inline">\(S\)</span> 개의 training group 으로 각 training group 마다 <span class="math inline">\(S-1\)</span> 개의 데이터 그룹을 training set으로 나머지 하나를 validation set으로 사용한다.</p></li>
<li><p>Training group 마다 각자의 모델 (혹은 별도의 parameters set) 을 사용하므로 computationally expensive 하다. 또한 하나의 모델에 대한 다수의 complexcity parameter 를 갖게 될 수 있다. 이런 조합들을 탐색하다보면 최악의 경우 training run 이 parameter 갯수의 지수승으로 증가할수도 있다.!!!</p></li>
<li><p>우리는 더 좋은 접근법을 사용해야 한다. 이상적으로 이 접근법은 training data 에 의존해야 하며, 한번의 training run을 통해 비교 할 수 있는 다수의 hyperparameters와 model types 를 허용해야 하는데….</p></li>
<li><p>이를 위해 training data 에만 의존하며 over fitting에 의한 bias로부터 자유로운 성능 척도를 찾아야 한다.</p></li>
<li><p>역사적으로 복잡한 모델에서의 over fitting을 보상하는 penalty term을 추가함으로서 maximum likelihood의 bais를 교정하고자 하는 다양한 ‘information criteria’ 가 제안되었다. 예를 들어 <em>Akaike information criterion</em> (AIC) 의 경우 <span class="math display">\[
\ln p(\mathcal{D}\mid \boldsymbol{w}_{ML})-M
\]</span> 을 최대화 하는 모델을 선택한다. 여기서 <span class="math inline">\(p(\mathcal{D}\mid \boldsymbol{w}_{ML})\)</span> 은 best-fit log likelihood 이며 <span class="math inline">\(M\)</span> 은 모델에서 adjustable 한 parameter의 갯수이다. 이의 변형으로서 <em>Bayesian information criterion</em> 이 있는데 이는 section 4.4.1 에서 소개될 것이다. 이러한 criteria는 model parameter의 불확실성을 고려하지 않으며, 실제적으로는 과하게 간단한 모델을 선호한다.</p></li>
<li><p>따라서 우리는 section 3.4 에서 fully Bayesian approach 로 전환할 것이며 이러한 complexity penalty 가 자연스럽고 원칙적인 방법으로 발생하는지 볼 것이다.</p></li>
</ul>
<p><br></p>
</section>
</section>
<section id="차원의-저주" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="차원의-저주"><span class="header-section-number">3.7</span> 차원의 저주</h2>
<ul>
<li><p>우리가 다루고자 하는 입력 데이터가 고차원의 데이터 (<span class="math inline">\(\mathcal{D}-\dim\)</span>)라고 가정해보자. 다항식 근사에서 order <span class="math inline">\(3\)</span> 까지 전개하면 다음과 같다.</p>
<p><span id="eq-ML_statistics_polynomial_expansion_of_mulitivariable"><span class="math display">\[
y(\boldsymbol{x},\,\boldsymbol{w})=w_0+\sum_{i=1}^\mathcal{D} w_i x_i + \sum_{i=1}^\mathcal{D}\sum_{j=1}^\mathcal{D} w_{ij}x_ix_j + \sum_{i=1}^\mathcal{D}\sum_{j=1}^\mathcal{D} \sum_{k=1}^\mathcal{D} w_{ijk}x_i x_j x_k
\tag{3.46}\]</span></span></p>
<p><span class="math inline">\(\mathcal{D}\)</span> 에 따라 3차항의 계수의 갯수는 <span class="math inline">\(\mathcal{D}^3\)</span> 개 만큼 증가하는 것처럼 보인다.(실제로는 interchange symmetry 로 인해 이것보다는 작지만 그래도 <span class="math inline">\(\mathcal{D}\gg M\)</span> 일 경우는 <span class="math inline">\(\mathcal{D}^M\)</span> 와 같이 증가한다. (<span class="citation" data-cites="Bishop2006">Bishop (<a href="ML.html#ref-Bishop2006" role="doc-biblioref">2006</a>)</span> exercise 1.16) 이것도 아주 급격하게 증가하는 것이다. )</p></li>
<li><p><span class="math inline">\({D}\)</span> 차원의 구를 생각하자. <span class="math inline">\({D}\)</span> 가 커질수록 구의 대부분의 부피는 표면에 분포한다. <span class="math inline">\({D}\)</span> 차원에서 반경 <span class="math inline">\(r\)</span> 인 구의 부피 <span class="math inline">\(V_D(r)=K_D r^D\)</span> 이다 여기에 작은 <span class="math inline">\(0&lt;\epsilon\ll 1\)</span> 을 생각하면 구 표면의 두께 <span class="math inline">\(\epsilon\)</span> 만큼의 껍질의 부피와 <span class="math inline">\(D\)</span> 차원에서의 unit sphere 의 부피의 비는, <span class="math display">\[
\dfrac{V_D(1)-V_D(1-r)}{V_D(1)}=1-(1-\epsilon)^D
\]</span> 임을 안다. <span class="math inline">\({D}\)</span> 가 커질 수록 작은 <span class="math inline">\(\epsilon\)</span> 에서의 값이 크다.</p></li>
<li><p><span class="math inline">\(D\)</span> 차원 가우시안 분포에서 이 데이터를 polar coordinate 로 바꾸어 보자. 차원이 늘어날수록 <span class="math inline">\(p(r)\)</span> 에서 가장 높은 확률을 가진 값이 점점 커진다. 이는 고차원 구에서 대부분의 부피가 spherical shell에 위치한다는 앞의 논리와 상응한다.</p></li>
<li><p>차원의 저주는 저차원에서의 직관이 고차원에서도 통용되지 않는 경우가 많음을 의미한다. 이 차원의 저주는 패턴 인식의 응용에 있어서 중요한 문제를 제기하지만 고차원을 다루는 효율적인 테크닉이 부족하거나 없다는 것을 의미하지는 않는다.</p>
<ul>
<li>고차원의 데이터라도 실제로는 보다 낮은 차원의 특정 영역에 데이터가 제한되어 있는 경우가 흔하며,</li>
<li>실제 데이터는 전형적으로 어떤 smoothness properties 를 (최소한 국소적으로라도) 가지고 있는 경우가 많다.</li>
</ul></li>
</ul>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Bishop2006" class="csl-entry" role="listitem">
Bishop, Christopher M. 2006. <em>Pattern Recognition and Machine Learning (Information Science and Statistics)</em>. Berlin, Heidelberg: Springer-Verlag.
</div>
<div id="ref-Goodfellow2016" class="csl-entry" role="listitem">
Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep Learning</em>. MIT Press.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "복사완료!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "복사완료!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../src/theory/regression.html" class="pagination-link" aria-label="선형 회귀">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">선형 회귀</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../src/theory/ML_basics.html" class="pagination-link" aria-label="기계학습의 기초">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">기계학습의 기초</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>