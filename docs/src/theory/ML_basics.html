<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>4&nbsp; 기계학습의 기초 – MachineLearning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../src/theory/classification.html" rel="next">
<link href="../../src/theory/statistics.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-b467865d89f01302b3bb45791fa41ab5.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "일치 없음",
    "search-matching-documents-text": "일치된 문서",
    "search-copy-link-title": "검색 링크 복사",
    "search-hide-matches-text": "추가 검색 결과 숨기기",
    "search-more-match-text": "추가 검색결과",
    "search-more-matches-text": "추가 검색결과",
    "search-clear-button-title": "제거",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "취소",
    "search-submit-button-title": "검색",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">MachineLearning</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="탐색 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../about.qmd"> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="사이드바 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../src/theory/ML.html">기계학습</a></li><li class="breadcrumb-item"><a href="../../src/theory/ML_basics.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">기계학습의 기초</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="사이드바 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">MachineLearning</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../src/theory/ML.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">기계학습</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/theory/optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">최적화</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/theory/regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">선형 회귀</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/theory/statistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">통계학 이론</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/theory/ML_basics.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">기계학습의 기초</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/theory/classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">퍼셉트론과 분류</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/theory/perceptron_and_ann.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">퍼셉트론과 인공신경망</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/theory/cnn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">합성곱 신경망</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">목차</h2>
   
  <ul>
  <li><a href="#학습-알고리즘" id="toc-학습-알고리즘" class="nav-link active" data-scroll-target="#학습-알고리즘"><span class="header-section-number">4.1</span> 학습 알고리즘</a>
  <ul class="collapse">
  <li><a href="#작업-t" id="toc-작업-t" class="nav-link" data-scroll-target="#작업-t"><span class="header-section-number">4.1.1</span> 작업 <span class="math inline">\(T\)</span></a></li>
  <li><a href="#성능-척도-p" id="toc-성능-척도-p" class="nav-link" data-scroll-target="#성능-척도-p"><span class="header-section-number">4.1.2</span> 성능 척도 <span class="math inline">\(P\)</span></a></li>
  <li><a href="#경험-e" id="toc-경험-e" class="nav-link" data-scroll-target="#경험-e"><span class="header-section-number">4.1.3</span> 경험 <span class="math inline">\(E\)</span></a></li>
  </ul></li>
  <li><a href="#capacitiy-overfitting-and-underfitting" id="toc-capacitiy-overfitting-and-underfitting" class="nav-link" data-scroll-target="#capacitiy-overfitting-and-underfitting"><span class="header-section-number">4.2</span> Capacitiy, Overfitting and Underfitting</a>
  <ul class="collapse">
  <li><a href="#reguralization" id="toc-reguralization" class="nav-link" data-scroll-target="#reguralization"><span class="header-section-number">4.2.1</span> Reguralization</a></li>
  </ul></li>
  <li><a href="#초매개변수와-검증-데이터" id="toc-초매개변수와-검증-데이터" class="nav-link" data-scroll-target="#초매개변수와-검증-데이터"><span class="header-section-number">4.3</span> 초매개변수와 검증 데이터</a>
  <ul class="collapse">
  <li><a href="#sec-ML_ML_cross_validation" id="toc-sec-ML_ML_cross_validation" class="nav-link" data-scroll-target="#sec-ML_ML_cross_validation"><span class="header-section-number">4.3.1</span> 교차 검증</a></li>
  </ul></li>
  <li><a href="#추정량-편향-분산" id="toc-추정량-편향-분산" class="nav-link" data-scroll-target="#추정량-편향-분산"><span class="header-section-number">4.4</span> 추정량, 편향, 분산</a>
  <ul class="collapse">
  <li><a href="#sec-ML_ML_point_estimation" id="toc-sec-ML_ML_point_estimation" class="nav-link" data-scroll-target="#sec-ML_ML_point_estimation"><span class="header-section-number">4.4.1</span> 점추정 (Point estimation)</a></li>
  <li><a href="#sec-ML_ML_bias" id="toc-sec-ML_ML_bias" class="nav-link" data-scroll-target="#sec-ML_ML_bias"><span class="header-section-number">4.4.2</span> 편향</a></li>
  <li><a href="#분산과-표준오차" id="toc-분산과-표준오차" class="nav-link" data-scroll-target="#분산과-표준오차"><span class="header-section-number">4.4.3</span> 분산과 표준오차</a></li>
  <li><a href="#평균제곱합을-최소화-하는-편향과-분산의-이율배반" id="toc-평균제곱합을-최소화-하는-편향과-분산의-이율배반" class="nav-link" data-scroll-target="#평균제곱합을-최소화-하는-편향과-분산의-이율배반"><span class="header-section-number">4.4.4</span> 평균제곱합을 최소화 하는 편향과 분산의 이율배반</a></li>
  </ul></li>
  <li><a href="#최대-우도" id="toc-최대-우도" class="nav-link" data-scroll-target="#최대-우도"><span class="header-section-number">4.5</span> 최대 우도</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../src/theory/ML.html">기계학습</a></li><li class="breadcrumb-item"><a href="../../src/theory/ML_basics.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">기계학습의 기초</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">기계학습의 기초</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="hidden">
<p>% %</p>
%
<p><span class="math display">\[
\DeclarePairedDelimiters{\set}{\{}{\}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\]</span></p>
</div>
<p>지금까지 최적화와 최적화의 예로서의 선형 회귀, 그리고 통계학에 대해 알아보았으며 이는 기계학습에 진입하기 위한 선행 학습이었다. 기계 학습은 단적으로 말해 컴퓨터를 사용하는 응용통계학이며, 확률론적 경사 하강법을 사용하는 최적화 알고리즘을 사용한다.</p>
<p><br></p>
<section id="학습-알고리즘" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="학습-알고리즘"><span class="header-section-number">4.1</span> 학습 알고리즘</h2>
<p>기계학습에서의 학습은 무엇을 의미하는가? Mitchell 은 다음과 같이 정의했다.</p>
<blockquote class="blockquote">
<p>컴퓨터 프로그램이 수행하는 어떤 부류의 작업 <span class="math inline">\(T\)</span> 와 이 작업에 대한 성능 측정 척도 <span class="math inline">\(P\)</span> 를 생각하자. 어떤 경험 <span class="math inline">\(E\)</span> 로 부터 <span class="math inline">\(P\)</span> 가 향상되었을 때 이 컴퓨터 프로그램이 <span class="math inline">\(T\)</span> 에 대한 경험 <span class="math inline">\(E\)</span> 로 부터 학습했다고 할 수 있다.</p>
</blockquote>
<p>기계학습에서의 학습은 보통 입력 벡터 <span class="math inline">\(\boldsymbol{x}\in \mathbb{R}^n\)</span> 와 출력값의 집합 <span class="math inline">\(Y\)</span> 에 대해에 대해 우리가 원하는 출력값을 출력하는 함수의 집합 가운데 학습을 통해 가장 잘 수행하는 함수 <span class="math inline">\(f:\mathbb{R}^n \to Y\)</span> 를 구하는 것이다. 학습은 <span class="math inline">\(\mathbb{R}^n \mapsto Y\)</span> 함수 가운데 <span class="math inline">\(P\)</span> 를 향상시키는 함수를 구하는 과정이다.</p>
<p><br></p>
<section id="작업-t" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="작업-t"><span class="header-section-number">4.1.1</span> 작업 <span class="math inline">\(T\)</span></h3>
<p>아래의 항목들은 일반적으로 기계학습을 통해 수행하는 작업을 분류한 것이지만 이것 이외에도 다양한 분야에 활용 될 수 있다. 단지 예일 뿐이다.</p>
<section id="분류-classificiation" class="level4">
<h4 class="anchored" data-anchor-id="분류-classificiation"><strong>분류 (Classificiation)</strong></h4>
<p>입력 벡터 각각을 <span class="math inline">\(k\)</span> 개의 카테고리중 하나에 지정하는 작업. 알고리즘은 <span class="math inline">\(f:\mathbb{R}^n \to \{1,\ldots,\,k\}\)</span> 을 찾는 것이다. 이의 변형으로 입력 벡터 각각에 대해 <span class="math inline">\(k\)</span> 개의 카테고리 각각에 포함될 확률을 구하는 것이 있다.</p>
<p><br></p>
</section>
<section id="불완전-입력에-대한-분류-classification-with-missing-inputs" class="level4">
<h4 class="anchored" data-anchor-id="불완전-입력에-대한-분류-classification-with-missing-inputs"><strong>불완전 입력에 대한 분류 (Classification with missing inputs)</strong></h4>
<p>예를 들어 의학 진단의 경우 진단에 비용, 환자의 상태 등의 이유로 필요한 모든 결과가 갖춰져 있지 않은 경우가 있다. 이 경우 학습을 통해 구하는 것은 단일한 함수가 아닌 함수의 집합이며 이 함수들은 입력 벡터 <span class="math inline">\(\boldsymbol{x}\)</span> 를 미입력 값에 대한 다양한 부분집합을 출력한다. <span class="math inline">\(n\)</span> 개의 입력 변수 각각이 결손될 수 있다고 하면 <span class="math inline">\(2^n\)</span> 개의 서로 다른 분류 함수가 필요하며 이것을 조합하여 결합확률분포를 얻는다.</p>
<p><br></p>
</section>
<section id="회귀-regression" class="level4">
<h4 class="anchored" data-anchor-id="회귀-regression"><strong>회귀 (Regression)</strong></h4>
<p>회귀는 <span class="math inline">\(f:\mathbb{R}^n \mapsto \mathbb{R}\)</span> 를 구하는 것이다.</p>
<p><br></p>
</section>
<section id="전사-transcription" class="level4">
<h4 class="anchored" data-anchor-id="전사-transcription"><strong>전사 (Transcription)</strong></h4>
<p>구조화되지 않은 입력을 이산적이고 언어적인 표현으로 바꾸는 작업을 말한다. OCR(optical character recognition), 음석 인식이 대표적이다.</p>
<p><br></p>
</section>
<section id="기계-번역-machine-traslation" class="level4">
<h4 class="anchored" data-anchor-id="기계-번역-machine-traslation"><strong>기계 번역 (Machine traslation)</strong></h4>
<p>글자 그대로</p>
<p><br></p>
</section>
<section id="구조화된-출력-structured-output" class="level4">
<h4 class="anchored" data-anchor-id="구조화된-출력-structured-output"><strong>구조화된 출력 (Structured output)</strong></h4>
<p>구조화되지 않은 입력을 구조화 시키는 작업. 예를 들어 일상 언어를 입력받아 문법 구조에 따른 트리 구조를 구성하고 이 트리 구조에 명사, 동사, 형용사 등의 택(tag) 을 붙이는 작업이 있다.</p>
<p><br></p>
</section>
<section id="비정상-탐지-anomaly-detection" class="level4">
<h4 class="anchored" data-anchor-id="비정상-탐지-anomaly-detection"><strong>비정상 탐지 (Anomaly detection)</strong></h4>
<p>예를 들면 신용카드 비정상 사용 감지. 이 경우 각각의 신용카드의 사용 습관을 분석하여 비정상 사용을 감지한다.</p>
<p><br></p>
</section>
<section id="합성과-샘플링-synthesis-and-sampling" class="level4">
<h4 class="anchored" data-anchor-id="합성과-샘플링-synthesis-and-sampling"><strong>합성과 샘플링 (Synthesis and sampling)</strong></h4>
<p>입력과 유사한 대상을 출력하는 작업을 말한다.</p>
<p><br></p>
</section>
<section id="imputation" class="level4">
<h4 class="anchored" data-anchor-id="imputation"><strong>Imputation</strong></h4>
<p>입력값 <span class="math inline">\(\boldsymbol{x}\in \mathbb{R}^n\)</span> 에 손상이 있을 때 이 값을 채워주는 작업.</p>
<p><br></p>
</section>
<section id="노이즈-제거-denoising" class="level4">
<h4 class="anchored" data-anchor-id="노이즈-제거-denoising"><strong>노이즈 제거 (Denoising)</strong></h4>
<p>글자 그대로</p>
<p><br></p>
</section>
<section id="확률-추정-probability-densitymass-estimation" class="level4">
<h4 class="anchored" data-anchor-id="확률-추정-probability-densitymass-estimation"><strong>확률 추정 (Probability density/mass estimation)</strong></h4>
<p><br></p>
</section>
</section>
<section id="성능-척도-p" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="성능-척도-p"><span class="header-section-number">4.1.2</span> 성능 척도 <span class="math inline">\(P\)</span></h3>
<p>분류, 불완전 입력에 대한 분류, 전사 와 같은 작업에 대해 그 정확도를 측정 할 수 있다. 여기서 정확도는 모델이 정확한 출력을 내는 비율이다. 혹은 에러율을 척도로 삼을 수도 있다. 그러나 확률 추정과 같은 경우는 이런 방법을 사용할 수는 없다. 즉 우리가 수행하고자 하는 작업마다 성능 척도는 달라진다. 또한 문제는 학습 이후 실제 데이터에 대해 작업을 수행할 때 학습의 정확도가 얼마나 보장되느냐 하는 것이다. 보통은 학습에 사용된 데이터셋과는 별도의 데이터셋을 이용해 테스트를 수행한다.</p>
<p>성능 척도란 것이 어휘상으로는 확정적이고 객관적으로 보일지라도 실제로는 시스템에 따라 선택하기 힘들 경우가 있다는 것이다. 예를 들어 전사의 경우 부분적으로 맞는 결과를 어떻게 평가할 것이냐는 문제가 있다. 또한 회귀의 경우는 작은 오차, 중간 크기의 오차, 큰 오차에 대해 어떤 가중치로 평가할 것이냐는 문제도 있다.</p>
<p><br></p>
</section>
<section id="경험-e" class="level3" data-number="4.1.3">
<h3 data-number="4.1.3" class="anchored" data-anchor-id="경험-e"><span class="header-section-number">4.1.3</span> 경험 <span class="math inline">\(E\)</span></h3>
<ul>
<li><p><strong>비지도 학습 (unsupervised learning)</strong> 의 경우 많은 특성(features) 를 포함하는 데이터셋을 경험하고 이 데이터셋의 구조의 유용한 특징을 학습한다. 딥러닝의 맥락에서 이것은 이 데이터 셋을 만들어넨 전체 확률 분포를 학습하는 것이라고 볼 수 있다. 명시적인 학습으로는 한다면 확률 추정이 있고 암시적인 학습으로는 합성과 샘플링이 있다. 다른 예로는 clustering 이 있다.</p></li>
<li><p><strong>지도학습 (supervised learning)</strong> 에 사용되는 데이터셋은 각각의 데이터에 대해 <em>target</em> 혹은 <em>레이블(label)</em> 이라고 불리는 정답이 붙어 있다.</p></li>
<li><p><strong>강화 학습 (reinforcedment learning)</strong> 은 데이터 셋이 아니라 환경과의 상호작용을 통해 학습힌다.</p></li>
</ul>
<p><br></p>
<p>우리는 앞서 선형 회귀에서 <strong>설계행렬 (design matrix)</strong> 을 정의했다. 설계행렬은 단순히 선형 회귀 뿐만 아니라 데이터의 특징을 수로 정리한 데이터를 의미한다. 예를 들어 <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">Fisher’s Iris data</a> 는 150 개의 붓꽃 각각 대한 4가지의 특성과 3개의 종이 정리된 데이터이다. 일반적으로 설계행렬에서 한 데이터셋은 한 행으로 표현되므로 붓꽃 데이터는 <span class="math inline">\(150 \times 4\)</span> 의 설계행렬로 정리 될 수 있다. 입력 데이터는 같은 크기의 벡터로 정리되는 것이 좋지만 항상 그렇게 할 수 있는 것은 아니며 이 경우에는 각각의 경우에 맞게 처리해야 한다. 이런 경우까지 포함하여 입력 데이터를 <span class="math inline">\(\{x^{(1)}, \, \boldsymbol{x}^{(2)},\ldots,\}\)</span> 와 같은 형태로 표현한다. <span class="math inline">\(\boldsymbol{x}^{(i)}\)</span> 와 <span class="math inline">\(\boldsymbol{x}^{(j)}\)</span> 는 같은 크기의 벡터가 아닐 수도 있다.</p>
<p><br></p>
</section>
</section>
<section id="capacitiy-overfitting-and-underfitting" class="level2 page-columns page-full" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="capacitiy-overfitting-and-underfitting"><span class="header-section-number">4.2</span> Capacitiy, Overfitting and Underfitting</h2>
<p>기계 학습에서 가장 중요한 목표중의 하나는 학습/훈련에 사용된 데이터에 대해서 뿐만 아니라 새로운, 이전에 사용되지 않았던 입력에 대해서도 잘 동작해야 한다는 것이다. 이런 능력을 <strong>일반화 (generalization)</strong> 라고 한다.</p>
<p>데이터를 학습 시킬 때 훈련 데이터에 대해 발생하는 에러를 <strong>훈련 오차 (training error)</strong> 라고 한다. 선형 회귀의 경우 <a href="regression.html#eq-ML_linear_regression_master_equation_with_L2" class="quarto-xref">식&nbsp;<span>2.3</span></a> 을 학습 데이터당 에러로 변형하면</p>
<p><span class="math display">\[
\dfrac{1}{m^{(\text{train})}} \|\boldsymbol{y}^{(\text{train})}- \boldsymbol{\Phi^{(\text{train})} \theta}\|_2^2
\]</span></p>
<p>이다. 같은 논리로 시험용 데이터에 대해 <strong>시험 오차 (test error)</strong> 를 아래와 같이 정의 할 수 있다.</p>
<p><span class="math display">\[
\dfrac{1}{m^{(\text{test})}} \|\boldsymbol{y}^{(\text{test})}- \boldsymbol{\Phi^{(\text{test})} \theta}\|_2^2
\]</span></p>
<p>이 될 것이다. 여기서 <span class="math inline">\(m^{(\text{train})},\, m^{(\text{test})}\)</span> 는 각각 훈련과 시험에 사용된 데이터의 개수이다.</p>
<p>훈련 데이터와 시험 데이터는 어떤 확률 분포를 따르는 과정에 의해 생성된다. 이 과정을 데이터 생성 과정 (data generating process) 라고 부른다. 우리는 이 데이터들에 대해 <em>i,i,d 가정 (i,i, d assumptions)</em> 이라는 가정을 상정한다. 이 가정은</p>
<ul>
<li>각각의 데이터셋은 서로 독립적이며, (<em>independent</em>)</li>
<li>훈련 데이터셋과 시험 데이터셋은 같은 확률분포를 따른다. (<em>identically distributed</em>)</li>
</ul>
<p>이다. 이 가정은 데이터 생성 과정을 <span class="math inline">\(i.i.d\)</span> 가정의 확률 분포를 이용하여 수학적으로 다룰 수 있도록 한다. 이 확률 분포를 데이터에 대해 <strong>데이터 생성 분포 (data generating distribution)</strong> 라고 부르며 <span class="math inline">\(p_\text{data}\)</span> 로 표기한다. 훈련 데이터와 시험 데이터는 <span class="math inline">\(p_\text{data}\)</span> 에 대한 샘플링이다. 훈련은 훈련 데이터셋에 대해서만 수행한다. 즉 학습 매개변수 <span class="math inline">\(\boldsymbol{\theta}\)</span> 는 훈련용 데이터에 대해 학습되었으므로 시험 오차는 훈련 오차보다 크거나 같을 것으로 기대할 수 있다. 학습이 잘 되어있는지를 결정하는 요인은</p>
<ol type="1">
<li>훈련 오차를 작게,</li>
<li>훈련 오차와 시험 오차의 차이를 작게</li>
</ol>
<p>하는 것이다. 앞서 언급한 underfitting 은 훈련 오차가 큰 것이며, overfitting 은 훈련 오차와 시험 오차의 차이가 큰 것이다.</p>
<div class="page-columns page-full"><p>underfit 이나 overfit 이 발생하는 상황은 모델의 <strong>capacity</strong> 를 변화시키면서 조절 할 수 있다. 모델의 capacity 는 이 모델로 표현할 수 있는 함수의 다양성을 의미한다. <strong>가설 공간 (hypothesis space)</strong> 을 학습 알고리즘에 의해 선택될 수 있는 함수의 집합이라고 하면 모델의 capacity 는 가설공간의 크기에 상응하는 값이 될 것이다. 기계 학습 알고리즘이 가장 좋은 성능을 내는 경우는 작업(task) 의 복잡성에 과 비교했을 때 적당한 capacity 를 갖는 모델을 선택하고, 역시 적당한 수의 훈련 데이터를 사용하여 훈련시켰을 때 이다. 문제의 복잡성에 비해 너무 큰 capacity 를 가진 모델을 선택한다면 당연해 overfit 이 발생 할 수 있다.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">capacity 는 complexity, expressive power, richness, or flexibility 라고 불리기도 한다.</span></div></div>
<p>모델의 capcity 를 변경시키는 방법으로는 우선 입력 벡터의 크기(개수가 아니라)를 변화시키는 것, 즉 모델 매개변수의 크기를 변화시키는 것이다. 예를 들어 선형 회귀에서 <span class="math inline">\(\boldsymbol{x}\)</span> 가 2차원에서 3차원이 된다면 매개변수는 3개에서 4개로 증가한다. 선택된 모델에 대해 기계학습은 가장 최적화된 파라미터를 찾게 되지만 많은 경우 훈련 오차를 줄이는 파라미터를 찾게 된다. 즉 비용함수에 대해 전역적 최소점이 아닌 국소적 최소점을 찾게 된다. 실제로 모델 훈련 과정에서 모델의 capacity 를 전부다 활용하지 못하며, 모델 capacity 의 일부분에 대해서만 선택할 수 있는 경우가 대부분이다. 이렇게 모델의 capacity 가운데 실제로 선택될 수 있는 함수의 집합을 모델의 <strong>representive capacity</strong> 라고 한다.</p>
<p>통계학적 학습 이론(Statistical learning theory) 는 이 capacity 에 대한 다양한 정량화 수단을 제공한다. 예를 들어 Vapnik-Chervonenkis 차원(VC dimension) 은 이진 분류기(binary classifier) 에 대한 척도이다. 하지만 대부분의 경우 이론적 관심에 머무는 경우가 많은데 정량화된 값을 구하기 너무 어렵거나 구했다고 하더라도 실제로 사용하기에는 실용적이지 않기 때문이다.</p>
<p><br></p>
<section id="reguralization" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="reguralization"><span class="header-section-number">4.2.1</span> Reguralization</h3>
<p><br></p>
</section>
</section>
<section id="초매개변수와-검증-데이터" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="초매개변수와-검증-데이터"><span class="header-section-number">4.3</span> 초매개변수와 검증 데이터</h2>
<p>대부분의 기계 학습 알고리즘은 학습 알고리즘의 동작을 제어하는 설정을 가지고 있으며 이 설정을 <strong>초매개변수 (hyperparameters)</strong> 라고 한다. 매개변수는 학습 과정에서 조절되지만 초매개변수는 그렇지 않다. 예를 들어 다항함수 회귀에서 다항식의 차수가 초매개변수이다. Regularization <a href="regression.html#eq-ML_regression_regulaization" class="quarto-xref">식&nbsp;<span>2.5</span></a> 의 <span class="math inline">\(\lambda\)</span> 역시 초매개변수이다.</p>
<p>초매개변수를 최적화하기 위해 일반적으로 <strong>검증 데이터셋 (validation dataset)</strong> 을 사용한다. 검증 데이터셋은 훈련 데이터셋의 일부를 사용하며 당연히 시험 데이터셋과는 겹치지 않아야 한다. 보통 훈련 데이터셋의 80% 는 훈련에, 20% 는 검증 데이터셋으로 사용한다. 검증 데이터셋을 사용하면 초매개변수를 학습 과정에서 직접 최적화하지 않고도 모델의 일반화 성능을 유지할 수 있다. 그러나 검증 데이터셋을 너무 자주 사용하면 검증 데이터에 대해 과적합(overfitting)이 발생할 수 있다.</p>
<p><br></p>
<section id="sec-ML_ML_cross_validation" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="sec-ML_ML_cross_validation"><span class="header-section-number">4.3.1</span> 교차 검증</h3>
<p><strong>교차 검증 (cross-validation)</strong> 기법은 데이터 셋이 충분하지 않을 때 사용 할 수 있다. 충분하지 않은 데이터셋을 훈련용, 검증용, 시험용으로 나누게 된다면, 특별히 시험용 데이터셋의 갯수가 적기 때문에 통계적인 불확실성이 커지게 된다. <strong><span class="math inline">\(k\)</span>-겹 교차 검증 (<span class="math inline">\(k\)</span>-fold cross-validation)</strong> 은 데이터를 <span class="math inline">\(k\)</span> 개의 폴드로 나누고, <span class="math inline">\(k\)</span> 번의 학습-검증 과정을 통해 초매개변수를 조정한다. 이 방법은 검증 데이터셋에 대한 과적합을 줄이고, 모델의 일반화 성능을 더 잘 평가할 수 있도록 돕는다.</p>
<p><br></p>
</section>
</section>
<section id="추정량-편향-분산" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="추정량-편향-분산"><span class="header-section-number">4.4</span> 추정량, 편향, 분산</h2>
<p>통계학은 학습 데이터 셋에 대해서 뿐만 아니라 일반화의 경우에도 기계학습을 통해 하고자 하는 작업을 수행하는 데 도움이 되는 많은 도구를 제공한다.</p>
<section id="sec-ML_ML_point_estimation" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="sec-ML_ML_point_estimation"><span class="header-section-number">4.4.1</span> 점추정 (Point estimation)</h3>
<p>우리가 관심 이 있는 어떤 값을 추정하는 것을 말한다. 단일한 스칼라 일수도 있고 벡터일 수도 있다. 이 때 실제 값 <span class="math inline">\(\boldsymbol{\theta}\)</span> 에 해 추정값을 <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> 와 같이 표기하자. <span class="math inline">\(m\)</span> 개의 독립적이고 동일한 분포를 따르는(즉 i.i.d 가정을 따르는) 데이터의 집합 <span class="math inline">\(\{\boldsymbol{x}^{(1)},\ldots,\,\boldsymbol{x}^{(m)}\}\)</span> 을 생각하자. <span class="math inline">\(m\)</span> 개의 데이터에 대한 점추정 <span class="math inline">\(\hat{\boldsymbol{\theta}}_m\)</span> 은 <span class="math inline">\(\{\boldsymbol{x}^{(1)},\ldots,\,\boldsymbol{x}^{(m)}\}\)</span> 의 함수이다.</p>
<p><span id="eq-ML_ML_point_estimate"><span class="math display">\[
\hat{\boldsymbol{\theta}}_m = g(\{\boldsymbol{x}^{(1)},\ldots,\,\boldsymbol{x}^{(m)}\}).
\tag{4.1}\]</span></span></p>
<p>이 정의 자체는 함수 <span class="math inline">\(g\)</span> 가 <span class="math inline">\(\boldsymbol{\theta}\)</span> 와 가까운 값을 출력한다는 보장도 없고 심지어 <span class="math inline">\(\boldsymbol{\theta}\)</span> 의 가능한 영역에서 출력한다는 보장도 없다. 그러나 당연히 좋은 추정이 되려면 <span class="math inline">\(\boldsymbol{\theta}\)</span> 에 가까운 값을 반환해야 한다. 당분간 빈도주의적 입장에 서도록 하자. <span class="math inline">\(\boldsymbol{\theta}\)</span> 는 어떤 정해진 값이며, 단지 우리는 이 값을 모를 뿐이고, <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> 는 데이터에 대한 함수이다. <u>데이터는 확률 과정에 의햇 선택되었으며, 어떤 데이터의 함수도 임의적이다. 따라서 <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> 도 확률 변수이다.</u></p>
<p><br></p>
<p>이 점추정을 확장하면 우리는 입력값과 출력값에 대한 추정을 포함 할 수 있다. 이를 <strong>함수 추정 (function estimation)</strong> 이라고 한다. 입력 <span class="math inline">\(\boldsymbol{x}\)</span> 와 출력 <span class="math inline">\(\boldsymbol{y}\)</span> 사이에 <span class="math inline">\(\boldsymbol{y}=f(\boldsymbol{x}) + \boldsymbol{\epsilon}\)</span> 의 관계가 성립한다고 가정 할 수 있다. 여기서 <span class="math inline">\(\boldsymbol{\epsilon}\)</span> 은 <span class="math inline">\(\boldsymbol{x}\)</span> 로부터 예상 할 수 없는 <span class="math inline">\(\boldsymbol{y}\)</span> 의 일부이다. 함수 추정에서 우리는 <span class="math inline">\(f\)</span> 를 모델 <span class="math inline">\(\hat{f}\)</span> 로 근사한다. 함수 추정은 실제로 매개변수 <span class="math inline">\(\boldsymbol{\theta}\)</span> 에 대한 추정이며, 함수공간에서의 점추정이다.</p>
<p><br></p>
</section>
<section id="sec-ML_ML_bias" class="level3" data-number="4.4.2">
<h3 data-number="4.4.2" class="anchored" data-anchor-id="sec-ML_ML_bias"><span class="header-section-number">4.4.2</span> 편향</h3>
<p><span class="math inline">\(\boldsymbol{\theta}\)</span> 에 대한 추정량 <span class="math inline">\(\hat{\boldsymbol{\theta}}_m\)</span> 에 대한 편향 <span class="math inline">\(\text{bias}(\hat{\boldsymbol{\theta}}_m)\)</span> 은 다음과 같이 정의된다.</p>
<p><span id="eq-ML_ML_definition_of_bias"><span class="math display">\[
\boxed{\text{bias}(\hat{\boldsymbol{\theta}}_m) = \mathbb{E}(\hat{\boldsymbol{\theta}}_m) -\boldsymbol{\theta}}.
\tag{4.2}\]</span></span></p>
<p><span class="math inline">\(\text{bias}(\hat{\boldsymbol{\theta}}_m) = 0\)</span> 일 경우 <span class="math inline">\(\hat{\boldsymbol{\theta}}_m\)</span> 이 편향되지 않았다(unbiased) 라고 하고, 변향되지 않은 추정량을 <strong>불편추정량(不偏推定量, unbiased estimator)</strong> 이라고 한다. 이 경우 <span class="math inline">\(\text{bias}(\hat{\boldsymbol{\theta}}_m) = \mathbb{E}(\hat{\boldsymbol{\theta}}_m)\)</span> 이다. <span class="math inline">\(\lim_{m \to \infty}\text{bias}(\hat{\boldsymbol{\theta}}_m) = 0\)</span> 일 경우 이 <span class="math inline">\(\hat{\boldsymbol{\theta}}_m\)</span> 을 <strong>점근적 불편추정량(asymptotically unbiased estimator)</strong> 이라고 한다.</p>
<p><br></p>
<div class="border" style="background-color:#F2F4F4  ;padding:5px;">
<div id="exm-ML_ML_bernoulli_distribution" class="theorem example">
<p><span class="theorem-title"><strong>예제 4.1 (베르누이 분포에서의 평균값)</strong></span> <span class="math inline">\(\{x^{(1)},\ldots,\, x^{(m)}\}\)</span> 이 <a href="../../src/theory/statistics.html#sec-ML_statistics_bernoulli_distribution">베르누이 분포</a>를 i.i.d 로 따르는 표본이라고 하자. <span class="math inline">\(x=1\)</span> 에 대한 확률을 <span class="math inline">\(\theta\)</span> 라고 하면</p>
<p><span class="math display">\[
P(x^{(i)};\theta)= \theta^{x^{(i)}} (1-\theta)^{1-x^{(i)}}
\]</span></p>
<p>이다. 이제 <span class="math inline">\(\theta\)</span> 에 대한 추정값은 다음과 같다.</p>
<p><span class="math display">\[
\hat{\theta}_m = \dfrac{1}{m} \sum_{i=1}^m x^{(i)}.
\]</span></p>
<p>그렇다면,</p>
<p><span class="math display">\[
\begin{aligned}
\text{bias}(\hat{\theta}_m) &amp;= \mathbb{E}[\hat{\theta}_m] -\theta = \dfrac{1}{m}\mathbb{E}[x^{(i)}] -\theta \\[0.3em]
&amp;= \dfrac{1}{m} \sum_{i=1}^m \sum_{x^{(i)} \in \{0,\,1\}}\left[x^{(i)}P(x^{(i)};\theta)\right] \\[0.3em]
&amp;= \left(\dfrac{1}{m} \sum_{i=1}^m \theta\right) - \theta = 0
\end{aligned}
\]</span></p>
<p>이다. 즉 <span class="math inline">\(\hat{\theta}\)</span> 는 불편추정량이다.</p>
</div>
</div>
<p><br></p>
<div class="border" style="background-color:#F2F4F4  ;padding:5px;">
<div id="exm-ML_ML_gaussian_distributino_estimator_of_the_mean" class="theorem example">
<p><span class="theorem-title"><strong>예제 4.2 (가우시안 분포에서의 평균 추정)</strong></span> <span class="math inline">\(\{x^{(1)},\ldots,\, x^{(m)}\}\)</span> 이 평균 <span class="math inline">\(\mu\)</span>, 표준편차 <span class="math inline">\(\sigma^2\)</span> 에 대한 <a href="../../src/theory/statistics.html#sec-ML_statistics_normal_distribution">가우스 분포</a>를 i.i.d 로 따르는 표본이라고 하자. 확률분포는 아래와 같다.</p>
<p><span class="math display">\[
P(x^{(i)};\mu,\, \sigma^2)= \dfrac{1}{\sqrt{2\pi \sigma^2}} \exp \left[- \dfrac{\left(x^{(i)}-\mu\right)^2}{2\sigma^2}\right]
\]</span></p>
<p>이다. <span class="math inline">\(\mu\)</span> 에 대한 일반적인 추정값은 표본 평균 <span class="math inline">\(\hat{\mu}_m\)</span> 으로 다음과 같다,.</p>
<p><span id="eq-ML_ML_sample_mean"><span class="math display">\[
\boxed{\hat{\mu}_m = \dfrac{1}{m} \sum_{i=1}^m x^{(i)}}.
\tag{4.3}\]</span></span></p>
<p>그렇다면,</p>
<p><span class="math display">\[
\begin{aligned}
\text{bias}(\hat{\mu}_m) &amp;= \mathbb{E}[\hat{\mu}_m] -\theta = \dfrac{1}{m}\mathbb{E}[x^{(i)}] -\theta \\[0.3em]
&amp;= \dfrac{1}{m} \sum_{i=1}^m \sum_{x^{(i)} \in \{0,\,1\}}\left[x^{(i)}P(x^{(i)};\mu,\, \sigma^2)\right] \\[0.3em]
&amp;= \left(\dfrac{1}{m} \sum_{i=1}^m \mu\right) - \mu = 0
\end{aligned}
\]</span></p>
<p>이다. 즉 <span class="math inline">\(\hat{\theta}\)</span> 는 불편추정량이다.</p>
</div>
</div>
<p><br></p>
<div class="border" style="background-color:#F2F4F4  ;padding:5px;">
<div id="exm-ML_ML_gaussian_distributino_estimator_of_the_variance" class="theorem example">
<p><span class="theorem-title"><strong>예제 4.3 (가우시안 분포에서의 분산 추정)</strong></span> 가우시안 분포의 분산 <span class="math inline">\(\sigma^2\)</span> 에 대한 일반적인 추정값은 <strong>표본 분산(sample variance)</strong> <span class="math inline">\(\hat{\sigma}^2_m\)</span> 으로 다음과 같다,.</p>
<p><span id="eq-ML_ML_sample_variance"><span class="math display">\[
\boxed{\hat{\sigma}_m = \dfrac{1}{m} \sum_{i=1}^m  \left(x^{(i)} - \hat{\mu}_m\right)^2}.
\tag{4.4}\]</span></span></p>
<p>그렇다면,</p>
<p><span class="math display">\[
\text{bias}(\hat{\sigma}^2_m) = \mathbb{E}[\hat{\sigma}^2_m] -\sigma^2
\]</span></p>
<p>이며 우선 <span class="math inline">\(\mathbb{E}[\hat{\sigma}^2_m]\)</span> 를 계산해보자.</p>
<p><span class="math display">\[
\begin{aligned}
\mathbb{E}[\hat{\sigma}^2_m] &amp;= \dfrac{1}{m}\mathbb{E}\left[\sum_{i=1}^m \left(x^{(i)} -\hat{\mu}_m\right)^2\right] \\
&amp;=\dfrac{1}{m}\left[\mathbb{E} \left[(x^{(i)} - \mu - (\hat{\mu}_m - \mu))^2\right]\right] \\[0.3em]
&amp;= \mathbb{E} \left[\dfrac{1}{m}\sum_{i=1}^m \left(x^{(i)} - \mu\right)^2\right]  +\mathbb{E} \left[\dfrac{1}{m}\sum_{i=1}^m(\hat{\mu}_m- \mu)^2\right] \\
&amp;\qquad \qquad - 2\mathbb{E}\left[\dfrac{1}{m}\sum_{i=1}^m\left(x^{(i)} - \mu\right) \left(\hat{\mu}_m - \mu\right)\right] \\[0.3em]
\end{aligned}
\]</span></p>
<p>이다. <a href="statistics.html#eq-ML_ststistics_properties_of_1d_gaussian_distribution" class="quarto-xref">식&nbsp;<span>3.32</span></a> 로 부터</p>
<p><span class="math display">\[
\begin{aligned}
\mathbb{E} \left[\dfrac{1}{m}\sum_{i=1}^m \left(x^{(i)} - \mu\right)^2\right] &amp;= \sigma^2, \\
\mathbb{E} \left[\dfrac{1}{m}\sum_{i=1}^m( \hat{\mu}_m - \mu)^2\right] &amp;= \mathbb{E}\left[(\hat{\mu}_m - \mu)^2\right], \\
\mathbb{E}\left[\dfrac{1}{m}\sum_{i=1}^m\left(x^{(i)} - \mu\right) \left(\hat{\mu}_m - \mu\right)\right] &amp;= \mathbb{E}\left[(\hat{\mu}_m - \mu)^2\right]
\end{aligned}
\]</span></p>
<p>이며,</p>
<p><span class="math display">\[
\begin{aligned}
\mathbb{E}\left[(\hat{\mu}_m - \mu)^2\right] &amp;= \mathbb{E}\left[\left(\dfrac{1}{m}\sum_{j=1}^m x^{(i)}-\mu\right)^2\right] \\
&amp;= \mathbb{E}\left[\left(\dfrac{1}{m}\sum_{j=1}^m x^{(j)}-\mu\right)\left(\dfrac{1}{m}\sum_{k=1}^m x^{(k)}-\mu\right)\right] \\[0.3em]
&amp;=\dfrac{1}{m^2} \mathbb{E}\left[\left(\sum_{j=1}^m x^{(j)}-m\mu\right) \left(\sum_{k=1}^m x^{(k)}-m\mu\right)\right] \\[0.3em]
&amp;= \dfrac{1}{m^2} \left\{\mathbb{E}\left[\sum_{j=1}^m \left(x^{(j)}\right)^2\right] + \mathbb{E}\left[\sum_{j,\,k=1,\, j\ne k}^m x^{(j)}x^{(k)} \right] \right. \\
&amp;\qquad \qquad \left.-2m\mu \mathbb{E}\left[\sum_{j=1}^m x^{(j)}\right] +m^2\mu^2 \right\} \\[0.3em]
&amp;= \dfrac{1}{m^2} \left(m(\mu^2+\sigma^2) + m(m-1)\mu^2-2m^2\mu^2 + m^2 \mu^2\right) = \dfrac{\sigma^2}{m}
\end{aligned}
\]</span></p>
<p>이다. 즉</p>
<p><span class="math display">\[
\mathbb{E}[\hat{\sigma}^2_m] = \sigma^2 - \dfrac{\sigma^2}{m}= \dfrac{m-1}{m}\sigma^2
\]</span></p>
<p>이므로 <span class="math inline">\(\text{bias}\left(\hat{\sigma}^2_m\right) \ne 0\)</span> 이다. 이렇게 정의된 <span class="math inline">\(\hat{\sigma}_m^2\)</span> 는 편향되어 있다. 그러나</p>
<p><span id="eq-ML_ML_unbiased_sample_variance"><span class="math display">\[
\tilde{\sigma}_m^2 := \dfrac{1}{m-1} \sum_{i=1}^m \left(x^{(i)}-\mu\right)^2
\tag{4.5}\]</span></span></p>
<p>로 정의하면,</p>
<p><span class="math display">\[
\mathbb{E}\left[\tilde{\sigma}_m^2\right] = \sigma^2
\]</span></p>
<p>이며, 따라서 <a href="#eq-ML_ML_unbiased_sample_variance" class="quarto-xref">식&nbsp;<span>4.5</span></a> 으로 정의된 <span class="math inline">\(\tilde{\sigma}_m^2\)</span> 를 <strong>불편 표본분산(unbiased sample variance)</strong> 라고 한다.</p>
</div>
</div>
<p><br></p>
</section>
<section id="분산과-표준오차" class="level3" data-number="4.4.3">
<h3 data-number="4.4.3" class="anchored" data-anchor-id="분산과-표준오차"><span class="header-section-number">4.4.3</span> 분산과 표준오차</h3>
<p>추정값 <span class="math inline">\(\hat{\theta}\)</span> 에 대한 분산을 <span class="math inline">\(\text{Var}(\hat\theta)\)</span> 라고 표기하고 이 분산의 제곱근을 표준오차(standard error) 라고 하며 <span class="math inline">\(\text{SE}(\hat\theta)\)</span> 라고 표기한다. 이 분산과 표준오차는 우리가 동일한 데이터 생성 과정을 통해 데이터를 리샘플링 할 경우 발생할 수 있는 변화에 대한 추정량이다.</p>
<p>우리거 어떤 통계학적 계산을 유한개의 샘플로 수차례 수행할 경우 각 경우마다 결과값이 다를 수 있고, 많은 경우 그러하다. 평균에 대한 표준오차는 다음과 같다.</p>
<p><span class="math display">\[
\text{SE}(\hat{\mu}_m) = \sqrt{\text{Var}\left[\dfrac{1}{m} \sum_{i=1}^m x^{(i)} \right]} = \dfrac{\sigma}{\sqrt{m}}.
\]</span></p>
<p>여기서 <span class="math inline">\(\sigma^2\)</span> 는 <span class="math inline">\(x^{(i)}\)</span> 가 따르는 분포의 실제 분산이다.</p>
<p>평균에 대한 표준 오차는 기계 학습 실험에서 매우 유용하다. 보통 시험 데이터셋에서의 샘플 평균에 대한 오차를 계산하여 일반화 오차를 가늠한다. 이 경우 시험 데이터셋의 갯수가 이 추정의 정확도를 결정한다. 중심극한정리는 이 평균값이 근사적으로 정규분포를 따른다는 것을 보장한다. 실제 기대값이 정해진 범위 안에 있을 확률을 계산 할 수 있다. 예를 들어 95% 신뢰구간은</p>
<p><span class="math display">\[
(\hat{\mu}_m - 1.96 \, \text{SE}(\hat{\mu}_m)) ,\, \hat{\mu}_m + 1.96 \, \text{SE}(\hat{\mu}_m))
\]</span></p>
<p>이다. 기계학습에서 알고리즘 <span class="math inline">\(A\)</span> 가 <span class="math inline">\(B\)</span></p>
<div class="border" style="background-color:#F2F4F4  ;padding:5px;">
<div id="exm-ML_ML_bernoulli_distribution_variance_and_standard_error" class="theorem example">
<p><span class="theorem-title"><strong>예제 4.4 (베르누이 분포에서의 표준오차)</strong></span> 베르누이 분포와 i.i.d 가정을 따르는 샘플 <span class="math inline">\(\{x^{(1)},\ldots,\,x^{(m)}\}\)</span> 을 생각하자. 베르누이 분포가 <span class="math inline">\(P(x^{(i)};\theta) = \theta^{x^{(i)}} (1-\theta)^{(1-x^{i})}\)</span> 이다. 이 경우</p>
<p><span class="math display">\[
\begin{aligned}
\text{Var}(\hat{\theta}_m) = \text{Var} \left(\dfrac{1}{m}\sum_{i=1}^m x^{(i)}\right) = \dfrac{\theta (1-\theta)}{m}
\end{aligned}
\]</span></p>
<p>이다.</p>
</div>
</div>
<p><br></p>
</section>
<section id="평균제곱합을-최소화-하는-편향과-분산의-이율배반" class="level3" data-number="4.4.4">
<h3 data-number="4.4.4" class="anchored" data-anchor-id="평균제곱합을-최소화-하는-편향과-분산의-이율배반"><span class="header-section-number">4.4.4</span> 평균제곱합을 최소화 하는 편향과 분산의 이율배반</h3>
<p>편향(bias)은 함수 혹은 매개변수의 실제값과 기대값의 차이에 대한 척도이며, 분산은 어떤 특정한 표본 추출이 발생시키는 추정값과 실제값의 차이에 대한 척도이다. 이 편향과</p>
<p><span class="math display">\[
\begin{aligned}
\text{MSE} &amp;= \mathbb{E}\left[(\hat{\theta}_m - \theta)^2\right]
\end{aligned}
\]</span></p>
<ul>
<li>to be done *</li>
</ul>
<hr>
<p><br></p>
</section>
</section>
<section id="최대-우도" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="최대-우도"><span class="header-section-number">4.5</span> 최대 우도</h2>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "복사완료!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "복사완료!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../src/theory/statistics.html" class="pagination-link" aria-label="통계학 이론">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">통계학 이론</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../src/theory/classification.html" class="pagination-link" aria-label="퍼셉트론과 분류">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">퍼셉트론과 분류</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>