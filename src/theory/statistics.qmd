---
title: "통계학 이론"

number-sections: true
number-depth: 3
crossref:
  chapters: false
---

{{< include ../../../latexmacros.qmd >}}

</br>

## 베이지안 통계 (Bayesian Probabilities)

지금까지 우리는 확률을 무작위성(randomness) 과 반복적인 사건(repeated events) 이라는 **고전적(classica)** 혹은 **빈도적(frequencies)** 이라고 불리는 관점에서 봤다. 이제 우리는 확률을 이용하여 불확실성을 정량화하는 **Bayesian** 관점을 학습할 것이다.


커브 피팅 혹은 모델링을 생각하자. 즉 측정된 값 $\mathcal{D}=\{t_1,\ldots,\,t_n\}$ 을 통해 측정값을 가장 잘 기술하는 함수 $y(\bf{x};\,\bf{w})$ 를 결정한다고하자. 여기서 $\bf{w}$ 는 모델 매개변수이다. 빈도주의적 입장에서 $\bf{w}$ 는 확률이 아닌 우리가 알 내야 하는 값이 된다. 이에 대한 베이즈 정리는 다음과 같다.
$$
p(\bf{w}\,|\, \mathcal{D})=\dfrac{p(\mathcal{D}\,|\,\bf{w}) \cdot p(\bf{w})}{p(\mathcal{D})}.
$$

여기서 $p(\mathcal{D}\,|\,\bf{w})$ 를 **가능도** 혹은 **우도 (likelihood function)** 라고 하고  $p(\bf{w})$ 를 **사전 확률 분포 (prior distribution)** 라고 한다. $p(\mathcal{D})$ 는 정규화 상수(normalization constant) 이다. $p(\mathcal{D})$ 는 실험 결과에 따라 정해지는 확률이기 때문에 실험이 종료된 상황에서는 상수일 뿐이다.

</br>

#### **고전적/빈도주의적 입장**

고전적 입장에서는 $p(\bf{w})=1$ 이다. 따라서 $p(\bf{w}|\mathcal{D})$ 를 최대화 하는 것은 $p(\mathcal{D}|\bf{w})$ 를 최대화 하는 것이다. 보통 기계학습에서 에러 함수 $L(\bf{w})=-\ln p(\mathcal{D}|\bf{w})$ 이므로 에러 함수를 최소화 하는 것은 가능도를 최대로 하는 것과 동치이다.



</br>

#### **베이지언적 입장**

매개변수 $\bf{w}$ 는 고정된 값이 아닌 확률로 표현되는 값이다. 데이터를 보기 전에 $p(\bf{w})$ 에 대해 임시로 정한다. $\mathcal{D}=\{t_1,\ldots,\,t_N\}$ 는 $p(\mathcal{D}\,|\,\bf{w})$ 에 반영된다. 
  
- 빈도주의적이든 베이즈적이든 $p(\mathcal{D}|\bf{w})$ 가 중심적인 역할을 하지만 이에 대한 두 입장의 견해는 매우 다르다. 빈도주의 입장에서는 $\bf{w}$ 는 고정된 매개변수 이며 그 값과 에러는 $\mathcal{D}$ 의 분포를 고려하여 얻어진다. 그러나 베이즈주의적 입장에서는 유일한 $\mathcal{D}$ 가 존재하며 매개변수 $\bf{w}$ 가 확률 분포 $p(\bf{w})$ 로서 표현된다.

- 널리 사용되는 빈도주의자들의 estimator는 *최대 가능도* 혹은 *최대 우도 (maximum likelihood)* 이다. 이 입장에서는 $p(\bf{w})=1$ 이므로 $p(\mathcal{D}\,|\,\bf{w})$ 를 최대화하면 자연스럽게 $p(\bf{w}\,|\,\mathcal{D})$ 가 최대화 된다. ML 에서는 $-\ln p(D\,|\,\bf{w})$ 를 *error function* 이라 한다. 따라서 likelihood 를 최대화 하는것은 error function 을 최소화 하는 것이다.

- 예를 들어 동전을 던졌을 때 앞면이 나올 확률을 $q$ 라 하자. 세번의 동전을 던져 셋 다 앞면이 나왔을 때, 빈도주의적 접근에 의하면, Likelihood function 은
$$
p(\text{3 up}\,|\,q)=q^3
$$
  이므로 $p(\text{3 up}|q)$ 를 최대화  하는 것은 $q=1$ 이다. 이것은 매우 극단적인 결과이다.

- 그런데 베이지언에서는 $\bf{w}$ 에 받아들일만 한 사전확률분포 $p(\bf{w})$ 을 부여하므로 덜 극단적인 결론에 도달할 수 있다.

- 베이지언에 대한 가장 일반적인 비판중의 하나는 사전확률분포 $p(\bf{w})$ 를 선택할 때 수학적인 편리성이나 편견에 의해 결과가 왜곡 될 수 있다는 것이다. 이러한 주관성을 개선하기 위해 소위 **non-informative priors** 가 도입되기도 한다.


</br>

## The Gaussian Distribution (Normal Distribution)

평균 (mean) $\mu$ 와 분산 $\sigma^2$ 에 대한 1차원 가우시안 분포 $\mathcal{N}(x\mid \mu,\,\sigma^2)$ 는 다음과 같다.
$$
\mathcal{N} (x\mid \mu,\,\sigma^2) = \dfrac{1}{\sigma \sqrt{2\pi }} \exp \left[-\dfrac{(x-\mu)^2}{2\sigma^2}\right] 
$$ {#eq-ststistics_1d_gaussian_distribution}

가우시안 분포 $\mathcal{N}(x\mid \mu,\,\sigma^2)$ 는 다음과 같은 성질을 갖는다.

$$
\begin{align}
\mathcal{N}&(x\mid \mu,\,\sigma^2)  \ge 0\,,\\
\int_{-\infty}^\infty &\mathcal{N}(x\mid \mu,\,\sigma^2)\, dx = 1,\, \\
\mathbb{E}[x] &=\int_{-\infty}^\infty x\, \mathcal{N}(x\mid \mu,\,\sigma^2)\,dx=\mu\;, \\
\mathbb{E}[x^2] &= \int_{-\infty}^\infty x^2 \mathcal{N}(x\mid \mu,\,\sigma^2)\,dx=\mu^2+\sigma^2\;,\\
\operatorname{var}[f] &=\mathbb{E}[x^2]-\left(\mathbb{E}[x]\right)^2=\sigma^2 \;.
\end{align}
$${#eq-ststistics_properties_of_1d_gaussian_distribution}

$\mathbb{R}^\mathcal{D}$ 에서 평균 $\boldsymbol{\mu}$ 와 공분산 $\boldsymbol{\Sigma}$ 를 갖는 가우스 분포는 다음과 같다.

$$
\mathcal{N}(\boldsymbol{x}\mid \boldsymbol{\mu},\,\boldsymbol{\Sigma}) = \dfrac{1}{(2\pi)^{\mathcal{D}/2}}\dfrac{1}{\left|\boldsymbol{\Sigma}\right|^{1/2}} \exp \left[-\dfrac{1}{2} (\boldsymbol{x}-\boldsymbol{\mu})^T \boldsymbol{\Sigma} (\boldsymbol{x}-\boldsymbol{\mu})\right]
$${#eq-ststistics_properties_of_gaussian_distribution}

</br>

### 1-변수 가우스분포에서의 $\mu$와 $\sigma^2$ 의 추정 - 최대 가능도

스칼라 변수  $x$ 에 대해 $N$ 번 측정한 것을 $\bf{x}=\begin{bmatrix}x_1 &\ldots &x_N\end{bmatrix}^T$ 라 하자. 이 관측은 평균이 $\mu$ 이며 분산이 $\sigma^2$ 인 가우시안 분포를 따르는 변수에 대한 각각 독립적인 측정이라고 하자.

우선 $N$ 측정에서 $\bf{x}$ 가 관측될 확률은
$$
p(\bf{x}\mid \mu,\,\sigma^2)= \prod_{n=1}^N \mathcal{N}(x_n\mid \mu,\,\sigma^2)
$$ {#eq-ststistics_gaussian_likelihood_function}

이며 *likelihood function for the Gaussian* (가우시안 가능도 함수)이라 불리운다.

어쨋든, @eq-ststistics_gaussian_likelihood_function 의 우도함수를 최대화하는 $\mu,\,\sigma^2$ 를 정하자. 계산의 편의를 위해 로그함수를 사용한다.
$$
\ln p(\bf{x}\mid \mu,\,\sigma^2)= - \dfrac{1}{2\sigma^2}\sum_{n=1}^N (x_n-\mu)^2-\dfrac{N}{2} \ln \sigma^2 - \dfrac{N}{2} \ln 2\pi 
$$

이 때 $p (\bf{x}\mid \mu,\,\sigma^2)$ 를 최대화 하는 $\mu$ 와 $\sigma^2$ 를 $\mu_{ML},\,\sigma_{ML}^2$ 라 할 때 다음과 같다.

$$
\begin{align}
\mu_{ML} &= \dfrac{1}{N}\sum_{n=1}^N x_n \;,\\
\sigma_{ML}^2 &= \dfrac{1}{N} \sum_{n=1}^N (x_n-\mu_{ML})^2\;
\end{align}
$$ {#eq-statiscis_maximum_likelihood_mean_and_variance_of_gaussian}

</br>

#### **편항**

위와 같은 최대 가능도로부터 얻어진 분산은 원래 분포의 분산보다 작은데 하는데 이런 현상을 편향(bias)이라 한다. 표본의 평균과 분산의 기대값은 다음과 같다.
$$
\begin{align}
\mathbb{E}[\mu_{ML}]& =\mu \\
\mathbb{E}\left[\sigma_{ML}^2\right] & =\left(\dfrac{N-1}{N}\right)\sigma^2.
\end{align}
$$ {#eq-stastistics_mean_and_variance_of_sample_and_population}

식 (1.58)에서 보듯이 $\mathbb{E}\left[\sigma^2_{ML}\right]<\sigma^2$ 이다. 따라서 아래와 같이 정의된 $\widetilde{\sigma\,}^2$ 는 samples 로 부터 추정한 모집단의 분산과 같다. (즉 unbiased.) 이를 표본분산이라 한다.
$$
\widetilde{\sigma\,}^2 = \dfrac{N}{N-1}\sigma_{ML}^2 = \dfrac{1}{N-1} \sum_{n=1}^N\left(x_n-\mu_{ML}\right)^2 
$$ {#eq-statistics_population_variance}

$N\to \infty$ 일 때 $\sigma_{ML}^2 \to \sigma^2$ 임은 쉽게 알 수 있다. 실제로 $N$ 이 작지만 않으면 큰 문제는 되지 않는다.

</br> 

### Curve Fitting Revisited

$N$ 개의 입력 변수 $\bf{x} = \begin{bmatrix} x_1 &\ldots & x_N \end{bmatrix}^T$ 와 표적값 $\bf{t}=\begin{bmatrix} t_1 &\ldots &t_N\end{bmatrix}^T$ 사이에 다항식 $t=y(x;\bf{w})=w_0 + w_1x+ \cdots +w_nx^n$ 의 관계를 가정한다. 표적값의 불확도를 확률분포로서 표현하자. 이를 위해 주어진 $x$ 에 대해 표적값의 확률은 $y(\bf{x},\,\bf{w})$ 를 중심으로 분산이 $\beta^{-1}$ 인 가우시안분포를 따른다고 가정한다. 즉,

$$
p(t\mid x,\,\bf{w},\, \beta)=\mathcal{N}(t\mid y(x,\,\bf{w}),\,\beta^{-1}) 
$$ {#eq-statistics_parameter_distribution}

이다. 

훈련 데이터 $\{\bf{x},\,\bf{t}\}$ 를 이용하여 미지의 매개변수 $\bf{w}$ 와 $\beta$ 를 결정하자. 그렇다면 가능도 함수는 다음과 같이 주어진다.
$$
p(\bf{t}\mid \bf{x},\,\bf{w},\,\beta)=\prod_{n=1}^N \mathcal{N}(t_n\mid y(x_n,\, \bf{w}),\, \beta^{-1}).
$$ {#eq-statistics_curve_fitting_likelihood}

앞서와 같이 $\ln$ 을 취하면

$$
\ln p(\bf{t}\mid \bf{x},\, \bf{w},\,\beta)= -\dfrac{\beta}{2} \sum_{n=1}^N \left[y(x_n,\,\bf{w})-t_n\right]^2+\dfrac{N}{2} \ln \beta - \dfrac{N}{2} \ln (2\pi)
$$ {#eq-statistics_curve_fitting_likelihood_log}

이 된다. 


- @eq-statistics_curve_fitting_likelihood_log 로부터 고정된 $\beta$ 에 대해 $p(\bf{t}\mid \bf{x},\, \bf{w},\,\beta)$ 를 최대화 하는 것과 $\displaystyle \dfrac{1}{2}\sum_{n=1}^N \left[ y(x_n,\,\bf{w})-t_n\right]^2$ 를 최소화하는 것, 즉 제곱합 오차를 최소화 하는것은 동치라는 것을 알 수 있다. 이 $\bf{w}$ 를 $\bf{w}_{ML}$이라 하자. 
  
- 또한 $\beta$ 에 대해 미분하여 $p$ 를 최대화 하는 $\beta$ 를 찾아 $\beta_{ML}$ 이라 하면,
  $$
  \dfrac{1}{\beta_{ML}}=\dfrac{1}{N}\sum_{n=1}^N \left[ y(x_n,\, \bf{w}_{ML})-t_n\right]^2 
  $$ {#eq-statistics_cuve_fitting_param_1}

  이다. $\beta$ 역시 $\bf{w}_{ML}$ 이 결정된 상황에서 제곱합 오차를 최소화 할 때 확률을 최대화 하도록 결정된다.
  
  
이제 우리는 주어진 데이터로부터 가장 잘 예측할 수 있는 확률 분포를 다음과 갇이 얻는다.

$$
p(t\mid x,\,\bf{w}_{ML},\, \beta_{ML})=\mathcal{N}(t\mid  y(x,\,\bf{w}_{ML}),\,\beta_{ML}^{-1})
$$ {#eq-statistics_cuve_fitting_most_likely_function}

</br>

<div class="border" style="background-color:#F2F4F4  ;padding:5px;">

##### **베이즈 통계를 위한 공식**

$$
\begin{align}
p(a|x)&=\sum_y p(a| x,\,y)\, p(y| x)  \tag{B1} \\
p(a|x,\,y) &= \dfrac{p(x|a,\,y)\, p(a|y)} {p(y|x)}  \tag{B2}
\end{align}
$$

---

::: {.proof}
($B1$)
$$
\begin{aligned}
\sum_y p (a\,|\, x,\,y)\, p(y\mid x)&=\sum_y \dfrac{p(a,\,x,\,y)}{p(x,y)} \cdot \dfrac{p(x,\,y)}{p(x)} =\sum_y \dfrac{p(a,\,x,\,y)}{p(x)} \\
&=\dfrac{1}{p(x)}\sum_{y}p(a,\,x,\,y) = \dfrac{p(a,\,x)}{p(x)} \\
&=p(a|x)
\end{aligned}
$$

($B2$)
$$
\begin{aligned}
\dfrac{p(x|a,\,y)\, p(a|y)}{p(y|x)} &= \dfrac{p(a,\,x,\,y)}{p(a,\,y)} \cdot \dfrac{p(a,\,y)}{p(y)} \cdot \dfrac{p(y)}{p(x,\,y)}=\dfrac{p(a,\,x,\,y)}{p(x,\,y)}=p(a|x,\,y)
\end{aligned}
$$
:::
</div></br>


이제 Bayesian 접근법을 좀 알아보자. 즉 $\bf{w}$ 에 대한 사전 분포 $p(\bf{w})$ 에 대한 것이다. $\bf{w}$ 가 아래와 같은 분포를 따른다고 하자.

$$
p(\bf{w}|\alpha)=\mathcal{N}(\bf{w}|\bf{0},\,\alpha^{-1}\bf{1}_{M+1})=\left(\dfrac{\alpha}{2\pi}\right)^{(M+1)/2} \exp \left(-\dfrac{\alpha}{2}\bf{w}^T \bf{w}\right) 
$$ {#eq-statistics_bayesian_fitting_1}

여기서 $M$ 은 다항식의 차수이며 이며 따라서 $\bf{w}$ 는 $M+1$ 개의 성분을 가진다. $\alpha$ 와 같이 모델 파라메터의 분포를 제어하는 변수를 **초매개변수(hyperparameters)** 라 한다.  

베이즈 정리로 부터,
$$
[\bf{w} \text{ 에 대한 사후 확률}] \propto [\text{가능도}]\times[\bf{w}\text{ 의 사전 확률 분포}]
$$

임을 알고 있으므로,

$$
p(\bf{w}\,|\,\bf{x},\,\bf{t},\,\alpha,\,\beta) \propto p(\bf{t}\,|\,\bf{x},\,\bf{w},\,\beta)\cdot p(\bf{w}\,|\,\alpha) 
$$ {#eq-statistics_bayesian_fitting_2}

이다. @eq-statistics_bayesian_fitting_2 에 $-\ln$ 을 취하고 @eq-statistics_curve_fitting_likelihood_log, @eq-statistics_cuve_fitting_most_likely_function 를 대입하면, 사후확률을 극대화 하는 $\bf{w}$ 는 다음 식을 최소화 하는 것 $\bf{w}$ 이다.

$$
\dfrac{\beta}{2}\sum_{n=1}^N \{y(x_n,\,\bf{w})-t_n\}^2+\dfrac{\alpha}{2} \bf{w}^T \bf{w}.
$$ {#eq-statistics_bayesian_fitting_3}


즉 베이지안에서 사후확률분포를 최대화하는 것은 정규화된 제곱합 오차 함수를 최소화 하는 것과 동등하다.

</br>

### Bayesian Curve Fitting

앞서 우리는 사전확률분포 $p(\bf{w}|\alpha)$ 에 대한 추정을 포함시켰지만, $\bf{w}$ 에 대한 point estimate 이므로 이것은 제대로 된 베이지안 처리가 아니다. 제대로 된 베이지언 처리는 확률에 대한 합과 곱의 규칙들을 일관되게 적용해야 하며, 이는 $\bf{w}$ 에 대한 모든 값에 대해 적분해야 함을 의미한다. 이러한 marginalizations 가 패턴 인식에서의 베이지언 방법의 핵심이다.
  
- 일단 $\alpha,\,\beta$ 를 고정시키고 (편의를 위해 식에서는 일단 빼자.), test set $\{\bf{x},\,\bf{t}\}$ 만을 생각하자. 베이지안 방법은

  $$
  p(t\,|\,x,\,\mathbf{x},\,\mathbf{t})=\int p(t\mid x,\,\mathbf{w})\, p(\mathbf{w}\mid\mathbf{x},\,\mathbf{t})\,d\mathbf{w}
  $${#eq-statistics_bayesian_fitting_4}


  을 생각한다. 여기서 $p(t\mid x,\,\bf{w})$ 는 식 @eq-statistics_parameter_distribution 에 나와 있으며 $p(\bf{w}\mid \bf{x},\,\bf{t})$ 는 사후확률분포이다. (@eq-statistics_bayesian_fitting_2 을 보라.) 

- 뒤에 보겠지만, curve fitting example 과 같은 문제에서 이 사후확률분포 은 Gaussian 이며 해석적으로 계산 할 수 있다. 비슷하게 @eq-statistics_bayesian_fitting_4 도 해석적으로 적분될 수 있으며 그 결과는 아래와 같은 가우시한 형태로 주어진다.

  $$
  p(t\mid x,\,\bf{x},\,\bf{t}) =\mathcal{N}(t\mid m(x),\, s^2(x))
  $$

  여기서 평균 $m(x)$ 와 분산 $s^2(x)$ 는 다음과 같다.
  $$
  \begin{aligned}
  m(x) &=\beta \phi(x)^T \bf{S} \sum_{n=1}^N \bf{\phi} (x_n) t_n\\
  s^2(x) &=\beta^{-1}+ \bf{\phi}(x)^T\bf{S}\bf{\phi}(x) \\
  \end{aligned}
  $$

  여기서 행렬 $\bf{S}$ 는 다음과 같고 $\bf{\phi}(x) = \begin{bmatrix} x^0 & \cdots & x^M\end{bmatrix}^T$ 이다.  
$$
\begin{align}
\bf{S}^{-1} &= \alpha \bf{I} + \beta \sum_{n=1}^N \bf{\phi}(x_n) \bf{\phi}(x_n)^T
\end{align}
$$

</br>

## Model Selection

- 최소자승법을 이용한 Polynomial curve fitting 에서 보았듯이 best generalization을 주는 최적의 다항식의 order $M$ 이 존재한다. 다항식의 order는 모델에서 free parameters의 갯수를 제어한다. Regularization 을 사용하면 regularization coefficient $\lambda$ 는 모델의 유효 복잡도(effiective complexcity) 를 통제한다. 
- 실제 응용에서 우리는 이러한 parameters 들을 결정해야 하며 이렇게 하는 주요 목적은 새로운 데이터에 대한 최소의 predictive performance를 얻기 위함이다. 또한 이렇게 complexicity parameters 에 대한 적당한 값을 찾는 것 뿐만 아니라, 특정 목표에 적합한 모델을 찾기 위해 다양한 모델을 고려할 필요가 있다.
- MLA (maximum likelihood approach) 에서 보았듯이 training set 에 대한 performance 가 다른 데이터에 대한 예측력을 보장해주지 않는다. (overfitting). 만약 데이터가 많다면 가용한 데이터중 일부를 다양한 모델을 학습시키거나, 주어진 모델에 대해 complexicity parameters 를 다양한 범위에서 학습시키는데 사용하고 이것을 독립적인 데이터를 사용하여 predictive performance를 비교하여 수 도 있다. 이렇게 학습데이터와 독립적으로 사용되는 데이터를 **validation set** 이라 한다. 이렇게 수차례 반복한 다음에 **test set** 이라 불리는 별도의 독립적인 데이터를 사용하여 최종적으로 평가할 수도 있다.
-  보통은 training과 testing에 사용될 수 있는 데이터가 부족한데, 이 경우 좋은 모델을 만들기 위해 training에 가능한 많은 데이터를 사용하고자 할 수 있다. 그러나 만약 validation set이 부족하면 it will give a relatively noisy estimate of predictive performance. 이 딜레마에 대한 해결방법중 하나로 cross validation 방법이 있다.



#### **Cross Validation**

- 전체 데이터를 $S$ 개의 group으로 나눈다. $S$ 개의 training group 으로 각 training group 마다 $S-1$ 개의 데이터 그룹을 training set으로 나머지 하나를 validation set으로 사용한다.

- Training group 마다 각자의 모델 (혹은 별도의 parameters set) 을 사용하므로 computationally expensive 하다. 또한 하나의 모델에 대한 다수의 complexcity parameter 를 갖게 될 수 있다. 이런 조합들을 탐색하다보면 최악의 경우 training run 이 parameter 갯수의 지수승으로 증가할수도 있다.!!!

- 우리는 더 좋은 접근법을 사용해야 한다. 이상적으로 이 접근법은 training data 에 의존해야 하며, 한번의 training run을 통해 비교 할 수 있는 다수의 hyperparameters와 model types 를 허용해야 하는데....

- 이를 위해 training data 에만 의존하며 over fitting에 의한 bias로부터 자유로운 성능 척도를 찾아야 한다.

- 역사적으로 복잡한 모델에서의 over fitting을 보상하는 penalty term을 추가함으로서 maximum likelihood의 bais를 교정하고자 하는 다양한 'information criteria' 가 제안되었다. 예를 들어 *Akaike information criterion* (AIC) 의 경우 
  $$
  \ln p(\mathcal{D}\mid \bf{w}_{ML})-M
  $$
  을 최대화 하는 모델을 선택한다. 여기서 $p(\mathcal{D}\mid \bf{w}_{ML})$ 은 best-fit log likelihood 이며 $M$ 은 모델에서 adjustable 한 parameter의 갯수이다. 이의 변형으로서 *Bayesian information criterion* 이 있는데 이는 section 4.4.1 에서 소개될 것이다. 이러한 criteria는 model parameter의 불확실성을 고려하지 않으며, 실제적으로는 과하게 간단한 모델을 선호한다. 

- 따라서 우리는 section 3.4 에서 fully Bayesian approach 로 전환할 것이며 이러한 complexity penalty 가 자연스럽고 원칙적인 방법으로 발생하는지 볼 것이다.

  
</br>


## 차원의 저주

- 우리가 다루고자 하는 입력 데이터가 고차원의 데이터 ($\mathcal{D}-\dim$)라고 가정해보자. 다항식 근사에서 order $3$ 까지 전개하면 다음과 같다.
  
  $$
  y(\bf{x},\,\bf{w})=w_0+\sum_{i=1}^\mathcal{D} w_i x_i + \sum_{i=1}^\mathcal{D}\sum_{j=1}^\mathcal{D} w_{ij}x_ix_j + \sum_{i=1}^\mathcal{D}\sum_{j=1}^\mathcal{D} \sum_{k=1}^\mathcal{D} w_{ijk}x_i x_j x_k 
  $$ {#eq-ML_statistics_polynomial_expansion_of_mulitivariable}

  $\mathcal{D}$ 에 따라 3차항의 계수의 갯수는 $\mathcal{D}^3$ 개 만큼 증가하는 것처럼 보인다.(실제로는 interchange symmetry 로 인해 이것보다는 작지만 그래도 $\mathcal{D}\gg M$ 일 경우는 $\mathcal{D}^M$ 와 같이 증가한다. (@Bishop2006 exercise 1.16) 이것도 아주 급격하게 증가하는 것이다. )

- ${D}$ 차원의 구를 생각하자. ${D}$ 가 커질수록 구의 대부분의 부피는 표면에 분포한다. ${D}$ 차원에서 반경 $r$ 인 구의 부피 $V_D(r)=K_D r^D$ 이다 여기에 작은 $0<\epsilon\ll 1$ 을 생각하면 구 표면의 두께 $\epsilon$ 만큼의 껍질의 부피와 $D$ 차원에서의 unit sphere 의 부피의 비는,
  $$
  \dfrac{V_D(1)-V_D(1-r)}{V_D(1)}=1-(1-\epsilon)^D
  $$
  임을 안다. ${D}$ 가 커질 수록 작은 $\epsilon$ 에서의 값이 크다. 

- $D$ 차원 가우시안 분포에서 이 데이터를 polar coordinate 로 바꾸어 보자. 차원이 늘어날수록 $p(r)$ 에서 가장 높은 확률을 가진 값이 점점 커진다. 이는 고차원 구에서 대부분의 부피가 spherical shell에 위치한다는 앞의 논리와 상응한다. 

- 차원의 저주는 저차원에서의 직관이 고차원에서도 통용되지 않는 경우가 많음을 의미한다. 이 차원의 저주는 패턴 인식의 응용에 있어서 중요한 문제를 제기하지만 고차원을 다루는 효율적인 테크닉이 부족하거나 없다는 것을 의미하지는 않는다. 

  - 고차원의 데이터라도 실제로는 보다 낮은 차원의 특정 영역에 데이터가 제한되어 있는 경우가 흔하며,
  - 실제 데이터는 전형적으로 어떤 smoothness properties 를 (최소한 국소적으로라도) 가지고 있는 경우가 많다. 



