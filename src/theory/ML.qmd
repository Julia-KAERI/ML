---
number-sections: false
number-depth: 3
crossref:
  chapters: true


nocite: |
  @Bishop2006, @iAI_Kaist, @Deisenroth2020
---

# 기계학습 {.unnumbered}

{{< include ../latexmacros.qmd >}}

</br>

### References {.unnumbered}

::: {#refs}
:::


</br>

## 기계 학습의 분류

- 지도 학습(Supervised Learning) 
  - 입력 $\bf{x}$ 에 대한 정답(label) $\bf{t}$ 이 있는 데이터를 학습한다. 
  - 회귀(regression) : 정답으로서 가능한 값이 실수($\R$) 인 경우.
  - 분류(classification) : 정답으로서 가능한 값이 이산적인 값일 경우.


- 비지도 학습(Unsupervised Learning)
  - 정답(label)이 없는 데이터를 특징별로 군집화 (clustering) 하거나 데이터의 분포를 추정한다.

- 강화학습 or 증강학습 (Reinforced Learning)
  - 주어진 데이터가 아닌, 환경과 상호작용을 통해 학습
  - 주어진 상태(state) 에 행동 (action) 을 취하며, 이에 대한 보상(reward)을 받는다.
  - 훈련 도중에, 최대 보상을 받도록 정책(policy)를 지속적으로 수정한다.

</br>

## 함수로서의 기계학습

- 인공지능은 어떤 입력에 대한 출력을 하며 우리는 보통 이런 것을 수학적으로는 함수(function) 라고 부른다.
  
- 기계학습에서의 학습이란 대량의 데이터를 입력하여 이 데이터를 가장 잘 표현하는 하나의 함수를 정하는 것이다. 하나의 데이터에 대해 보통 입력값이 여러개이므로  $i$-번째 데이터의 입력은 $\bf{x}_i$ 로 $i$-번째 데이터의 label 은 $y_i$ 로 표기한다. 입력값과 레이블 의 쌍을 $(\bf{x}_i, y_i)$  로 표기한다. 
  
- 함수를 내부적으로 표현하는데 쓰는 값을 매개변수 (parameter) 라 한다. 예를 들어 
$$
y=f(\bf{x}=(x_1, x_2)) = ax_1+bx_2+c = \begin{bmatrix} 1 & a & b \end{bmatrix}\begin{bmatrix} 1 \\ x_1 \\ x_2 \end{bmatrix} 
$$
  일 경우, 입력값은 $\bf{x}=\begin{bmatrix}x_1 & x_2\end{bmatrix}^T$, 매개변수는 $a, b, c$, 출력값은 $y$ 이다.

- 기계학습을 통해 매개변수를 정해야 함수가 완성된다. 매개변수의 집합을 $\bf{w}$ 로 표기하여 함수를 다음과 같이 쓰기도 한다.
$$
y=f(\bf{x} ; \bf{w})
$$

  출력값이 벡터일 경우는 다음과 같이 쓰기도 한다.

$$
\bf{y} = \bf{f}(\bf{x};\bf{w})
$$


- 데이터와 레이블의 쌍의 집합을 데이터셋이라고 하고 $i$ 번째 데이터를 $(\bf{x}^{(i)},\, \bf{t}^{(i)})$ 과 같이 표기하자. 함수가 얼마나 데이터를 잘 기술하는지를 평가하는 함수를 **손실함수(Loss function)** 혹은 **비용함수(Cost function)** 라고 한다. 대표적인 손실함수로는 신경망(Neural Network) 에서, 회귀의 경우 **평균제곱오차 (Mean Square Error, MSE) 함수** 와 분류의 경우 **교차 엔트로피 오차 (Cross Entropy Error, CEE)** 함수가 있다.  
$$
\begin{aligned}
\text{MSE}(\bf{w}) &= \dfrac{1}{2} \sum_{i=1}^N \|\bf{t}^{(i)} - f(\bf{x}^{(i)}; \bf{w})\|^2 \\[0.3em]
\text{CEE}(\bf{w}) &= -\sum_{i=1}^N t^{(i)} \ln (f(\bf{x}^{(i)};\bf{w}))\\[0.3em]
\end{aligned}
$$
  여기에 대한 정확한 설명은 뒤로 미루기로 하자.


- 기계학습을 통해 오차함수를 최소화 하는 매개변수들을 찾아 함수를 완성한다.
  
- 손실 함수(Loss Function) $L(\bf{w})$ 의 특징
  - $L(\bf{w}) ≥ 0$
  - $L(\bf{w})$ 는 미분가능 함수
  - 최적의 경우 = $L(\bf{w})$ 가 최소값이 되는 경우
  - 따라서 기계학습에서 학습이란 $L(\bf{w})$ 가 최소값이 되도록 하는 $\bf{w}$ 를 찾는 것이다. (최적화 (optimization))
  

</br>

